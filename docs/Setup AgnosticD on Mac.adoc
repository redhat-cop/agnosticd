= Setup AgnosticD on M1 Macs for OpenShift development (non Execution Environment version)

[WARNING]
====
This is a stop gap solution until the Ansible BU supports building execution environments on M1 Macs.
====

This documents walks through how to set up AgnosticD development on a Mac (with M1 chip) for OpenShift development.

. Make sure you have Homebrew installed (https://brew.sh)
. Install Python 3, Virtualenv and jq
+
[source,sh]
----
brew install python3 virtualenv jq
----

. Set up directory structure:
+
[source,sh]
----
mkdir -p ~/Development/agnosticd
mkdir -p ~/Development/agnosticd-vars
mkdir -p ~/Development/agnosticd-output
mkdir -p ~/Development/virtualenvs
----

. Clone the AgnosticD repo:
+
[source,sh]
----
cd ~/Development
git clone https://github.com/redhat-cop/agnosticd
----

. Set up Virtualenv
.. Create requirements file for Python Modules (now this is mine and probably has tons of things installed that you don't actually need. The official one is at https://github.com/redhat-cop/agnosticd/blob/development/ansible/configs/ocp4-cluster/files/requirements_k8s.txt)
+
~/Development/virtualenvs/agnosticd.txt
[source,sh]
----
ansible==2.9.27
asn1crypto==1.3.0
boto==2.49.0
cachetools==4.2.4
certifi==2021.10.8
cffi==1.15.1
chardet==3.0.4
charset-normalizer==2.0.7
colorama==0.4.3
cryptography==38.0.3
dictdiffer==0.8.1
distro==1.4.0
docutils==0.15.2
google-auth==2.3.3
idna==3.3
Jinja2==3.0.3
jmespath==0.10.0
lxml==4.6.3
MarkupSafe==2.0.1
oauthlib==3.1.1
pyasn1==0.4.8
pyasn1-modules==0.2.8
pycparser==2.19
PyJWT==1.7.1
pyRFC3339==1.1
python-dateutil==2.8.2
python-string-utils==1.0.0
pytz==2019.3
PyYAML==5.4.1
requests==2.26.0
rsa==4.7.2
ruamel.yaml==0.17.7
ruamel.yaml.clib==0.2.6
selinux==0.2.1
six==1.16.0
urllib3==1.26.7
websocket-client==1.2.1
----
.. Create requirements file for Ansible Collections (again this is mine, offial is at https://github.com/redhat-cop/agnosticd/blob/development/ansible/configs/ocp4-cluster/requirements.yml)
+
~/Development/virtualenvs/collections.yaml
[source,yaml]
----
---
collections:
- name: amazon.aws
  version: 2.3.0 # Do not use anything newer than 2.x
- name: kubernetes.core
  version: 2.3.2
- name: community.general
  version: 5.4.0
- name: ansible.posix
  version: 1.4.0
- name: community.crypto
  version: 2.7.1
----

.. Create the virtualenv
+
[source,sh]
----
virtualenv -p $(which python3) ~/Development/virtualenvs/agnosticd
source ~/Development/virtualenvs/agnosticd/bin/activate
----

.. Install requirements and collections
+
[source,sh]
----
pip install -r ~/Development/virtualenvs/agnosticd.txt
ansible-galaxy install -r ~/Development/virtualenvs/collections.yaml
----

. Link the deployer scripts to you `~/bin` directory (make sure `~/bin` is in your PATH in either `.bashrc` or `.zshrc`):
+
[source,sh]
----
mkdir ~/bin
ln -s ~/Development/agnosticd/tools/deployer_scripts/* ~/bin
----

== Deploy a new OpenShift Cluster

=== Setting up secrets

. Create a secrets file for generic secret information (RHN subscription, Pull Secret, ...)
+
~/Development/agnosticd-vars/secrets.yaml
[source,yaml]
----
# Satellite
repo_method: satellite
set_repositories_satellite_ha: true
set_repositories_satellite_url: "<< ASK >>"
set_repositories_satellite_org: "<< ASK >>"
set_repositories_satellite_activationkey: "<< ASK >>"

# Or Employee Subscription
# repo_method: rhn
# rhel_subscription_user: "<< rhel subscription user >>"
# rhel_subscription_pass: "<< rhel subscription password >>"

# Pull secret from https://console.redhat.com
ocp4_pull_secret: "<< Your OCP Pull Secret >>"

email: "<< Your Red Hat e-mail>>"

# Your public key for the bastion VM needs to be in Github
ssh_authorized_keys:
- key: https://github.com/xxxxxxx.keys
----

. Create a second secrets file for your cloud environment. E.g. for an AWS Open Environment (from https://demo.redhat.com)
+
~/Development/agnosticd-vars/secrets-sandbox.yaml
[source,yaml]
----
# Get these values from the Open Environment
# Or if you have your own AWS account use those
aws_access_key_id: "<< ACCESS KEY ID >>"
aws_secret_access_key: "<< SECRET ACCESS KEY >>"
subdomain_base_suffix: .sandboxXXXX.opentlc.com

agnosticd_aws_capacity_reservation_enable: false
----

== Create a Key Pair

In order to access the bastion VM of your cluster you need an ssh key pair. The easiest way to manage that is to store your public key on Github.

. Create a new key pair (hit enter twice for no passphrase)
+
[source,sh]
----
# XXXXXX is your redhat ID
ssh-keygen -f ~/.ssh/XXXXXXXXX-github
----

. Upload your public key to Github
.. Navigate to https://github.com/settings/keys
.. Click *New SSH Key*
.. Use a Title for you to remember what this is for e.g. `agnosticd-key` and paste your *public* key from `~/.ssh/XXXXXXXXX-github.pub`

== Deploying a base cluster

To start development on a workload you want to have a base OpenShift cluster available. The following variable file sets up an OpenShift cluster with Let's Encrypt certificates and HTPasswd authentication.

. Create a variable file for your cluster:
+
~/Development/agnosticd-vars/ocp-cluster.yaml
[source,yaml]
----
---
# -------------------------------------------------------------------
# Mandatory Variables
# -------------------------------------------------------------------
cloud_provider: ec2
env_type: ocp4-cluster
software_to_deploy: openshift4
# -------------------------------------------------------------------
# End Mandatory Variables
# -------------------------------------------------------------------

# -------------------------------------------------------------------
# Platform
# -------------------------------------------------------------------
platform: labs
purpose: development

# -------------------------------------------------------------------
# Cloud config
# -------------------------------------------------------------------
aws_region: us-east-2
# aws_zones:
# - us-east-2a
# - us-east-2b

# Use key from your Github
ssh_authorized_keys:
- key: https://github.com/GITHUBID.keys

cloud_tags:
- owner: "<< YOUR REDHAT EMAIL >>"
- Purpose: development
- env_type: "{{ env_type }}"
- guid: "{{ guid }}"

# -------------------------------------------------------------------
# VM configuration
# -------------------------------------------------------------------
master_instance_type: m5.xlarge
master_instance_count: 3
worker_instance_type: m5a.2xlarge
worker_instance_count: 2
bastion_instance_type: t3a.medium
bastion_instance_image: RHEL84GOLD-latest

# -------------------------------------------------------------------
# Install Student User on bastion VM
# -------------------------------------------------------------------
install_student_user: true
student_name: lab-user

# -------------------------------------------------------------------
# OpenShift Installer Version
# -------------------------------------------------------------------
# Latest stable 4.11 release (in quotes!)
ocp4_installer_version: "4.11"
ocp4_installer_root_url: http://mirror.openshift.com/pub/openshift-v4/clients

# -------------------------------------------------------------------
# Other Variables
# -------------------------------------------------------------------
ocp4_network_type: OVNKubernetes

# Update RHEL to the latest packages (and reboot)
update_packages: true

# -------------------------------------------------------------------
# Workloads
# -------------------------------------------------------------------
# --- Infra Workloads (YAML List)
infra_workloads:
- ocp4_workload_authentication
- ocp4_workload_le_certificates

# -------------------------------------------------------------------
# Workload variables
# -------------------------------------------------------------------

# -------------------------------------------------------------------
# Workload: ocp4_workload_authentication
# -------------------------------------------------------------------
ocp4_workload_authentication_idm_type: htpasswd
ocp4_workload_authentication_admin_user: admin
ocp4_workload_authentication_htpasswd_admin_password: r3dh4t1!
ocp4_workload_authentication_htpasswd_user_base: user
ocp4_workload_authentication_htpasswd_user_password: openshift
ocp4_workload_authentication_htpasswd_user_count: 5
ocp4_workload_authentication_remove_kubeadmin: true
----

. Run the script to deploy your cluster (using the YAML files you created previously)
+
[source,sh]
----
# Script   GUID   CLUSTER     CLOUD CREDENTIALS
aad_create myguid ocp-cluster sandbox
----

. If you need to delete the cluster you can either delete the Open Environment (which will clean everything up) or just run destroy:
+
[source,sh]
----
# Script   GUID   CLUSTER     CLOUD CREDENTIALS
aad_destroy myguid ocp-cluster sandbox
----

== Deploying a workload on a cluster

. To deploy a workload on an already provisioned base cluster create a vars file for your workload - the example will use the Pipelines operator workload
+
~/Development/agnosticd-vars/workload-pipelines.yaml
[source,yaml]
----
# ---------------------------------------------------------
# OpenShift Pipelines
# ---------------------------------------------------------
ocp4_workload_pipelines_channel: pipelines-1.8
ocp4_workload_pipelines_use_catalog_snapshot: true
ocp4_workload_pipelines_catalog_snapshot_image: quay.io/gpte-devops-automation/olm_snapshot_redhat_catalog
ocp4_workload_pipelines_catalog_snapshot_image_tag: v4.11_2022_11_07
----

. Create the shell script to install or remove the workload to/from your cluster (not necessary if you linked the scripts):
+
~/bin/aad_workload
[source,sh]
----
#!/bin/bash
# Args:
#   aad_workload action guid basedomain workload_name
# Example:
#   aad_workload create myguid sandbox2794.opentlc.com ocp4_workload_pipelines
#   aad_workload remove myguid sandbox2794.opentlc.com ocp4_workload_pipelines

ACTION=${1}
GUID=${2}
HOSTGUID=${2}
BASE_DOMAIN="${3}"
WORKLOAD=${4}

TARGET_HOST=bastion.${HOSTGUID}.${BASE_DOMAIN}
OCP_USERNAME="system:admin"

CLOUD_PROVIDER=ec2
ANSIBLE_USER=ec2-user

#VERBOSITY=-vvvv

# Your private key file matching the public key on Github
ANSIBLE_USER_KEY_FILE="~/.ssh/private-key.pem"

rm -rf $HOME/Development/agnosticd-output/${WORKLOAD}

# Deploy the Workload
ansible-playbook ${VERBOSITY} -i ${TARGET_HOST}, ~/Development/agnosticd/ansible/configs/ocp-workloads/ocp-workload.yml \
  --private-key=${ANSIBLE_USER_KEY_FILE} \
  -e"ansible_user=${ANSIBLE_USER}" \
  -e"ocp_username=${OCP_USERNAME}" \
  -e"ocp_workload=${WORKLOAD}" \
  -e"subdomain_base=${BASE_DOMAIN}" \
  -e"subdomain_base_suffix=.${BASE_DOMAIN}" \
  -e"silent=False" \
  -e"guid=${GUID}" \
  -e"ACTION=${ACTION}" \
  -e"become_override=False" \
  -e"output_dir=$HOME/Development/agnosticd-output/${WORKLOAD}" \
  -e"cloud_provider=${CLOUD_PROVIDER}" \
  -e"target_host=bastion.${GUID}.${BASE_DOMAIN}" \
  -e @$HOME/Development/agnosticd-vars/workload-${WORKLOAD}.yaml \
----

. Install the workload on your cluster:
+
[source,sh]
----
aad_workload create myguid sandbox2794.opentlc.com ocp4_workload_pipelines
----

. If the workload supports uninstall (it should....) uninstall from your cluster:
+
[source,sh]
----
aad_workload remove myguid sandbox2794.opentlc.com ocp4_workload_pipelines
----
