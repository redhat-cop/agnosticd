= ocp4-workload-mlops - Install and Configure Hands-On Lab for MlOps workshop


== Role overview

This is only tested and validated on OCP 4.6 and >= 4.6.15. Not on OCP 4.7 yet. 

* This role enables the MLOps workshop on an OpenShift 4 Cluster. It consists of the following playbooks:
** Playbook: link:./tasks/pre_workload.yml[pre_workload.yml] - Sets up an
 environment for the workload deployment.
*** Debug task will print out: `pre_workload Tasks completed successfully.`

** Playbook: link:./tasks/workload.yml[workload.yml] - Used to deploy the MLOps workshop instance
*** Debug task will print out: `workload Tasks completed successfully.`

** Playbook: link:./tasks/post_workload.yml[post_workload.yml] - Used to
 configure the workload after deployment
*** This role doesn't do anything here
*** Debug task will print out: `post_workload Tasks completed successfully.`

** Playbook: link:./tasks/remove_workload.yml[remove_workload.yml] - Used to
 delete the workload
*** This role removes the MLOps workshop Instance from OCP 4. This role does *not* remove the project - there may be other items in it.
*** Debug task will print out: `remove_workload Tasks completed successfully.`

== Review the defaults variable file

* This file link:./defaults/main.yml[./defaults/main.yml] contains all the variables you need to define to control the deployment of your workload.
* The variable *ocp_username* is mandatory to assign the workload to the correct OpenShift user.
* A variable *silent=True* can be passed to suppress debug messages.
* You can modify any of these default values by adding `-e "variable_name=variable_value"` to the command line

=== Deploy a Workload with the `ocp4-workload-mlops` playbook [Mostly for testing]

Using an existing OCP 4.6 workshop from RHPDS and upgrade to at least 4.6.15 first.

----
#!/bin/bash

OCP_USERNAME="opentlc-mgr"
WORKLOAD="ocp4-workload-mlops" 
USER_COUNT=2
PASSWORD=r3dh4t1!
GUID=b5c8
ACTION=create 

 # This to reset user password
 ansible-playbook -i localhost, -c local ./configs/ocp-workloads/ocp-workload.yml \
     -e "ansible_python_interpreter=`which python`" \
     -e"ACTION=create" \
     -e"ocp_username=${OCP_USERNAME}" \
     -e"ocp_workload=roles_ocp_workloads/ocp4_workload_authentication" \
     -e"silent=False" \
     -e"ocp4_workload_authentication_remove_kubeadmin=False" \
     -e"ocp4_workload_authentication_htpasswd_user_count=${USER_COUNT}" \
     -e"ocp4_workload_authentication_admin_user=${OCP_USERNAME}" \
     -e"ocp4_workload_authentication_htpasswd_admin_password=${PASSWORD}" \
     -e"ocp4_workload_authentication_htpasswd_user_password=${PASSWORD}"

# Deploy the workshop onto an existing OCP 4 cluster. 
ansible-playbook -i localhost, -c local ./configs/ocp-workloads/ocp-workload.yml \
    -e "ansible_python_interpreter=`which python`" \
    -e"ACTION=$ACTION" \
    -e"ocp_username=${OCP_USERNAME}" \
    -e"ocp_workload=${WORKLOAD}" \
    -e"guid=${GUID}" \
    -e"silent=False" \
    -e"num_users=${USER_COUNT}" 
----

=== To Delete an environment

----
OCP_USERNAME="opentlc-mgr"
WORKLOAD="ocp4-workload-mlops" 
USER_COUNT=2
GUID=b5c8
ACTION=remove 

# a TARGET_HOST is specified in the command line, without using an inventory file
ansible-playbook -i localhost, -c local ./configs/ocp-workloads/ocp-workload.yml \
    -e "ansible_python_interpreter=`which python`" \
    -e"ACTION=$ACTION" \
    -e"ocp_username=${OCP_USERNAME}" \
    -e"ocp_workload=${WORKLOAD}" \
    -e"guid=${GUID}" \
    -e"silent=False" \
    -e"num_users=${USER_COUNT}" 
----
== To develop the workshop guide on OpenShift

----
cat << EOF | oc create -f -

{
  "kind": "PersistentVolumeClaim",
  "apiVersion": "v1",
  "metadata": {
    "name": "httpd",
    "namespace": "labs-infra"
  },
  "spec": {
    "accessModes": [
      "ReadWriteMany"
    ],
    "resources": {
      "requests": {
        "storage": "1Gi"
      }
    },
    "storageClassName": "ocs-storagecluster-cephfs",
    "volumeMode": "Filesystem"
  }
}
EOF

$ oc new-app httpd:2.4 --name=httpd-app  -n labs-infra
$ oc expose svc/httpd-app -n labs-infra
$ oc set volume dc/httpd-app --add -m /var/www/html -t pvc --claim-name httpd --claim-mode ReadWriteMany -n labs-infra
$ HTTP_HOSTNAME=$(oc get routes httpd-app -o jsonpath="{.spec.host}" -n labs-infra)
$ oc set env dc/guides-m1 WORKSHOPS_URLS=http://$HTTP_HOSTNAME/_ocp-ai-ml-workshop.yml CONTENT_URL_PREFIX=http://$HTTP_HOSTNAME -n labs-infra
----

You can now `oc rsync` the workshop https://github.com/rh-mlops-workshop/ocp-al-ml-workshop-m1-guides[guide] into the http pod `/var/www/html` and restart the workshopper pod to view the new guide.


== Other related information:

=== Deploy Workload on OpenShift Cluster from an existing playbook:

[source,yaml]
----
- name: Deploy a workload role on a master host
  hosts: all
  become: true
  gather_facts: False
  tags:
    - step007
  roles:
    - { role: "{{ocp_workload}}", when: 'ocp_workload is defined' }
----
NOTE: You might want to change `hosts: all` to fit your requirements

