---
# Default variables that are defined by the playbook that will be deploying these roles
become_override: False
ocp_username: opentlc-mgr
silent: False

# The first user number to start with when creating projects
user_count_start: 1
# The last user number to start with when creating projects
# "num_users" is a global variable that specifies the total number of users AVAILABLE in the cluster
user_count_end: "{{user_count_start|int + num_users|int}}"

# NooBaa S3 information
ocp4_workload_rhte_analytics_data_ocp_workshop_noobaa_endpoint_url: "http://s3.openshift-storage.svc"

# RGW information
rgw_service_port: 80

ocp4_workload_rhte_analytics_data_ocp_workshop_namespace: opendatahub-workshop

## Open Data Hub
## Deploy the Open Data Hub CustomResource in the user project space,
##   after the project is setup and ODH ClusterServiceVersion has finished
#deploy_odh_cr: false
## Open Data Hub operator image
#odh_operator_image_repo: "quay.io/opendatahub/opendatahub-operator:v0.4.0"
## Registry and repistory for AICoE-JupyterHub images
## EXAMPLE: podman pull {{ jupyterhub_image_registry }}/{{ jupyterhub_image_repository }}:IMAGE:{{ jupyterhub_image_tag }}
#jupyterhub_image_registry: 'quay.io'
#jupyterhub_image_repository: 'odh-jupyterhub'
#jupyterhub_image_tag: 3.0.7-df59c25
#
# Custom notebook image source that will be used for the workshop
ocp4_workload_rhte_analytics_data_ocp_workshop_jupyter_notebook_imagestream_tag: "notebook-spark-2.3.2_hadoop-2.8.5"
ocp4_workload_rhte_analytics_data_ocp_workshop_jupyter_notebook_imagestream_image: "quay.io/odh-workshops/data-engineering-ml-workshop:{{ ocp4_workload_rhte_analytics_data_ocp_workshop_jupyter_notebook_imagestream_tag }}"
## Imagestream name for the custom workshop image
#workshop_jupyter_notebook_imagestream_name: data-engineering-spark-notebook
## Imagestream tag for the custom workshop image
#workshop_jupyter_notebook_imagestream_tag: "3.6"
#
## Command separated string list each git repo url to preload on the notebook pod when it spawns
ocp4_workload_rhte_analytics_data_ocp_workshop_preload_repos: "https://github.com/opendatahub-io/data-engineering-and-machine-learning-workshop"
#
## Amount of memory for the JupyterHub server
#jupyterhub_memory: "1Gi"
## Amount of cpu/memory for the spawned Jupyter Notebook pods
ocp4_workload_rhte_analytics_data_ocp_workshop_jupyter_notebook_cpu: "1"
ocp4_workload_rhte_analytics_data_ocp_workshop_jupyter_notebook_memory: "2Gi"
#
ocp4_workload_rhte_analytics_data_ocp_workshop_spark_configmap_template: "jupyterhub-spark-operator-configmap"
## Image to use for the Spark Cluster
ocp4_workload_rhte_analytics_data_ocp_workshop_spark_node_image: "quay.io/llasmith/openshift-spark:spark-2.3.2_hadoop-2.8.5"
#
## Number of Spark master nodes
ocp4_workload_rhte_analytics_data_ocp_workshop_spark_master_count: 1
## Amount of cpu/memory to Spark master node.
ocp4_workload_rhte_analytics_data_ocp_workshop_spark_master_memory: "2Gi"
ocp4_workload_rhte_analytics_data_ocp_workshop_spark_master_cpu: 1
#
## Number of Spark worker nodes
ocp4_workload_rhte_analytics_data_ocp_workshop_spark_worker_count: 2
## Amount of cpu/memory to allocate to each Spark node.
ocp4_workload_rhte_analytics_data_ocp_workshop_spark_worker_memory: "4Gi"
ocp4_workload_rhte_analytics_data_ocp_workshop_spark_worker_cpu: 1
#
## Path to append to env var PYTHONPATH for pyspark module
ocp4_workload_rhte_analytics_data_ocp_workshop_spark_pythonpath: "/opt/app-root/lib/python3.6/site-packages/pyspark/python/:/opt/app-root/lib/python3.6/site-packages/pyspark/python/lib/py4j-0.10.7-src.zip"
## PySpark submit args to be set as the env var SPARK_SUBMIT_ARGS
ocp4_workload_rhte_analytics_data_ocp_workshop_spark_submit_args: "--conf spark.cores.max=1 --conf spark.executor.instances=1 --conf spark.executor.memory=4G --conf spark.executor.cores=1 --conf spark.driver.memory=2G --packages com.amazonaws:aws-java-sdk:1.8.0,org.apache.hadoop:hadoop-aws:2.8.5 pyspark-shell"

validation_deploymentconfigs:
  - "jupyterhub"
  - "jupyterhub-db"

validation_deployments:
  - "grafana-deployment"
  - "grafana-operator"
  - "odh-dashboard"
  - "prometheus-operator"
  - "seldon-controller-manager"
  - "spark-operator"

validation_statefulsets:
  - "prometheus-prometheus"

ocs_namespace: "openshift-storage"
