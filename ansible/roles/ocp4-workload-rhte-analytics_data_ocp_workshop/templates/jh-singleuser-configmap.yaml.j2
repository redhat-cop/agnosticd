apiVersion: v1
data:
  jupyterhub-singleuser-profiles.yaml: |
    profiles:
    - name: globals
      env:
        - name: S3_ENDPOINT_URL
          value: s3.odh.com
        - name: JUPYTER_PRELOAD_REPOS
          value: {{ ocp4_workload_rhte_analytics_data_ocp_workshop_preload_repos }}
      resources:
        requests:
          memory: 1Gi
          cpu: 500m
        limits:
          memory: 2Gi
          cpu: 1

    - name: Spark Notebook
      images:
      - 's2i-spark-minimal-notebook:3.6'
      - 's2i-spark-scipy-notebook:3.6'
      - 's2i-spark-minimal-notebook:py36-spark2.4.5-hadoop2.7.3'
      env:
        - name: PYSPARK_SUBMIT_ARGS
          value: '--conf spark.cores.max=2 --conf spark.executor.instances=2 --conf spark.executor.memory=1G --conf spark.executor.cores=1 --conf spark.driver.memory=2G --packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.3 pyspark-shell'
        - name: PYSPARK_DRIVER_PYTHON
          value: 'jupyter'
        - name: PYSPARK_DRIVER_PYTHON_OPTS
          value: 'notebook'
        - name: SPARK_HOME
          value: '/opt/app-root/lib/python3.6/site-packages/pyspark/'
        - name: PYTHONPATH
          value: '$PYTHONPATH:/opt/app-root/lib/python3.6/site-packages/:/opt/app-root/lib/python3.6/site-packages/pyspark/python/:/opt/app-root/lib/python3.6/site-packages/pyspark/python/lib/py4j-0.8.2.1-src.zip'
      services:
        spark:
          resources:
          - name: spark-cluster-template
            path: notebookPodServiceTemplate
          - name: spark-cluster-template
            path: sparkClusterTemplate
          configuration:
            worker_nodes: '2'
            master_nodes: '1'
            master_memory_limit: '2Gi'
            master_cpu_limit: '1'
            master_memory_request: '2Gi'
            master_cpu_request: '1'
            worker_memory_limit: '2Gi'
            worker_cpu_limit: '1'
            worker_memory_request: '2Gi'
            worker_cpu_request: '1'
            spark_image: 'quay.io/radanalyticsio/openshift-spark-py36:2.4.5-2'
          return:
            SPARK_CLUSTER: 'metadata.name'

    sizes:
    - name: Small
      resources:
        requests:
          memory: 1Gi
          cpu: 1
        limits:
          memory: 2Gi
          cpu: 2
    - name: Medium
      resources:
        requests:
          memory: 2Gi
          cpu: 2
        limits:
          memory: 4Gi
          cpu: 4
    - name: Large
      resources:
        requests:
          memory: 4Gi
          cpu: 4
        limits:
          memory: 8Gi
          cpu: 8
kind: ConfigMap
metadata:
  labels:
    component.opendatahub.io/name: jupyterhub
    opendatahub.io/component: "true"
  name: jupyter-singleuser-profiles
  namespace: {{ ocp4_workload_rhte_analytics_data_ocp_workshop_namespace }}
