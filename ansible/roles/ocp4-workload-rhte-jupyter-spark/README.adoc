= Jupyter and Spark Workload

This workload creates builds for Spark and Jupyter on OpenShift 4 cluster. 

== Deploy the workload
[source, bash]
----
ansible-playbook -i "bastion.${GUID}.${BASE_DOMAIN}", ./ansible/configs/ocp-workloads/ocp-workload.yml \
    -e"ansible_ssh_private_key_file=${ANSIBLE_USER_KEY_FILE}" \
    -e"ansible_user=${ANSIBLE_USER}" \ 
    -e"ocp_workload=ocp4-workload-rhte-jupyter-spark" \ 
    -e"silent=False" \
    -e"ACTION=create" \
    -e @./secret.yaml \ <1>
    -e @./workload_vars.yaml <2>
----
<1> This is the same file you used while deploying OCP cluster using agnosticd. Your AWS credentials go in this file

Optionally, you may choose to override following default variables.

=== Variables
[source, yaml]
----
jupyter_spark_namespace: my-analytics
----

== Delete the workload
----
ansible-playbook -i "bastion.${GUID}.${BASE_DOMAIN}", ./ansible/configs/ocp-workloads/ocp-workload.yml \
    -e"ansible_ssh_private_key_file=${ANSIBLE_USER_KEY_FILE}" \
    -e"ansible_user=${ANSIBLE_USER}" \ 
    -e"ocp_workload=ocp4-workload-rhte-jupyter-spark" \ 
    -e"silent=False" \
    -e"ACTION=remove" \
    -e @./secret.yaml \ <1>
    -e @./workload_vars.yaml <2>
----
<1> This is the same file you used while deploying OCP cluster using agnosticd. Your AWS credentials go in this file
