---

# TODO: Make this GPU agnostic, building it initially around Nvidia and CUDA
# TODO: Extract vars to defaults/main.yml

- name: Set CUDA related vars for all users
  ansible.builtin.blockinfile:
    path: /etc/environment
    block: |
      CUDA_HOME={{ ai_setup_ilab_cuda_home }}
      LD_LIBRARY_PATH={{ ai_setup_ilab_cuda_lib_path }}
    marker: "# {mark} ANSIBLE MANAGED BLOCK"
    create: true

- name: Set CUDA related vars etc in .bashrc
  ansible.builtin.blockinfile:
    path: "/home/{{ ai_setup_ilab_user }}/.bashrc"
    block: |
      export CUDA_HOME={{ ai_setup_ilab_cuda_home }}
      export LD_LIBRARY_PATH={{ ai_setup_ilab_cuda_lib_path }}
      export PATH=$PATH:/usr/local/cuda/bin
      {% if not ai_setup_ilab_summit2024_mode %}
      echo "Welcome to the InstructLab VM"
      echo
      echo "- To get started see https://github.com/instructlab"
      echo "- To chat: ilab chat"
      echo
      {% endif %}
    marker: "# {mark} ANSIBLE MANAGED BLOCK"
    create: true
  become_user: "{{ ai_setup_ilab_user | default('instruct') }}"


- name: Setup AI developer packages
  ansible.builtin.dnf:
    name: "{{ package }}"
    state: present
  loop: "{{ ai_setup_ilab_developer_packages }}"
  loop_control:
    loop_var: package

- name: Set system default Python version, to 3.11
  ansible.builtin.alternatives:
    name: python
    link: /usr/bin/python3
    path: /usr/bin/python3.11

# TODO: Extract vars to defaults/main.yml and make more generic
- name: Setup the users InstructLab environment
  block:

    - name: Clone InstructLab repository
      ansible.builtin.git:
        repo: "{{ ai_setup_ilab_repo_url }}"
        dest: "{{ ai_setup_ilab_install_path_base }}/instructlab"
        version: "main"
        clone: true
        update: true
      register: r_git_clone_instructlab

    - name: Clone taxonomy repository if not present
      when: not ai_setup_ilab_summit2024_mode | bool
      ansible.builtin.git:
        repo: "{{ ai_setup_ilab_taxonomy_repo_url }}"
        dest: "{{ ai_setup_ilab_install_path_base }}/taxonomy"
        version: "main"
        clone: true
        update: true
      register: r_git_clone_taxonomy

  become_user: "{{ ai_setup_ilab_user | default('instruct') }}"

# TODO: THis python setup seems hideous but it works, need to find a better way
# TODO: Remove hard paths etc

- name: Venv and iLab Python setup
  block:

    - name: Setup a Python 3.11 virtual environment
      ansible.builtin.command:
        cmd: "python3.11 -m venv /home/{{ ai_setup_ilab_user }}/instructlab/venv"
      args:
        creates: "/home/{{ ai_setup_ilab_user }}/instructlab/venv"

    - name: Upgrade venv pip
      ansible.builtin.command:
        cmd: "/home/{{ ai_setup_ilab_user }}/instructlab/venv/bin/python -m pip install --upgrade pip"

    - name: Install InstructLab package
      when: r_git_clone_instructlab.changed
      ansible.builtin.command:
        cmd: >-
          /home/{{ ai_setup_ilab_user }}/instructlab/venv/bin/pip 
          install git+https://github.com/instructlab/instructlab.git@stable

    - name: Setup llama-cpp-python with CUDA Support
      ansible.builtin.command:
        cmd: >-
            /home/{{ ai_setup_ilab_user }}/instructlab/venv/bin/pip install --force-reinstall 
            --no-cache-dir "llama-cpp-python[server]=={{ ai_setup_ilab_llama_cpp_python_version | default('0.2.75') }}"
      environment:
        CUDACXX: /usr/local/cuda-12/bin/nvcc 
        CMAKE_ARGS: "-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=all-major" 
        FORCE_CMAKE: 1 

    - name: Initialize InstructLab non-interactively
      ansible.builtin.shell: >-
        source {{ ai_setup_ilab_install_path_base }}/instructlab/venv/bin/activate && 
        ilab init --non-interactive --model-path instructlab/models/merlinite-7b-lab-Q4_K_M.gguf --taxonomy-path taxonomy 
        && ilab download
      args:
        chdir: "{{ ai_setup_ilab_install_path_base }}/instructlab"

  become_user: "{{ ai_setup_ilab_user | default('instruct') }}"

- name: Setup AI Developer Preview with Mixtral and Granite and ai-lab images
  when: ai_setup_ilab_developer_preview | default(false) | bool
  block:

    # TODO:
    # loop the LLMs
    # Make the LLMs a list in defaults/main.yml so we can drive via AgnosticV
    # But need this out the door today!

    - name: Load Mixtral LLM via ilab
      when: not ai_setup_ilab_summit2024_mode | bool
      ansible.builtin.shell: >-
        source {{ ai_setup_ilab_install_path_base }}/instructlab/venv/bin/activate && 
        ilab download --repository mistralai/Mixtral-8x7B-Instruct-v0.1 
        --hf-token {{ huggingface_token }}
      args:
        chdir: "{{ ai_setup_ilab_install_path_base }}/instructlab"

    - name: Load Granite LLM via ilab
      ansible.builtin.shell: >-
        source {{ ai_setup_ilab_install_path_base }}/instructlab/venv/bin/activate && 
        ilab download  --repository ibm/granite-7b-base
        --hf-token {{ huggingface_token }}
      args:
        chdir: "{{ ai_setup_ilab_install_path_base }}/instructlab"

      #TODO: move to Defaults/main.yml, drive from AgV   

    - name: Podman Pull  
      containers.podman.podman_image:
        name: "quay.io/{{ __image }}"
        username: "{{ quay_io_username }}"
        password: "{{ quay_io_password }}"
      loop: 
        - "ai-lab/instructlab-nvidia:latest"
        - "ai-lab/vllm:latest"
        - "ai-lab/deepspeed-trainer:latest"
      loop_control:
        loop_var: __image

  become_user: "{{ ai_setup_ilab_user | default('instruct') }}"
# End of AI Developer Preview block

- name: Add Summit 2024 files and assets  
  when: ai_setup_ilab_summit2024_mode | default(false) | bool
  block:

    - name: Create ilab directories
      ansible.builtin.file:
        path: "{{ __directory }}"
        state: directory
        owner: "{{ ai_setup_ilab_user | default('instruct') }}"
        mode: u=rwx,g=rx,o=rx
      loop:
        - "~/files"
        -  "~/instructlab/models"
      loop_control:
        loop_var: __directory

    - name: Create qna sample file
      ansible.builtin.copy:
        src: qna.yaml
        dest: "~/files/qna.yaml"
        mode: u=rw,g=rw,o=

    # - name: Load Granite LLM via ilab
    #   ansible.builtin.shell: >-
    #     source {{ ai_setup_ilab_install_path_base }}/instructlab/venv/bin/activate && 
    #     ilab download  --repository instructlab/granite-7b-lab-GGUF 
    #     --filename=granite-7b-lab-Q4_K_M.granite-7b-lab-GGUF
    #   args:
    #     chdir: "{{ ai_setup_ilab_install_path_base }}/instructlab"

    - name: Fetch the Summit LLM via http from S3 and move to models
      ansible.builtin.get_url:
        url:  https://gpte-public.s3.amazonaws.com/llms/ggml-ilab-pretrained-Q4_K_M.gguf
        dest: "~/instructlab/models/ggml-ilab-pretrained-Q4_K_M.gguf"
        mode: u=rw,g=rw,o=

  become_user: "{{ ai_setup_ilab_user | default('instruct') }}"

- name: Automatically activate venv at login via .bashrc
  when: not ai_setup_ilab_summit2024_mode | bool
  ansible.builtin.lineinfile:
    path: "/home/{{ ai_setup_ilab_user }}/.bashrc"
    line: 'source instructlab/venv/bin/activate'
    create: true
    state: present
    insertafter: EOF

  become_user: "{{ ai_setup_ilab_user | default('instruct') }}"
  become: true
