apiVersion: metering.openshift.io/v1alpha1
kind: Metering
metadata:
  name: "operator-metering"
  namespace: "{{ _metering_namespace }}"
spec:
  reporting-operator:
    spec:
      route:
        enabled: true
      authProxy:
        enabled: true

        # htpasswdData can contain htpasswd file contents for allowing auth
        # using a static list of usernames and their password hashes.
        #
        # username is 'testuser' password is 'password123'
        # generated htpasswdData using: `htpasswd -nb -s testuser password123`
        # htpasswdData: |
        #   testuser:{SHA}y/2sYAj5yrQIN4TL0YdPdmGNKpc=
        #
        # change REPLACEME to the output of your htpasswd command
        #htpasswdData: |
        #  REPLACEME
        # cookieSeed is used to protect the cookie created if accessing the API
        # via your browser.
        #
        # generate a 32 character random string using a command of your choice,
        # for example: `openssl rand -base64 32 | head -c32; echo`
        #
        # change REPLACEME to the output of your command
        #cookieSeed: "REPLACEME"
        cookieSeed: "{{ 65535 | random | hash('md5') }}"

        # Enables authenticating using a bearer token from a serviceAccount or user.
        # It must have have one of the following roles:
        # "report-exporter", "reporting-admin" or "reporting-viewer"
        # or it must have permissions granting "GET reports/export":
        # the export subresource of "reports".
        subjectAccessReviewEnabled: true
        delegateURLsEnabled: true
      # More CPU is for ensuring it never get's throttled during metrics
      # importing when backlogged.
      resources:
        requests:
          memory: "500Mi"
          cpu: "250m"
        limits:
          memory: "500Mi"
          cpu: 1

  presto:
    spec:
      presto:
        coordinator:
          resources:
            requests:
              memory: "4Gi"
              cpu: "4"
            limits:
              memory: "4Gi"
              cpu: "8"
        worker:
          replicas: 1
          resources:
            requests:
              memory: "8Gi"
              cpu: "4"
            limits:
              memory: "16Gi"
              cpu: "8"
      hive:
        metastore:
          resources:
            requests:
              memory: "2Gi"
              cpu: "1"
            limits:
              memory: "2Gi"
              cpu: "4"
          storage:
            size: "10Gi"
        server:
          resources:
            requests:
              memory: "500Mi"
              cpu: "500m"
            limits:
              memory: "1Gi"
              cpu: 1
  hdfs:
    spec:
      datanode:
        resources:
          requests:
            memory: "750Mi"
            cpu: "250m"
          limits:
            memory: "1.5Gi"
            cpu: "250m"
        storage:
          size: "20Gi"
      namenode:
        resources:
          requests:
            memory: "750Mi"
            cpu: "250m"
          limits:
            memory: "1.5Gi"
            cpu: "250m"
        storage:
          size: "20Gi"

