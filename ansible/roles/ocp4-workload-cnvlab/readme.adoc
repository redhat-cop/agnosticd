= ocp4-workload-cnvlab - OpenShift virtualisation (CNV) Hands on Lab Workload for agnosticd

== Role overview

This is a supplementary workload for the ocp4-cluster workload, i.e. this expects the standard ocp4-cluster workload to be
deployed first, with this one an add-on to provide capabilities to host the OpenShift virtualisation (CNV) hands-on lab.

If you want to test with this you simply need to deploy the ocp4-cluster workload first, and then deploy this workload
on-top using the generic ocp-workload playbook as follows:

== Create

.Example: `myvars.yml`
[source,yaml]
----
cloud_provider: ocp
env_type: ocp4-cluster

ocp_workloads:
  - ocp4-workload-cnvlab

target_host: bastion.dev.mycluster.mydomain.com

#become_override: false

# If the ocp4-workload supports it, you should specify the OCP user:
# ocp_username: myuser

# Usually the ocp4-workloads want a GUID also:
# guid: changeme
----

.Run
[source,shell]
----
cd agnosticd/ansible
ansible-playbook main.yml -e @myvars.yml
----

== Delete

Just run the following:

[source,shell]
----
cd agnosticd/ansible
ansible-playbook destroy.yml -e @myvars.yml
----

It will run the ocp4-workload role with `ACTION=destroy`.


== Lifecycle

The link:../../lifecycle_entry_point.yml[`lifecycle_entry_point.yml`] playbook can be used as well.

It will just run the workload passing the `ACTION` variable. Just make sure  to implement the action `stop`, `start`, `status` in the ocp4-workloads.

== `target_host` variable

This variable correspond to the bastion host used to run `oc` commands or `k8s` ansible task.

You can specify the target host in 2 different ways.

=== As an hostname

If you want to just specify:

[source,yaml]
----
target_host: bastion.dev.mycluster.mydomain.com
----

Then you need to configure ssh properly to be able to connect to that host.
Just make sure the command `ssh bastion.dev.mycluster.mydomain.com` works.

=== As a dictionary

You can specify the bastion host using a dictionary. This is useful is you need to specify the user, port, ssh_key to use, etc.

[source,yaml]
----
target_host:
  ansible_host: bastion.rdo.students.osp.opentlc.com
  ansible_port: 22
  ansible_user: cloud-user
  #ansible_ssh_private_key_content: "{{ ssh_private_key_content }}"
  ansible_ssh_private_key_file: ~/.ssh/admin_key.pem
  #ansible_ssh_extra_args:  ...
----

NOTE: you can add the `ansible_ssh_private_key_content` to a secret file or a vault. The config will create the key using that content in the directory `output_dir/` and use it to connect to the bastion. The key will then be deleted when the playbook ends, see link:cleanup.yml[`cleanup.yml`].


== `ocp-workload.yml` file

This file is for reference only.

It is still used in some of our deployment scripts.

It can be useful if you want to specify the bastion to connect to by passing it as the inventory:

[source,shell]
----
ansible-playbook -i $TARGETHOST, ocp-workload.yml -e ocp_workload=ocp-workload-fuse-ignite
----

== FAQ

. But i want to run my workload as root!

Just use the var `become_override`. Set it to true in your var file. Most ocp-workloads implement that variable.

.extract of `main.yml` in ocp-workload
[source,yaml]
----
- name: Running Workload Tasks
  import_tasks: ./workload.yml
  become: "{{ become_override | bool }}"
  when: ACTION == "create" or ACTION == "provision"
----
