---
# Implement your Workload deployment tasks here
- name: Setting up workload for user
  debug:
    msg: "Setting up workload for user ocp_username = {{ ocp_username }}"

- name: Run shell 'oc' command to retrieve the cluster subdomain
  shell: "oc whoami --show-server | cut -d'.' -f 2,3,4,5 | cut -d':' -f 1"
  register: r_shell

- set_fact: subdomain_base={{ r_shell.stdout_lines[0] }}
- set_fact: ocp_apps_domain=apps.{{ subdomain_base }}

###
# Project Mercury users configuration
# ---
# Skip in case OAuth/htpasswd is not yet configured in the cluster

- name: "Project Mercury :: Check if cluster OAuth is configured"
  k8s_info:
    api_version: v1
    kind: Secret
    name: htpasswd-secret
    namespace: openshift-config
  register: r_htpasswd

- name: "Project Mercury :: Check if './files/users.htpasswd' exist to update cluster OAuth"
  when: r_htpasswd | d('') | length > 0
  block:

  - name: "Try copying './files/users.htpasswd' file onto the target filesystem"
    copy:
      src: "/secrets/users.htpasswd"
      dest: "/home/{{ ansible_user }}/users.htpasswd"
      owner: "{{ ansible_user }}"
      mode: 0664
    register: r_htpasswd_copy
    ignore_errors: true

  - name: "Generate htpasswd-secret resource definition Yaml using 'oc command'"
    when:
      - r_htpasswd_copy is defined
      - not r_htpasswd_copy.failed | d(False) | bool
    command: "oc create secret generic htpasswd-secret -n openshift-config --from-file=htpasswd=/home/{{ ansible_user }}/users.htpasswd --dry-run -o yaml"
    register: r_htpasswd_res_yaml

  - name: Create htpasswd-secret from htpasswd file and generated Yaml description
    when:
      - r_htpasswd_copy is defined
      - r_htpasswd_res_yaml is defined
      - r_htpasswd_res_yaml | d('') | length > 0
    k8s:
      state: present
      merge_type:
        - strategic-merge
        - merge
      definition: "{{ r_htpasswd_res_yaml.stdout }}"

  - name: Delete the users.htpasswd file generated on the target filesystem
    when:
      - r_htpasswd_copy is defined
      - not r_htpasswd_copy.failed | bool
    file:
      state: absent
      dest: "/home/{{ ansible_user }}/users.htpasswd"

# Sets up the Cluster auto-scaling
# - name: 'Project Mercury :: Configure the OCP4 cluster autoscaler'
#   include_role:
#     name: ocp4-workload-cluster-autoscale
#   vars:
#     become_override: yes
#     _autoscale_machineset_min_replicas: "{{ autoscale_machineset_min_replicas }}"
#     _autoscale_machineset_max_replicas: "{{ autoscale_machineset_max_replicas }}"
#     _autoscale_cluster_max_replicas: "{{ autoscale_cluster_max_replicas }}"
#     _autoscale_cluster_enable_scaledown: "{{ autoscale_cluster_enable_scaledown }}"

# Sets up the Cluster with User quota

###
# Projects
- name: "Project Mercury :: Add new project named 'mercury'"
  include_tasks: create_project.yaml
  vars:
    user: "{{ ocp_username }}"
    name: "mercury"
    display_name: "Project Mercury"

###
# OpenShift Pipelines operator install
- name: 'Project Mercury :: Install the OpenShift Pipelines operator task'
  include_role:
    name: ocp4-workload-pipelines
  vars:
    become_override: yes

###
# OpenShit ServiceMesh operator install
# - name: 'Project Mercury :: Install the OpenShift ServiceMesh operator task'
#   include_role:
#     name: ocp4-workload-servicemesh
#   vars:
#     become_override: yes

###
# 3scale Operator install
# ---
- name: 'Project Mercury :: Setting up the 3scale in the cluster'
  when:
    - ocp4_workload_mercury_threescale_registry_token is defined
  block:

  # create the "3scale" project and namespace
  - name: Create '3scale' project
    include_tasks: create_project.yaml
    vars:
      user: "{{ ocp_username }}"
      name: "3scale"
      display_name: "3scale Operator"

  # Sets up the RWX storage provider required for 3scale
  - name: Configure NFS Server workload to provide RWX storage class
    include_role:
      name: ocp4-workload-nfs-server
    vars:
      become_override: yes
      _nfs_provided_storage_class: "{{ nfs_provided_storage_class }}"
      _nfs_pvc_size: "{{ nfs_pvc_size }}"
      _nfs_pv_provided_size: "{{ nfs_pv_provided_size }}"

  # install 3scale operator
  - name: install 3scale operator
    include_tasks: install_3scaleoperator.yaml

  # deploy staging API manager instance
  - name: Create 3scale API Manager instance Staging
    vars:
      _3scale_apimanager_instancename: staging
    k8s:
      state: present
      merge_type:
      - strategic-merge
      - merge
      definition: "{{ lookup('template', item ) | from_yaml }}"
    loop:
      - ./templates/3scale-operator-3-apimanager.yaml.j2
    
    # wait to APIManager resource creation
    - name: Wait for 3scale pods to be ready
      k8s_facts:
        api_version: v1
        kind: DeploymentConfig
        namespace: 3scale
        name: apicast-production
      register: r_dc
      until:
        - r_dc is defined
        - r_dc.resources is defined
        - r_dc.resources | list | length > 0
        - r_dc.resources[0].status is defined
        - r_dc.resources[0].status.readyReplicas is defined
        - r_dc.resources[0].status.readyReplicas | int >= 1
      retries: 30
      delay: 10


###
# Nexus GPTE's operator install and server deployment
- name: 'Project Mercury :: Install the Nexus operator and deploy its server task'
  include_role:
    name: ocp4-workload-nexus-operator
  vars:
    become_override: yes


# Leave this as the last task in the playbook.
- name: workload tasks complete
  debug:
    msg: "Workload Tasks completed successfully."
  when: not silent|bool
