= ocp4-workload-eap8-workshop - Deploy EAP7 to EAP8 Workshop into OCP4

== Role overview

* This role deploys the workshop into an OpenShift 4 Cluster. It depends on infrastructure nodes existing. It consists of the following tasks files:
** Tasks: link:./tasks/pre_workload.yml[pre_workload.yml] - Sets up an
 environment for the workload deployment.
*** Debug task will print out: `pre_workload Tasks completed successfully.`

** Tasks: link:./tasks/workload.yml[workload.yml] - Used to deploy the guides and dev spaces
*** Debug task will print out: `workload Tasks completed successfully.`

** Tasks: link:./tasks/post_workload.yml[post_workload.yml] - Used to
 configure the workload after deployment
*** This role doesn't do anything here
*** Debug task will print out: `post_workload Tasks completed successfully.`

** Tasks: link:./tasks/remove_workload.yml[remove_workload.yml] - Used to
 delete the workload
*** This role removes the logging deployment and project but not the operator configs
*** Debug task will print out: `remove_workload Tasks completed successfully.`

== Review the defaults variable file

* This file link:./defaults/main.yml[./defaults/main.yml] contains all the variables you need to define to control the deployment of your workload.
* The variable *ocp_username* is mandatory to assign the workload to the correct OpenShift user.
* A variable *silent=True* can be passed to suppress debug messages.
* You can modify any of these default values by adding `-e "variable_name=variable_value"` to the command line

=== Deploy a Workload with the `ocp-workload` playbook [Mostly for testing]

Deploy an RHPDS OCP 4.13 cluster

Login to the bastion host and add your public key to the ~/.ssh/authorized_keys file


Set environment variables with a script e.g.
export TARGET_HOST="bastion.vmlrl.sandbox1296.opentlc.com"
export OCP_USERNAME="lab-user"
export WORKLOAD="ocp4-workload-eap8-workshop"
export GUID=vmlrl
export USER_COUNT=1
export SSH_KEY=~/.ssh/id_rsa
export AWS_REGION=us-east-1
export MODULE_TYPE="m1"

Set environment variables for HTTP downloads using values from cloudfront

export HTTP_USERNAME=
export HTTP_PASSWORD=
export HTTP_URL=https://xxx.domain.com 

Run the ansible playbook

ansible-playbook -i ${TARGET_HOST}, ./configs/ocp-workloads/ocp-workload.yml \
    -e"ansible_ssh_private_key_file=${SSH_KEY}" \
    -e"ansible_user=${OCP_USERNAME}" \
    -e"ocp_username=${OCP_USERNAME}" \
    -e"ocp_workload=${WORKLOAD}" \
    -e"silent=False" \
    -e"guid=${GUID}" \
    -e"aws_region=${AWS_REGION}" \
    -e"num_users=${USER_COUNT}" \
    -e"module_type=${MODULE_TYPE}" \
    -e"subdomain_base=${TARGET_HOST}" \
    -e"HTTP_USERNAME=${HTTP_USERNAME}" \
    -e"HTTP_PASSWORD=${HTTP_PASSWORD}" \
    -e"HTTP_URL=${HTTP_URL}" \
    -e"ACTION=create"
----

=== To Delete an environment


# a TARGET_HOST is specified in the command line, without using an inventory file
ansible-playbook -i ${TARGET_HOST}, ./configs/ocp-workloads/ocp-workload.yml \
    -e"ansible_ssh_private_key_file=${SSH_KEY}" \
    -e"ansible_user=${OCP_USERNAME}" \
    -e"ocp_username=${OCP_USERNAME}" \
    -e"ocp_workload=${WORKLOAD}" \
    -e"silent=False" \
    -e"guid=${GUID}" \
    -e"aws_region=${AWS_REGION}" \
    -e"num_users=${USER_COUNT}" \
    -e"module_type=${MODULE_TYPE}" \
    -e"subdomain_base=${TARGET_HOST}" \
    -e"ACTION=remove"
----

