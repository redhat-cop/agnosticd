---
- name: "Ensuring AWS credentials are present"
  fail:
    msg: "This workload requires AWS credentials defined. Exiting..."
  when: aws_secret_access_key is not defined or aws_access_key_id is not defined or aws_region is not defined

- block:
  - name: Checking if Ceph PVCs exist
    k8s_facts:
      api_version: v1
      kind: PersistentVolumeClaim
    register: ceph_pvcs
  - set_fact:
      found_scs: "{{ ceph_pvcs | json_query('resources[*].spec.storageClassName') | list | unique }}"
      csi_rbd: "csi-rbd"
      csi_cephfs: "csi-cephfs"
  - fail:
      msg: "Ceph provisioned PVCs found. Please remove the PVCs provisioned by Ceph and try removing again..."
    when: csi_rbd in found_scs or csi_cephfs in found_scs
  when: ceph_workload_destroy | bool

- name: Discovering worker nodes
  k8s_facts:
    api_version: machine.openshift.io/v1beta1
    kind: Machine
    label_selectors:
    - machine.openshift.io/cluster-api-machine-role = worker
    namespace: "{{ ceph_mahineset_namespace }}"
  register: machines

- name: Registering target worker nodes
  set_fact:
    ceph_worker_nodes: |
      {% set workers = [] -%}
      {% for machine in machines['resources'] -%}
        {% set ignored = workers.extend([{'name' : machine['status']['providerStatus']['instanceId'], 'aZone': machine['spec']['providerSpec']['value']['placement']['availabilityZone']}]) -%}
      {%- endfor %}
      {{ workers }}
    ceph_cluster_id: "{{ machines['resources'][0]['metadata']['labels']['machine.openshift.io/cluster-api-cluster']  }}"

- fail:
    msg: "Less than 3 worker nodes detected. Cannot install Ceph..."
  when: ceph_worker_nodes | length < 3

- block:
  - name: "Creating temporary directory for VirtualEnv"
    tempfile:
      state: directory
    register: ceph_workload_venv_path

  - name: "Creating virtualenv in temporary location"
    pip:
      name: "{{ item }}"
      chdir: "{{ ceph_workload_venv_path.path }}"
      virtualenv: "{{ ceph_workload_venv_path.path }}"
    loop:
    - boto
    - boto3
    - ansible

  - name: "Copying AWS helper scripts"
    synchronize:
      src: "{{ role_path }}/files/aws_helper.yaml"
      dest: "{{ ceph_workload_venv_path.path }}/aws_helper.yaml"

  - name: "Sanitize worker list prior passing to AWS helper script"
    set_fact:
      ceph_worker_nodes_sane: "{{ ceph_worker_nodes | to_json }}"

  - name: "Running AWS helper scripts"
    shell: |
      ./bin/ansible-playbook aws_helper.yaml \
      -e aws_access_key_id={{ aws_access_key_id }} \
      -e aws_secret_access_key={{ aws_secret_access_key }} \
      -e aws_region={{ aws_region }} \
      -e ceph_cluster_id={{ ceph_cluster_id }} \
      -e ceph_workload_destroy={{ ceph_workload_destroy }} \
      --extra-vars '{'ceph_worker_nodes':{{ ceph_worker_nodes_sane }} }' \
    args:
      chdir: "{{ ceph_workload_venv_path.path }}"
