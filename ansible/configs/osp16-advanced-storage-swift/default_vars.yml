guid: CHANGEME # Your Global UNIQUE Identifier

################
### Env vars ###
################

env_type: osp-advanced-storage-swift # Name of config to deploy
cloud_provider: osp # Which AgnosticD Cloud Provider to use

ansible_user: cloud-user

email: example@example.com # User info for notifications
output_dir: /tmp/output_dir # Writable working scratch directory
admin_user: "{{ guid }}-user" # User created by the project. Leave as {{ guid }}-user
student_name: "{{ guid }}-user" # This will be used to create a student login ID
# Auto-generated by default
#student_password: "r3dh4t1!"             # Customize the student password here. Keep in mind these systems may be public facing.
install_student_user: true

default_metadata:
  owner: "{{ email | default('unknownuser') }}"
  Project: "{{ project_tag }}"
  env_type: "{{ env_type }}"
multi_network: true
multi_network_primary: "{{ guid }}-public-network"

osp_migration_report_labconsole: true
osp_migration_labconsole_url: https://console.apps.open.redhat.com/

ansible_ssh_private_key_file: ~/.ssh/{{key_name}}.pem

########################
## Quotas             ##
########################

quota_networks: 10
quota_subnets: 10

########################
## Environment Images ##
########################

__allinone_instance_image: "{{ allinone_instance_image }}"
__ipmihost_instance_image: "{{ ipmihost_instance_image }}"
__workstation_instance_image: "{{ workstation_instance_image }}"

__stor01_instance_image: "{{ stor01_instance_image }}"
__stor02_instance_image: "{{ stor02_instance_image }}"
__stor03_instance_image: "{{ stor03_instance_image }}"
__proxy01_instance_image: "{{ proxy01_instance_image }}"
__proxy02_instance_image: "{{ proxy02_instance_image }}"
__haproxy01_instance_image: "{{ haproxy01_instance_image }}"

########################
## Environment Sizing ##
########################
#
__workstation_instance_flavor:
  osp: "{{ workstation_instance_flavor  }}"

__ipmihost_instance_flavor:
  osp: "{{ ipmihost_instance_flavor  }}"

__allinone_instance_flavor:
  osp: "{{ allinone_instance_flavor  }}"

__stor01_instance_flavor:
  osp: "{{ stor01_instance_flavor  }}"

__stor02_instance_flavor:
  osp: "{{ stor02_instance_flavor  }}"

__stor03_instance_flavor:
  osp: "{{ stor03_instance_flavor  }}"

__proxy01_instance_flavor:
  osp: "{{ proxy01_instance_flavor  }}"

__proxy02_instance_flavor:
  osp: "{{ proxy02_instance_flavor  }}"

__haproxy01_instance_flavor:
  osp: "{{ haproxy01_instance_flavor  }}"

# Networks
# A list of the private networks and subnets to create in the project
# You can create as many as you want, but at least one is required.
# Use the name of the networks where appropriate in the instance list
networks:
  - name: storage
    shared: "false"
    subnet_cidr: 192.168.99.0/24
    enable_dhcp: True
    gateway_ip: 192.168.99.1
    allocation_start: 192.168.99.81
    allocation_end: 192.168.99.251
    dns_nameservers: [8.8.8.8]
    create_router: false
    router_network: public

  - name: admin
    shared: "false"
    subnet_cidr: 172.16.7.0/24
    enable_dhcp: True
    gateway_ip: 172.16.7.1
    allocation_start: 172.16.7.81
    allocation_end: 172.16.7.251
    dns_nameservers: []
    create_router: false
    router_network: public

  - name: public
    shared: "false"
    subnet_cidr: 192.168.56.0/24
    gateway_ip: 192.168.56.1
    allocation_start: 192.168.56.81
    allocation_end: 192.168.56.249
    dns_nameservers: [8.8.8.8]
    create_router: true
    router_network: public

##### Security Groups ###
#      - {port_range_max: 22, port_range_min: 22, protocol: tcp, remote_ip_prefix: 0.0.0.0/0}
#      - {port_range_max: 80, port_range_min: 80, protocol: tcp, remote_ip_prefix: 0.0.0.0/0}
#      - {port_range_max: 6080, port_range_min: 6080, protocol: tcp, remote_ip_prefix: 0.0.0.0/0}

security_groups:
  - name: workstationSG
    rules:
      - name: workstationSSHPublic
        description: "SSH public"
        from_port: 22
        to_port: 22
        protocol: tcp
        cidr: "0.0.0.0/0"
        rule_type: Ingress
      - name: workstationWEBPublic
        description: "WEB public"
        from_port: 80
        to_port: 80
        protocol: tcp
        cidr: "0.0.0.0/0"
        rule_type: Ingress
      - name: workstationVNCPublic
        description: "VNC public"
        from_port: 6080
        to_port: 6080
        protocol: tcp
        cidr: "0.0.0.0/0"
        rule_type: Ingress
      - name: workstationStorage
        description: "Storage private"
        from_port: 1
        to_port: 65535
        protocol: tcp
        cidr: "172.18.0.0/24"
        rule_type: Ingress

# Environment Instances
instances:
  - name: "workstation"
    count: 1
    unique: true
    public_dns: true
    dns_loadbalancer: false
    image_id: "{{ __workstation_instance_image }}"
    flavor: "{{ __workstation_instance_flavor }}"
    userdata: |
      ssh_pwauth:   true
    metadata:
      - AnsibleGroup: "bastions"
      - ostype: "linux"
      - instance_filter: "{{ env_type }}-{{ email }}"
      - guid: "{{ guid }}"
      - env_type: "{{ env_type }}"
    tags:
      - key: "AnsibleGroup"
        value: "bastions"
      - key: "ostype"
        value: "linux"
      - key: "instance_filter"
        value: "{{ env_type }}-{{ email }}"
    networks:
      - public
      - admin
      - storage
    floating_ip: true
    floating_ip_network: "public"
    security_groups:
      - workstationSG
    fixed_ips:
      public: 192.168.56.252
      admin: 172.16.7.252
      storage: 192.168.99.252

  - name: "ipmi-host"
    count: 1
    unique: true
    public_dns: false
    dns_loadbalancer: false
    image_id: "{{ __ipmihost_instance_image }}"
    flavor: "{{ __ipmihost_instance_flavor }}"
    userdata: |
      ssh_pwauth:   true
      runcmd:
        - sleep 180
      chpasswd:
         list: |
           root:r3dh4t1!
         expire: False
    metadata:
      - ostype: "linux"
      - instance_filter: "{{ env_type }}-{{ email }}"
      - env_type: "{{ env_type }}"
      - api_user: "{{ osp_auth_username_member }}"
      - api_pass: "{{ osp_auth_password_member }}"
      - api_url: "{{ osp_auth_url }}"
      - project_name: "{{  osp_project_name}}"
      - pxe_image: "pxeboot"

    tags:
      - key: "ostype"
        value: "linux"
      - key: "instance_filter"
        value: "{{ env_type }}-{{ email }}"
    networks:
      - public
    floating_ip: false
    fixed_ips:
      public: "192.168.56.253"

  - name: "allinone"
    count: 1
    unique: true
    public_dns: false
    dns_loadbalancer: false
    image_id: "{{ allinone_instance_image }}"
    flavor: "{{ __allinone_instance_flavor }}"
    userdata: |
      ssh_pwauth:   true
      hostname: allinone.example.com
      chpasswd:
         list: |
           root:r3dh4t1!
         expire: False

    metadata:
      - AnsibleGroup: "allinone"
      - ostype: "linux"
      - instance_filter: "{{ env_type }}-{{ email }}"
      - guid: "{{ guid }}"
      - env_type: "{{ env_type }}"
    tags:
      - key: "AnsibleGroup"
        value: "allinone"
      - key: "ostype"
        value: "linux"
      - key: "instance_filter"
        value: "{{ env_type }}-{{ email }}"
    networks:
      - public
      - admin
    floating_ip: false
    fixed_ips:
      public: "192.168.56.200"
      admin: "172.16.7.200"

  - name: "stor01"
    count: 1
    unique: true
    public_dns: false
    dns_loadbalancer: false
    image_id: "{{ stor01_instance_image }}"
    flavor: "{{ __stor01_instance_flavor }}"
    userdata: |
      ssh_pwauth:   true
      chpasswd:
         list: |
           root:r3dh4t1!
         expire: False

    metadata:
      - AnsibleGroup: "labnodes"
      - ostype: "linux"
      - instance_filter: "{{ env_type }}-{{ email }}"
      - env_type: "{{ env_type }}"
      - guid: "{{ guid }}"
      - env_type: "{{ env_type }}"
    tags:
      - key: "AnsibleGroup"
        value: "labnodes"
      - key: "ostype"
        value: "linux"
      - key: "instance_filter"
        value: "{{ env_type }}-{{ email }}"
    networks:
      - public
      - admin
      - storage
    floating_ip: false
    fixed_ips:
      public: "192.168.56.21"
      admin: "172.16.7.21"
      storage: "192.168.99.21"
    volumes:
      - volume_name: "stor01-volume01"
        volume_size: "10"
      - volume_name: "stor01-volume02"
        volume_size: "10"
      - volume_name: "stor01-volume03"
        volume_size: "10"

  - name: "stor02"
    count: 1
    unique: true
    public_dns: false
    dns_loadbalancer: false
    image_id: "{{ stor02_instance_image }}"
    flavor: "{{ __stor02_instance_flavor }}"
    userdata: |
      ssh_pwauth:   true
      chpasswd:
         list: |
           root:r3dh4t1!
         expire: False

    metadata:
      - AnsibleGroup: "labnodes"
      - ostype: "linux"
      - instance_filter: "{{ env_type }}-{{ email }}"
      - env_type: "{{ env_type }}"
      - guid: "{{ guid }}"
      - env_type: "{{ env_type }}"
    tags:
      - key: "AnsibleGroup"
        value: "labnodes"
      - key: "ostype"
        value: "linux"
      - key: "instance_filter"
        value: "{{ env_type }}-{{ email }}"
    networks:
      - public
      - admin
      - storage
    floating_ip: false
    fixed_ips:
      public: "192.168.56.22"
      admin: "172.16.7.22"
      storage: "192.168.99.22"
    volumes:
      - volume_name: "stor02-volume01"
        volume_size: "10"
      - volume_name: "stor02-volume02"
        volume_size: "10"
      - volume_name: "stor02-volume03"
        volume_size: "10"

  - name: "stor03"
    count: 1
    unique: true
    public_dns: false
    dns_loadbalancer: false
    image_id: "{{ stor03_instance_image }}"
    flavor: "{{ __stor03_instance_flavor }}"
    userdata: |
      ssh_pwauth:   true
      chpasswd:
         list: |
           root:r3dh4t1!
         expire: False

    metadata:
      - AnsibleGroup: "labnodes"
      - ostype: "linux"
      - instance_filter: "{{ env_type }}-{{ email }}"
      - env_type: "{{ env_type }}"
      - guid: "{{ guid }}"
      - env_type: "{{ env_type }}"
    tags:
      - key: "AnsibleGroup"
        value: "labnodes"
      - key: "ostype"
        value: "linux"
      - key: "instance_filter"
        value: "{{ env_type }}-{{ email }}"
    networks:
      - public
      - admin
      - storage
    floating_ip: false
    fixed_ips:
      public: "192.168.56.23"
      admin: "172.16.7.23"
      storage: "192.168.99.23"
    volumes:
      - volume_name: "stor03-volume01"
        volume_size: "10"
      - volume_name: "stor03-volume02"
        volume_size: "10"
      - volume_name: "stor03-volume03"
        volume_size: "10"

  - name: "proxy01"
    count: 1
    unique: true
    public_dns: false
    dns_loadbalancer: false
    image_id: "{{ proxy01_instance_image }}"
    flavor: "{{ __proxy01_instance_flavor }}"
    userdata: |
      ssh_pwauth:   true
      chpasswd:
         list: |
           root:r3dh4t1!
         expire: False

    metadata:
      - AnsibleGroup: "labnodes"
      - ostype: "linux"
      - instance_filter: "{{ env_type }}-{{ email }}"
      - env_type: "{{ env_type }}"
      - guid: "{{ guid }}"
      - env_type: "{{ env_type }}"
    tags:
      - key: "AnsibleGroup"
        value: "labnodes"
      - key: "ostype"
        value: "linux"
      - key: "instance_filter"
        value: "{{ env_type }}-{{ email }}"
    volumes:
      - volume_name: "proxy01-volume01"
        volume_size: "20"
      - volume_name: "proxy01-volume02"
        volume_size: "20"
    networks:
      - public
      - admin
      - storage
    floating_ip: false
    fixed_ips:
      public: "192.168.56.24"
      admin: "172.16.7.24"
      storage: "192.168.99.24"

  - name: "proxy02"
    count: 1
    unique: true
    public_dns: false
    dns_loadbalancer: false
    image_id: "{{ proxy02_instance_image }}"
    flavor: "{{ __proxy02_instance_flavor }}"
    userdata: |
      ssh_pwauth:   true
      chpasswd:
         list: |
           root:r3dh4t1!
         expire: False

    metadata:
      - AnsibleGroup: "labnodes"
      - ostype: "linux"
      - instance_filter: "{{ env_type }}-{{ email }}"
      - env_type: "{{ env_type }}"
      - guid: "{{ guid }}"
      - env_type: "{{ env_type }}"
    tags:
      - key: "AnsibleGroup"
        value: "labnodes"
      - key: "ostype"
        value: "linux"
      - key: "instance_filter"
        value: "{{ env_type }}-{{ email }}"

    networks:
      - public
      - admin
      - storage
    floating_ip: false
    fixed_ips:
      public: "192.168.56.25"
      admin: "172.16.7.25"
      storage: "192.168.99.25"

  - name: "haproxy01"
    count: 1
    unique: true
    public_dns: false
    dns_loadbalancer: false
    image_id: "{{ haproxy01_instance_image }}"
    flavor: "{{ __haproxy01_instance_flavor }}"
    userdata: |
      ssh_pwauth:   true
      chpasswd:
         list: |
           root:r3dh4t1!
         expire: False

    metadata:
      - AnsibleGroup: "labnodes"
      - ostype: "linux"
      - instance_filter: "{{ env_type }}-{{ email }}"
      - env_type: "{{ env_type }}"
      - guid: "{{ guid }}"
      - env_type: "{{ env_type }}"
    tags:
      - key: "AnsibleGroup"
        value: "labnodes"
      - key: "ostype"
        value: "linux"
      - key: "instance_filter"
        value: "{{ env_type }}-{{ email }}"
    networks:
      - public
      - admin
      - storage
    floating_ip: false
    fixed_ips:
      public: "192.168.56.80"
      admin: "172.16.7.80"
      storage: "192.168.99.80"

# Stuff that only GPTE cares about:
install_ipa_client: false

################################################################################
################################################################################
### Common Host settings
################################################################################
################################################################################

#repo_method: ""
# Do you want to run a full yum update
update_packages: false
common_packages:
  - bash-completion
  - tmux
  - wget
  - vim-enhanced

rhel_repos:
  - rhel-8-for-x86_64-appstream-eus-rpms
  - rhel-8-for-x86_64-baseos-eus-rpms
  - rhel-8-for-x86_64-highavailability-eus-rpms
  - ansible-2.9-for-rhel-8-x86_64-rpms
  - openstack-16.2-for-rhel-8-x86_64-rpms
  - fast-datapath-for-rhel-8-x86_64-rpms
  - advanced-virt-for-rhel-8-x86_64-rpms

###V2WORK, these should just be set as default listed in the documentation
install_bastion: true
install_common: false
## SB Don't set software_to_deploy from here, always use extra vars (-e) or "none" will be used
#software_to_deploy: none

## guid is the deployment unique identifier, it will be appended to all tags,
## files and anything that identifies this environment from another.
# Using GUID is required, if it is not passed in the command line or uncommented
# here the deployment will fail
#guid: defaultguid

###V2WORK, these should just be set as default listed in the documentation
# This is where the ssh_config file will be created, this file is used to
# define the communication method to all the hosts in the deployment
deploy_local_ssh_config_location: "{{output_dir}}/"

### If you want a Key Pair name created and injected into the hosts,
# set `set_env_authorized_key` to true and set the keyname in `env_authorized_key`
# you can use the key used to create the environment or use your own self generated key
# if you set "use_own_key" to false your PRIVATE key will be copied to the bastion. (This is {{key_name}})

###V2WORK, these should just be set as default listed in the documentation
use_own_key: true
env_authorized_key: "{{guid}}key"
set_env_authorized_key: true

###V2WORK THIS SHOULD MOVE INTO THE ROLE
# This var is used to identify stack (cloudformation, azure resourcegroup, ...)
project_tag: "{{ env_type }}-{{ guid }}"
