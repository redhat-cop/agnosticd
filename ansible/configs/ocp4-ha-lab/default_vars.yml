---
###### VARIABLES YOU SHOULD CONFIGURE FOR YOUR DEPLOYEMNT
###### OR PASS as "-e" args to ansible-playbook command
platform: labs
software_to_deploy: none

### Common Host settings
# Repo Method. One of file, satellite and rhn
repo_method: satellite

#If using repo_method: satellite, you must set these values as well.
# satellite_url: satellite.example.com
# satellite_org: Sat_org_name
# satellite_activationkey: "rhel7basic"

# Do you want to run a full yum update
update_packages: true

## guid is the deployment unique identifier, it will be appended to all tags,
## files and anything that identifies this environment from another "just like it"
#guid: defaultguid

install_bastion: true
install_common: true
install_ftl: false
install_student_user: true
student_name: lab-user

### If you want a Key Pair name created and injected into the hosts,
# set `set_env_authorized_key` to true and set the keyname in `env_authorized_key`
# you can use the key used to create the environment or use your own self generated key
# if you set "use_own_key" to false your PRIVATE key will be copied to the bastion. (This is {{key_name}})

use_own_key: true
set_env_authorized_key: true
env_authorized_key: "{{ guid }}key"
ansible_ssh_private_key_file: ~/.ssh/{{ key_name }}.pem

# Need cluster name defined for cleanup
cluster_name: "cluster-{{ guid }}"

# Next settings are for setting up a sandbox for
# The OCP 4 Advanced Infrastructure Deployment ILT
install_utilityvm: false
install_student_resources: false
install_certificates: false

# NFS
## NFS Server settings
nfs_export_path: /srv/nfs
nfs_server_address: "utilityvm.example.com"
nfs_exports_config: "*(rw,sync,no_wdelay,no_root_squash,insecure,fsid=0)"

# When the config is setting up NFS on the utility VM, which it does by default,
# this will define how many exports to create on the NFS server. These still have to
# be created as PVs by the user once OpenShift is installed. PV files are created
# and placed on the bastion to use for this.
user_vols: 20

# This will be used when creating the Kube PV definitions
user_vols_size: 20G

# End OCP 4 Advanced Infrastructure Deployment ILT settings

### AWS EC2 Environment settings

### Route 53 Zone ID (AWS)
# This is the Route53 HostedZoneId where you will create your Public DNS entries
# This should come from the account
# HostedZoneId: Z3IHLWJZOU9SRT

# The region to be used, if not specified by -e in the command line
aws_region: us-east-2

# The key that is used to
key_name: "default_key_name"

## Networking (AWS)
subdomain_base_short: "{{ guid }}"
subdomain_base_suffix: ".example.opentlc.com"
subdomain_base: "{{ subdomain_base_short ~ subdomain_base_suffix }}"

## VM Sizing

bastion_instance_type: t3a.medium
bastion_rootfs_size: 30
bastion_instance_image: RHEL82GOLD

utilityvm_instance_type: t3a.small
utilityvm_rootfs_size: 50
utilityvm_instance_image: RHEL82GOLD

###### VARIABLES YOU SHOULD ***NOT*** CONFIGURE FOR YOUR DEPLOYEMNT

ansible_user: ec2-user
remote_user: ec2-user

common_packages_el8:
- python3
- unzip
- bash-completion
- tmux
- bind-utils
- wget
- nano
- git
- vim-enhanced
- httpd-tools
- openldap-clients
- podman
- skopeo
- buildah
- tree
- ansible

### CLOUDFORMATIONS vars

project_tag: "{{ env_type }}-{{ guid }}"

zone_internal_dns: "{{ guid }}.internal."
chomped_zone_internal_dns: "{{ guid }}.internal"

bastion_public_dns: "bastion.{{ subdomain_base }}."
bastion_public_dns_chomped: "bastion.{{ subdomain_base }}"
vpcid_name_tag: "{{ subdomain_base }}"

# az_1_name: "{{ aws_region }}a"
# az_2_name: "{{ aws_region }}b"

instances:
- name: "bastion"
  count: 1
  unique: true
  public_dns: true
  image: "{{ bastion_instance_image }}"
  flavor:
    ec2: "{{ bastion_instance_type }}"
  tags:
  - key: "AnsibleGroup"
    value: "bastions,clientvms"
  - key: "ostype"
    value: "linux"
  - key: "Purpose"
    value: "{{ purpose }}"
  rootfs_size: "{{ bastion_rootfs_size }}"
  security_groups:
  - BastionSG

# UtilityVM will only be created if install_utilityvm=true
- name: utilityvm
  count: "{% if install_utilityvm | bool %}1{% else %}0{% endif %}"
  image: "{{ utilityvm_instance_image }}"
  flavor:
    ec2: "{{ utilityvm_instance_type }}"
  unique: true
  public_dns: false
  tags:
  - key: "AnsibleGroup"
    value: "utility"
  - key: "ostype"
    value: "linux"
  - key: "Purpose"
    value: "{{ purpose }}"
  - key: "user"
    value: "{{ student_name }}"
  rootfs_size: "{{ utilityvm_rootfs_size }}"
  security_groups:
  - UtilitySG

security_groups:
- name: BastionSG
  rules:
  - name: BasSSHPublic
    description: "SSH public"
    from_port: 22
    to_port: 22
    protocol: tcp
    cidr: "0.0.0.0/0"
    rule_type: Ingress

- name: UtilitySG
  rules:
  - name: SSHUtility
    description: "SSH public"
    from_port: 22
    to_port: 22
    protocol: tcp
    cidr: "0.0.0.0/0"
    rule_type: Ingress
  - name: HTTPUtility
    description: "HTTP public"
    from_port: 80
    to_port: 80
    protocol: tcp
    cidr: "0.0.0.0/0"
    rule_type: Ingress
  - name: HTTPSUtility
    description: "HTTP public"
    from_port: 443
    to_port: 443
    protocol: tcp
    cidr: "0.0.0.0/0"
    rule_type: Ingress
  - name: RegistryUtility
    description: "Registry public"
    from_port: 5000
    to_port: 5000
    protocol: tcp
    cidr: "0.0.0.0/0"
    rule_type: Ingress
  - name: NFSUtility
    description: "NFS"
    from_port: 2049
    to_port: 2049
    protocol: tcp
    cidr: "0.0.0.0/0"
    rule_type: Ingress
