# vim: set ft=ansible:
---
- name: Bastion hostname config
  hosts: localhost
  connection: local
  become: false
  tags:
    - workshop
    - workshop_bastion_hostname
  tasks:
    - name: Store bastion hostname as a fact
      set_fact:
        bastion_hostname: "{{ hostvars[ groups[ ('tag_' ~ env_type ~ '_' ~ guid ~ '_bastion') | replace('-', '_') ].0 ]['ec2_public_dns_name'] }}"

# TODO: metrics nodeselector


- name: User volumes on NFS server
  hosts: 
    - "{{ ('tag_' ~ env_type ~ '_' ~ guid ~ '_nfs') | replace('-', '_') }}"
  gather_facts: False
  vars_files:
    - "env_vars.yml"
    - "env_secret_vars.yml"
    - "ssh_vars.yml"
  tasks:
    - name: Create user vols
      shell: "mkdir -p /srv/nfs/user-vols/vol{1..{{ user_vols }}}"
    - name: chmod the user vols
      shell: "chmod -R 777 /srv/nfs/user-vols"

- name: NFS voume configuration
  hosts: 
    - "{{ ('tag_' ~ env_type ~ '_' ~ guid ~ '_bastion') | replace('-', '_') }}"
  vars_files:
    - "env_vars.yml"
    - "env_secret_vars.yml"
    - "ssh_vars.yml"
  tasks:
    - name: Set NFS related facts
      set_fact:
        nfs_host: "{{ hostvars[ groups[ ('tag_' ~ env_type ~ '_' ~ guid ~ '_nfs') | replace('-', '_') ].0 ]['ec2_public_dns_name'] }}"
        pv_size: '10Gi'
        pv_list: "{{ nfs_shares }}"
        persistentVolumeReclaimPolicy: Retain

    # TODO: I think I can get rid of this pvs because I do it later
    - name: Generate PV file
      template:
        src: "{{ playbook_dir }}/files/pvs.j2"
        dest: "/root/pvs-{{ env_type }}-{{ guid }}.yml"
      tags: 
        - gen_pv_file

    - set_fact:
        pv_size: "{{ user_vols_size }}"
        persistentVolumeReclaimPolicy: Recycle

    - name: Generate user vol PV file
      template:
        src: "{{ playbook_dir }}/files/userpvs.j2"
        dest: "/root/userpvs-{{ env_type }}-{{ guid }}.yml"
      tags:
        - gen_user_vol_pv

    - shell: 'oc create -f /root/pvs-{{ env_type }}-{{ guid }}.yml || oc update -f /root/pvs-{{ env_type }}-{{ guid }}.yml'

    - shell: 'oc create -f /root/userpvs-{{ env_type }}-{{ guid }}.yml || oc update -f /root/userpvs-{{ env_type }}-{{ guid }}.yml'

- name: Workshop admins
  hosts: 
    - "{{ ('tag_' ~ env_type ~ '_' ~ guid ~ '_master') | replace('-', '_') }}"
  vars_files:
    - "env_vars.yml"
    - "env_secret_vars.yml"
    - "ssh_vars.yml"
  tags:
    - workshop
    - workshop_admins
  tasks:
##TODO: Use htpasswd module if possible. Need to look into it.
  - name: Add administrative user to htpasswd file
    command: "htpasswd -b /etc/origin/master/htpasswd admin openshift3"

- name: Create Workshop NFS shares
  hosts: 
    - "{{ ('tag_' ~ env_type ~ '_' ~ guid ~ '_nfs') | replace('-', '_') }}"
  vars_files:
    - "env_vars.yml"
    - "env_secret_vars.yml"
    - "ssh_vars.yml"
  tags:
    - workshop
    - workshop_nfs
  tasks:
    - name: Create workshop nfs directory
      file:
        name: '/srv/nfs/{{ item }}'
        state: directory
        mode: 0777
        owner: nfsnobody
        group: nfsnobody
        recurse: True
      with_items:
        - '{{ workshop_shares }}'

    - name: Create workshop exports file
      file:
        path: "/etc/exports.d/{{ env_type }}-{{ guid }}-workshop.exports"
        state: touch
        mode: 755

    - name: Update workshop exports file
      lineinfile:
        dest: "/etc/exports.d/{{ env_type }}-{{ guid }}-workshop.exports"
        line: "/srv/nfs/{{ item }} *(rw,root_squash,no_wdelay,sync)"
        state: present
      with_items:
        - '{{ workshop_shares }}'
      run_once: True

    - name: Reload NFS exports
      shell: "exportfs -r"

- name: Workshop PVs
  hosts: 
    - "{{ ('tag_' ~ env_type ~ '_' ~ guid ~ '_master') | replace('-', '_') }}"
  vars_files:
    - "env_vars.yml"
    - "env_secret_vars.yml"
    - "ssh_vars.yml"
  tags:
    - workshop
    - create_workshop_vol_pvs
  tasks:
    - set_fact:
        pv_size: '10Gi'
        pv_list: "{{ workshop_shares }}"
        persistentVolumeReclaimPolicy: Retain
        nfs_hostname: "{{ hostvars[ groups[ ('tag_' ~ env_type ~ '_' ~ guid ~ '_nfs') | replace('-', '_') ].0 ]['ansible_fqdn'] }}"

    - name: Generate workshop PV file
      template:
        src: "files/{{ env_type }}_pvs.j2"
        dest: "/root/pvs-{{ env_type }}-{{ guid }}.yml"

    - name: Create workshop PVs
      shell: 'oc create -f /root/pvs-{{ env_type }}-{{ guid }}.yml || oc update -f /root/pvs-{{ env_type }}-{{ guid }}.yml'

- name: Workshop infrastructure
  hosts: 
    - "{{ ('tag_' ~ env_type ~ '_' ~ guid ~ '_master') | replace('-', '_') }}"
  vars_files:
    - "env_vars.yml"
    - "env_secret_vars.yml"
    - "ssh_vars.yml"
  tags:
    - workshop
    - workshop_infra
  tasks:
    - name: Give administrative user cluster-admin privileges
      command: "{{ oc_path }} adm policy add-cluster-role-to-user cluster-admin admin"

    - name: Check for workshop-infra project
      command: "{{ oc_path }}  get project workshop-infra"

      register: result
      ignore_errors: true

    - name: Create workshop-infra project
      command: "{{ oc_path }} adm new-project workshop-infra --admin admin --node-selector='env=infra'"

      when: result | failed
## TODO: Should we bundle all of these into an
## items or subelements list?
    - name: Make workshop-infra project network global
      command: "{{ oc_path }} adm pod-network make-projects-global workshop-infra"

    - name: Set workshop-infra SCC for anyuid
      command: "{{ oc_path }} adm policy add-scc-to-group anyuid system:serviceaccounts:workshop-infra"

    - name: Add capabilities within anyuid which is not really ideal
      command: "{{ oc_path }} patch scc/anyuid --patch '{\"requiredDropCapabilities\":[\"MKNOD\",\"SYS_CHROOT\"]}'"


    - name: Copy nexus.yaml to master
      copy:
        src: "files/nexus.yaml"
        dest: "/root/nexus.yaml"

    - name: Check if Nexus was already provisioned
      command: "{{ oc_path }} get service nexus -n workshop-infra"

      register: install_nexus
      ignore_errors: true

    - name: Instantiate nexus from template
      command: "{{ oc_path }} create -f /root/nexus.yaml -n workshop-infra"

      when: install_nexus | failed

    # looks like we need a better check - it seems we're ready up to several
    # seconds before the router finds out about us, so we might want another
    # http check to make sure nexus is responding
    - name: Wait for Nexus to be running
      command: "{{ oc_path }} get dc/nexus -o yaml -n workshop-infra"

      register: result
      until: '"availableReplicas: 1" in result.stdout'
      retries: 5
      delay: 60

    - name: Wait for Nexus to be happy
      uri:
        url: "http://nexus.workshop-infra.svc.cluster.local:8081/content/repositories/"
        status_code: 200
      register: nexus_happy
      until: nexus_happy | success
      retries: 5
      delay: 60

    - name: Install EPEL (for jq)
      package:
        name: "https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm"
        state: installed

## TODO: Use the yum module to enable/disable repos
    - name: Disable EPEL
      command: "yum-config-manager --disablerepo=epel"

    - name: Install jq
      package:
        name: jq
        state: present
        enablerepo: epel

    - name: Copy Nexus addrepo script
      copy:
        src: "files/addrepo.sh"
        dest: "/root/addrepo.sh"

    - name: Check for redhat-ga repository in Nexus
      uri:
        url: "http://nexus.workshop-infra.svc.cluster.local:8081/content/repositories/redhat-ga"
        status_code: 200
      register: redhat_ga_out
      ignore_errors: true

    - name: Add redhat-ga repository for Nexus
      shell: "NEXUS_BASE_URL=nexus.workshop-infra.svc.cluster.local:8081 bash /root/addrepo.sh redhat-ga https://maven.repository.redhat.com/ga/"
      when: redhat_ga_out | failed

    - name: Check for JBoss repository in Nexus
      uri:
        url: "http://nexus.workshop-infra.svc.cluster.local:8081/content/repositories/jboss"
        status_code: 200
      register: redhat_ga_out
      ignore_errors: true

    - name: Add redhat-ga repository for Nexus
      shell: "NEXUS_BASE_URL=nexus.workshop-infra.svc.cluster.local:8081 bash /root/addrepo.sh jboss https://repository.jboss.org/nexus/content/repositories/public"
      when: redhat_ga_out | failed

    - name: Copy gitlab-template.yaml to master
      copy:
        src: "files/gitlab-template.yaml"
        dest: "/root/gitlab-template.yaml"

    - name: Check if Gitlab was already provisioned
      command: "{{ oc_path }} get service gitlab-ce -n workshop-infra"

      register: install_gitlab
      ignore_errors: true

    - name: Instantiate Gitlab from template
      shell: >
        {{ oc_path }} process -f /root/gitlab-template.yaml
        -v APPLICATION_HOSTNAME=gitlab-ce-workshop-infra.{{ cloudapps_suffix }}
        -v GITLAB_ROOT_PASSWORD=password | {{ oc_path }} create -f - -n workshop-infra

      when: install_gitlab | failed
      tags:
        - instantiate-gitlab

    - name: Wait for Gitlab to be running
      command: "{{ oc_path }} get dc/gitlab-ce -o yaml -n workshop-infra"

      register: result
      until: '" availableReplicas: 1" in result.stdout'
      retries: 8
      delay: 60
      tags:
        - wait-for-gitlab

    - name: Copy simple-java-s2i IS to server
      copy:
        src: "files/java-s2i-is.yaml"
        dest: "/root/java-s2i-is.yaml"
      tags:
        - copy-java-s2i-is

    - name: Create simple-java-s2i IS in openshift namespace
      shell: "{{ oc_path }} create -f /root/java-s2i-is.yaml -n openshift || {{ oc_path }} replace -f /root/java-s2i-is.yaml -n openshift"

      tags:
        - create-java-s2i-is

    - name: Create Jenkins pipeline template in openshift namespace
      shell: "{{ oc_path }} create -f https://raw.githubusercontent.com/openshift-roadshow/nationalparks/1.0.0/ose3/pipeline-template.yaml -n openshift || {{ oc_path }} replace -f https://raw.githubusercontent.com/openshift-roadshow/nationalparks/1.0.0/ose3/pipeline-template.yaml -n openshift"

      tags:
        - create-pipeline-template

    - name: Check for workshop lab build
      command: "{{ oc_path }} get svc/labs -n workshop-infra"

      ignore_errors: true
      register: labs_service_out

    - name: Build workshop lab server
      shell: >
        {{ oc_path }} new-app

        --name=labs {{ lab_url }}#{{ lab_tag }} \
        -e ROUTER_ADDRESS={{cloudapps_suffix}}
        -e CONSOLE_ADDRESS=master.{{subdomain_base}}
        -e DEFAULT_LAB=roadshow
        -n workshop-infra;
        {{ oc_path }} expose service labs -n workshop-infra

      when: labs_service_out | failed
      tags:
        - build-workshop-labs

- name: GitLab nfs permissions hack
  hosts: 
    - "{{ ('tag_' ~ env_type ~ '_' ~ guid ~ '_nfs') | replace('-', '_') }}"
  vars_files:
    - "env_vars.yml"
    - "env_secret_vars.yml"
    - "ssh_vars.yml"
  tags:
    - workshop
    - workshop_nfs_hack
  tasks:

## TODO: Use the file module for controlling ownership.
## This ensures idempotency and only changes when necessary.
    - name: Fix ownership of git-data
      shell: "chown -R 998:root /srv/nfs/gitlab-data"

    - name: Fix permission on git-data
      shell: "chmod -R 700 /srv/nfs/gitlab-data/git-data"

    - name: Fix permission on git-data/repositories
      shell: "chmod -R 2770 /srv/nfs/gitlab-data/git-data/repositories"

- name: Project Request Template
  hosts: 
    - "{{ ('tag_' ~ env_type ~ '_' ~ guid ~ '_master') | replace('-', '_') }}"
  vars_files:
    - "env_vars.yml"
    - "env_secret_vars.yml"
    - "ssh_vars.yml"
  tags:
    - workshop
    - project_request
  tasks:

    - name: Copy project request template to master
      copy:
        src: files/project-template.yaml
        dest: /root/project-template.yaml

    - name: Check for project request template
      command: "{{ oc_path }} get template project-request -n default"

      register: request_template
      ignore_errors: true

    - name: Create project request template in default project
      shell: "{{ oc_path }} create -f /root/project-template.yaml -n default || {{ oc_path }} replace -f /root/project-template.yaml -n default"
      when: request_template | failed

    - name: Update master config file to use project request template
      lineinfile:
        regexp: "  projectRequestTemplate"
        dest: "/etc/origin/master/master-config.yaml"
        line: '  projectRequestTemplate: "default/project-request"'
        state: present
      register: master_config

    - name: Restart master service
      service:
        name: atomic-openshift-master
        state: restarted
      when: master_config.changed

- name: Workshop Users
  hosts: 
    - "{{ ('tag_' ~ env_type ~ '_' ~ guid ~ '_master') | replace('-', '_') }}"
  vars_files:
    - "env_vars.yml"
    - "env_secret_vars.yml"
    - "ssh_vars.yml"
  tags:
    - workshop
    - workshop_users
  tasks:

    - name: Add log path to Ansible configuration
      lineinfile:
        regexp: "^#log_path"
        dest: "/etc/ansible/ansible.cfg"
        line: "log_path = /root/ansible.log"
        state: present

    - name: Copy vars file to master
      copy:
        src: "env_vars.yml"
        dest: "/root/{{ env_type }}_vars.yml"

    - name: Copy user provision Ansible script remotely
      copy:
        src: "files/userprovision.yaml"
        dest: "/root/userprovision.yaml"

    - name: Set Gitlab internal hostname
      set_fact:
        gitlab_hostname: 'gitlab-ce.workshop-infra.svc.cluster.local'

    - name: Get root user token
      uri:
        url: 'http://gitlab-ce.workshop-infra.svc.cluster.local/api/v3/session'
        body: 'login=root&password=password'
        method: POST
        status_code: 201
      register: root_token_out
      until: root_token_out|success
      retries: 3
      delay: 60

    - name: Create root token fact
      set_fact:
        root_token: '{{ root_token_out.json.private_token }}'

    - name: Execute user provision Ansible script remotely
      shell: >
        ansible-playbook
        -i localhost /root/userprovision.yaml
        -e config={{ env_type }}
        -e user={{ item }}
        -e root_token={{ root_token }}
        -e gitlab_hostname={{ gitlab_hostname }}
      with_sequence: start=0 end={{ user_vols }} format=%02d

- name: Cache Java dependencies
  hosts: 
    - "{{ ('tag_' ~ env_type ~ '_' ~ guid ~ '_master') | replace('-', '_') }}"
  vars_files:
    - "env_vars.yml"
    - "env_secret_vars.yml"
    - "ssh_vars.yml"
  vars:
    workshop_repos:
      - "nationalparks"
      - "mlbparks"
      - "parksmap-web"
  tags:
    - workshop
    - workshop_java_dependencies
  tasks:
    - name: Install Maven and Java
      yum:
        name: '{{ item }}'
        state: present
        enablerepo: "rhui-REGION-rhel-server-optional"
      with_items:
        - "maven"
        - "java-1.8.0-openjdk-devel"

    - name: Remove m2 folder
      file:
        path: "/home/ec2-user/.m2/repository"
        state: absent

    - name: Make repos directory
      file:
        path: "/home/ec2-user/repos"
        state: directory

    - name: Clone app repositories
      git:
        repo: 'https://github.com/openshift-roadshow/{{ item }}'
        dest: "/home/ec2-user/repos/{{ item }}"
      with_items:
        - '{{ workshop_repos }}'

    - name: Deploy maven settings file
      template:
        src: "files/maven.xml.j2"
        dest: "/home/ec2-user/maven.xml"
        mode: 0755
        owner: ec2-user

    - name: Build and cache dependencies
      shell: >
        mvn -q -s /home/ec2-user/maven.xml -f /home/ec2-user/repos/{{ item }}/pom.xml install
      with_items:
        - '{{ workshop_repos }}'

