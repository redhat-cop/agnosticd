###### VARIABLES YOU SHOULD CONFIGURE FOR YOUR DEPLOYEMNT
###### OR PASS as "-e" args to ansible-playbook command

# Stuff that should come from elsewhere, but including here to make things work locally
guid: sten1
opentlc_user: nate-redhat.com
admin_user: nate-admin # needed to give access to new projet and will be removed later
user_pub_key: |
  ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC4LIAh+LeqBsODfR9YMqyk6E74hE9/FzyDsBf7pukER7alw99JLySZFeO7hL0COXrQlbweVDTwbU5GJrLSbUQZvgVOIbH/roAwMBjzuwdh7ibLyxZNdJs/6gLifWUXSmaj/JKXCr2Lg+527wRfePY+1mXJNMc+cbrezWoUpNlhw3D1NrcJnxldmRn6Rw0jnQdaz1PtAgMfX4Xftr9RV0GggtAwCGjViBK6WM+Fkfp4hT0EMVoCtwvhmEIzeaYaHofit3pW/KONp1DG/OisojUcDuQ6S7i5Mt35N1LmzR06ED4c8kOLMaqZ7UDupFOoILL/vqayVjL67trgcsTcJXI5
output_dir: /Users/nstephan/gpte/tests
env_type: ocp4-disconnected-osp-lab
heat_retries: 0

cluster_name: cluster-{{ guid }}
project_tag: "{{ env_type }}-{{ guid }}"

# Cloud provider should be set to the IaaS type. This will determine where
# this is deployed and what template to use (CFN, ARM, HOT, etc.)
cloud_provider: osp

install_student_user: false
install_ipa_client: false
set_env_authorized_key: true
env_authorized_key: "{{guid}}key"
key_name: "id_rsa"
ansible_ssh_private_key_file: ~/.ssh/{{key_name}}

ansible_user: cloud-user
remote_user: cloud-user

# Bastion install and prep section
install_bastion: true
install_k8s_modules: true

# This will tell Agnosticd to use either:
# sattelite, rhn, or file for repos
repo_method: satellite
# If using satellite, these are needed:
satellite_url: satellite.opentlc.com
satellite_activationkey: # This should be stored in secrets
satellite_org: # This should be stored in secrets
use_content_view: true
update_packages: true
install_common: true
common_packages:
  - python
  - unzip
  - bash-completion
  - tmux
  - bind-utils
  - wget
  - ansible
  - git
  - vim-enhanced
  - iptables-services
  - httpd-tools
  - openldap-clients
rhel_repos:
  - rhel-7-server-rpms
  - rhel-7-server-extras-rpms
  - rhel-7-server-ansible-2.7-rpms
  - rhel-7-server-optional-rpms

# These will influence the Client VM (bastion) if it is being deployed
clientvm_instance_type: small
clientvm_instance_image: rhel-server-7.7

# These will influence the utility VM, which is primarily used for disconnected
# install, but can be used for anything really.
utilityvm_instance_type: small
utilityvm_instance_image: rhel-server-7.7

# DNS servers will be provided to the subnet and
# injected into the instances on that subnet.
# This should be a comma separated list if more than one
# dns_nameservers: 169.45.246.132
# ocp_cluster_dns_zone: rh.stencell.net
ocp_cluster_dns_zone: red.osp.opentlc.com
ocp_cluster_dns_server: ddns01.opentlc.com
wait_for_dns: true
# Authenticaion for DDNS
ddns_key_name: 
ddns_secret_name: 

# Set this to true if you want a FIPs provisioned for an OpenShift on OpenStack install
openshift_fip_provision: True

# Quotas to set for new project that is created
quota_num_instances: 10
quota_num_cores: 40
quota_memory: 131072 # in MB
quota_num_volumes: 25
quota_volumes_gigs: 500
#quota_loadbalancers: #when Octavia is available
#quota_pool: #when Octavia is available
quota_networks: 3
quota_subnets: 3
quota_routers: 3
quota_fip: 5
quota_sg: 10
quota_sg_rules: 100

# The external network in OpenStack where the floating IPs (FIPs) come from
provider_network: external
# A list of the private networks and subnets to create in the project
networks:
  - name: ocp
    shared: false
    subnet_cidr: 192.0.2.0/24
    gateway_ip: 192.0.2.1
    allocation_start: 192.0.2.10
    allocation_end: 192.0.2.254
    custom_dns: false
    dns_nameservers: []
    create_router: true

# If you are deploying OpenShift, this should be set to the network that you 
# want to use and will be used to create security groups.
ocp_network: "ocp"
ocp_network_subnet_cidr: "{{ networks | selectattr('name', 'equalto', '~ ocp_network ~') | map(attribute='subnet_cidr') | first }}"
# Security groups and associated rules
security_groups:
  - name: bastion_sg
    description: Bastion security group allows basic ICMP and SSH ingress and egress to *
    rules:
    - protocol: ICMP
      direction: ingress
    - protocol: ICMP
      direction: egress
    - protocol: TCP
      direction: egress
      remote_ip_prefix: 0.0.0.0/0
    - protocol: UDP
      direction: egress
      remote_ip_prefix: 0.0.0.0/0
    - protocol: TCP
      direction: ingress
      port_range_min: 22
      port_range_max: 22
      remote_ip_prefix: 0.0.0.0/0
  - name: utility_sg
    description: Utility security group allows SSH from bastion and egress to *
    rules:
    - protocol: ICMP
      direction: ingress
      remote_group_id: bastion_sg
    - protocol: TCP
      direction: ingress
      port_range_min: 22
      port_range_max: 22
      remote_group_id: bastion_sg
    - protocol: TCP
      direction: egress
      rmote_ip_prefix: 0.0.0.0/0
    - protocol: UDP
      direction: egress
      remote_ip_prefix: 0.0.0.0/0
  - name: isolated_sg
    description: All instances in the disconnected network
    # TODO: This is still creating an 'any' egress ruleset too
    rules:
    - protocol: ICMP
      direction: ingress
      remote_group_id: bastion_sg
    - protocol: TCP
      direction: ingress
      port_range_min: 22
      port_range_max: 22
      remote_group_id: bastion_sg
  - name: "{{ guid }}-master_sg"
    description: Security group for OpenShift master and bootstrap
    rules:
      - protocol: ICMP
        direction: ingress
        description: "ICMP"
      - protocol: TCP
        direction: ingress
        port_range_min: 22623
        port_range_max: 22623
        remote_ip_prefix: "{{ ocp_network_subnet_cidr }}"
        description: "machine config server"
      - protocol: TCP
        direction: ingress
        port_range_min: 22
        port_range_max: 22
        remote_mode: remote_group_id
        remote_group_id: bastion_sg
        description: "SSH"
      - protocol: TCP
        direction: ingress
        port_range_min: 53
        port_range_max: 53
        remote_ip_prefix: "{{ ocp_network_subnet_cidr }}"
        description: "DNS (TCP)"
      - protocol: UDP
        direction: ingress
        port_range_min: 53
        port_range_max: 53
        remote_ip_prefix: "{{ ocp_network_subnet_cidr }}"
        description: "DNS (UDP)"
      - protocol: UDP
        direction: ingress
        port_range_min: 5353
        port_range_max: 5353
        remote_ip_prefix: "{{ ocp_network_subnet_cidr }}"
        description: "mDNS"
      - protocol: TCP
        direction: ingress
        port_range_min: 6443
        port_range_max: 6443
        remote_ip_prefix: 0.0.0.0/0
        description: "OpenShift API"
      - protocol: UDP
        direction: ingress
        port_range_min: 4789
        port_range_max: 4789
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-master_sg"
        description: "VXLAN"
      - protocol: UDP
        direction: ingress
        port_range_min: 4789
        port_range_max: 4789
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-worker_sg"
        description: "VXLAN (worker)"
      - protocol: UDP
        direction: ingress
        port_range_min: 6081
        port_range_max: 6081
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-master_sg"
        description: "Geneve"
      - protocol: UDP
        direction: ingress
        port_range_min: 6081
        port_range_max: 6081
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-worker_sg"
        description: "Geneve (worker)"
      - protocol: TCP
        direction: ingress
        port_range_min: 6641
        port_range_max: 6642
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-master_sg"
        description: "OVNDB"
      - protocol: TCP
        direction: ingress
        port_range_min: 6641
        port_range_max: 6642
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-worker_sg"
        description: "OVNDB (worker)"
      - protocol: TCP
        direction: ingress
        port_range_min: 9000
        port_range_max: 9999
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-master_sg"
        description: "Master ingress internal (TCP)"
      - protocol: TCP
        direction: ingress
        port_range_min: 9000
        port_range_max: 9999
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-worker_sg"
        description: "Master ingress from worker (TCP)"
      - protocol: UDP
        direction: ingress
        port_range_min: 9000
        port_range_max: 9999
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-master_sg"
        description: "Master ingress internal (UDP)"
      - protocol: UDP
        direction: ingress
        port_range_min: 9000
        port_range_max: 9999
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-worker_sg"
        description: "Master ingress from worker (UDP)"
      - protocol: TCP
        direction: ingress
        port_range_min: 10259
        port_range_max: 10259
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-master_sg"
        description: "Kube Scheduler"
      - protocol: TCP
        direction: ingress
        port_range_min: 10259
        port_range_max: 10259
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-worker_sg"
        description: "Kube Scheduler (worker)"
      - protocol: TCP
        direction: ingress
        port_range_min: 10257
        port_range_max: 10257
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-master_sg"
        description: "Kube controller manager"
      - protocol: TCP
        direction: ingress
        port_range_min: 10257
        port_range_max: 10257
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-worker_sg"
        description: "Kube controller manager (worker)"
      - protocol: TCP
        direction: ingress
        port_range_min: 10250
        port_range_max: 10250
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-master_sg"
        description: "master ingress kubelet secure"
      - protocol: TCP
        direction: ingress
        port_range_min: 10250
        port_range_max: 10250
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-worker_sg"
        description: "master ingress kubelet secure from worker"
      - protocol: TCP
        direction: ingress
        port_range_min: 2379
        port_range_max: 2380
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-master_sg"
        description: "etcd"
      - protocol: TCP
        direction: ingress
        port_range_min: 30000
        port_range_max: 32767
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-master_sg"
        description: "master ingress services (TCP)"
      - protocol: UDP
        direction: ingress
        port_range_min: 30000
        port_range_max: 32767
        remote_mode: remote_group_id
        remote_group_id: "{{ guid }}-master_sg"
        description: "master ingress services (UDP)"
      - protocol: VRRP
        direction: ingress
        remote_ip_prefix: "{{ ocp_network_subnet_cidr }}"
        description: "VRRP"
  - name: "{{ guid }}-worker_sg"
    description: Security group for OpenShift workers
    rules:
      - protocol: ICMP
        direction: ingress
        description: ICMP


# Authenication for OpenStack in order to create the things
osp_auth_url: 
osp_auth_username: 
osp_auth_password:
osp_auth_cloud:
osp_auth_project_domain: #usually set to "default"
osp_auth_user_domain: #usually set to "default"

# Instances to be provisioned in new project
instances:
  - name: bastion
    count: 1
    unique: yes
    alt_name: bastion
    image_id: "{{ clientvm_instance_image }}"
    floating_ip: yes
    flavor:
      ec2: "{{ clientvm_instance_type }}"
      osp: "{{ clientvm_instance_type }}"
    metadata:
      - AnsibleGroup: "bastions,clientvms"
      - function: bastion
      - user: nate
      - project: "{{ project_tag }}"
      - ostype: linux
    rootfs_size: 50
    security_groups:
      - bastion_sg
  
  - name: utilityvm
    count: 1
    image_id: "{{ utilityvm_instance_image }}"
    floating_ip: no
    flavor: 
      ec2: "{{ utilityvm_instance_type }}"
      osp: "{{ utilityvm_instance_type }}"
    metadata:
      - AnsibleGroup: "utility"
      - function: bastion
      - user: nate
      - project: "{{ project_tag }}"
      - ostype: linux
    rootfs_size: 50
    security_groups:
      - utility_sg
      - isolated_sg
