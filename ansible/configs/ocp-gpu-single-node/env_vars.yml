---
## TODO: What variables can we strip out of here to build complex variables?
## i.e. what can we add into group_vars as opposed to config_vars?
## Example: We don't really need "subdomain_base_short". If we want to use this,
## should just toss in group_vars/all.
### Also, we should probably just create a variable reference in the README.md
### For now, just tagging comments in line with configuration file.

### Vars that can be removed:
# use_satellite: true
use_subscription_manager: false
use_own_repos: true

###### VARIABLES YOU SHOULD CONFIGURE FOR YOUR DEPLOYEMNT
###### OR PASS as "-e" args to ansible-playbook command

### Common Host settings
repo_version: "3.11"
repo_method: file # Other Options are: file, satellite and rhn

#If using repo_method: satellite, you must set these values as well.
# satellite_url: satellite.example.com
# satellite_org: Sat_org_name
# satellite_activationkey: "rhel7basic"

# Do you want to run a full yum update
update_packages: false

## guid is the deployment unique identifier, it will be appended to all tags,
## files and anything that identifies this environment from another "just like it"
guid: defaultguid

# This var is used to identify stack (cloudformation, azure resourcegroup, ...)
project_tag: "{{ env_type }}-{{ guid }}"

## SB Don't set software_to_deploy from here, always use extra vars (-e) or "none" will be used
#software_to_deploy: openshift
deploy_openshift: true
deploy_openshift_post: true
deploy_env_post: true

install_bastion: false
install_common: true
install_nfs: true
install_glusterfs: false
install_opentlc_integration: true
install_zabbix: false
install_prometheus: false
install_ipa_client: false
install_lets_encrypt_certificates: false
install_openwhisk: false
install_metrics: false
install_logging: false
install_aws_broker: false

glusterfs_device_name: /dev/xvdc
glusterfs_device_size: 500

ocp_report: false
remove_self_provisioners: false
idm_ca_url: http://ipa.opentlc.com/ipa/config/ca.crt
zabbix_host: 23.246.247.58

# Options for container_runtime: docker, cri-o
container_runtime: "docker"
docker_version: "{{ '1.12.6' if repo_version | version_compare('3.9', '<')  else '1.13.1' }}"
docker_device: /dev/xvdb

### If you want a Key Pair name created and injected into the hosts,
# set `set_env_authorized_key` to true and set the keyname in `env_authorized_key`
# you can use the key used to create the environment or use your own self generated key
# if you set "use_own_key" to false your PRIVATE key will be copied to the bastion. (This is {{key_name}})

use_own_key: true
env_authorized_key: "{{guid}}key"
ansible_ssh_private_key_file: ~/.ssh/{{key_name}}.pem
set_env_authorized_key: true

# Is this running from Red Hat Ansible Tower
tower_run: false

admin_user: opentlc-mgr
admin_project: "ocp-workshop"

### Azure

# Create a dedicated resourceGroup for this deployment
az_destroy_method: resource_group
az_resource_group: "{{ project_tag }}"

# you can operate differently: if you share on resourceGroup for all you deployments,
# you can specify a different resourceGroup and method:
#az_destroy_method: deployment
#az_resource_group: my-shared-resource-group
#az_storage_account_type: Premium_LRS

### AWS EC2 Environment settings

### Route 53 Zone ID (AWS)
# This is the Route53 HostedZoneId where you will create your Public DNS entries
# This only needs to be defined if your CF template uses route53
HostedZoneId: Z1TQFSYFZUAO0D
# The region to be used, if not specified by -e in the command line
aws_region: us-east-1
# The key that is used to
key_name: "default_key_name"

## Networking (AWS)
subdomain_base_short: "{{ guid }}"
subdomain_base_suffix: ".openshift.opentlc.com"
subdomain_base: "{{subdomain_base_short}}{{subdomain_base_suffix}}"

## Environment Sizing

master_instance_type: "p2.xlarge"
master_instance_count: 1
bastion_instance_type: "p2.xlarge"
infranode_instance_count: 0

###### VARIABLES YOU SHOULD ***NOT*** CONFIGURE FOR YOUR DEPLOYEMNT

## This might get removed
env_specific_images:
#   - "registry.access.redhat.com/jboss-eap-7/eap70-openshift:latest"
#   - "registry.access.redhat.com/openshift3/jenkins-2-rhel7:latest"
#   - "registry.access.redhat.com/openshift3/jenkins-slave-maven-rhel7:latest"

#### Vars for the OpenShift Ansible hosts file
master_api_port: 8443
ovs_plugin: "subnet" # This can also be set to: "multitenant" or "networkpolicy"
multi_tenant_setting: "os_sdn_network_plugin_name='redhat/openshift-ovs-{{ovs_plugin}}'"
master_lb_dns: "bastion.{{subdomain_base}}"

lets_encrypt_openshift_master_named_certificates:
  - certfile: "/root/.acme.sh/{{ master_lb_dns }}/{{ master_lb_dns }}.cer"
    keyfile: "/root/.acme.sh/{{ master_lb_dns }}/{{ master_lb_dns }}.key"
    cafile: "/root/.acme.sh/{{ master_lb_dns }}/ca.cer"

lets_encrypt_openshift_hosted_router_certificate:
  certfile: "/root/.acme.sh/{{ master_lb_dns }}/{{ master_lb_dns }}.cer"
  keyfile: "/root/.acme.sh/{{ master_lb_dns }}/{{ master_lb_dns }}.key"
  cafile: "/root/.acme.sh/{{ master_lb_dns }}/ca.cer"

project_request_message: 'To provision Projects you must request access in https://labs.opentlc.com or https://rhpds.redhat.com'

cloudapps_suffix: 'apps.{{subdomain_base}}'
## TODO: This should be registered as a variable. Awk for os verions (OCP).
## yum info openshift...
osrelease: "3.11.16"
installer_release: "3.11.16"
openshift_master_overwrite_named_certificates: true
timeout: 60

########## OCP identity providers
# Options for install_idm: allow_all, htpasswd, ldap, ...  see the available below
install_idms: allow_all
install_idm: allow_all

# This var is empty by default.
# Every idm in the list 'install_idms' will be added, using the 'available_identity_providers' map
# you can:
#   - directly override the 'identity_providers' list
# or
#   - add an option to 'available_identity_providers' and then
#     reference it in 'install_idm' or the 'install_idms' list
identity_providers: []

openshift_master_ldap_ca_file: 'openshift_master_ldap_ca_file=/root/ca.crt'

available_identity_providers:
  ldap:
    name: OpenTLC IPA
    challenge: true
    login: true
    kind: LDAPPasswordIdentityProvider
    attributes:
      id: ['dn']
      email: ['mail']
      name: ['cn']
      preferredUsername: ['uid']
    bindDN: uid=ose-mwl-auth,cn=users,cn=accounts,dc=opentlc,dc=com
    bindPassword: "{{bindPassword|d('NOT_DEFINED')}}"
    ca: ipa-ca.crt
    insecure: false
    url: ldaps://ipa1.opentlc.com:636/cn=users,cn=accounts,dc=opentlc,dc=com?uid

  ssodev:
    name: ssodev-iad00
    challenge: false
    login: true
    kind: OpenIDIdentityProvider
    clientID: "{{ opentlc_ssodev_client_id|d('NOT_DEFINED') }}"
    clientSecret: "{{ opentlc_ssodev_client_secret|d('NOT_DEFINED') }}"
    ca: lets-encrypt-x3-cross-signed.pem.txt
    urls:
      authorize: https://ssodev-iad00.opentlc.com:8443/auth/realms/ipatest/protocol/openid-connect/auth
      token: https://ssodev-iad00.opentlc.com:8443/auth/realms/ipatest/protocol/openid-connect/token
      userInfo: https://ssodev-iad00.opentlc.com:8443/auth/realms/ipatest/protocol/openid-connect/userinfo
    claims:
      id:
        - sub
      preferredUsername:
        - preferred_username
      name:
        - name
      email:
        - email

  allow_all:
    name: allow_all
    login: "true"
    challenge: "true"
    kind: AllowAllPasswordIdentityProvider

  htpasswd:
    name: htpasswd_auth
    login: true
    challenge: true
    kind: HTPasswdPasswordIdentityProvider
    filename: /etc/origin/master/htpasswd

###### You can, but you usually wouldn't need to.
ansible_user: ec2-user
remote_user: ec2-user

common_packages:
  - python
  - unzip
  - bash-completion
  - tmux
  - bind-utils
  - wget
  - ansible
  - git
  - vim-enhanced
  - at
  - sysstat
  - strace
  - net-tools
  - iptables-services
  - bridge-utils
  - kexec-tools
  - sos
  - psacct
  - iotop

rhel_repos:
  - rhel-7-server-rpms
  - rhel-7-server-extras-rpms
  - rhel-7-fast-datapath-rpms
  - rhel-7-server-ose-{{repo_version}}-rpms

# rhn_pool_id_string: OpenShift Container Platform

### NFS Server settings
#nfs_vg: nfsvg
#nfs_pvs: /dev/xvdd
#nfs_export_path: /srv/nfs
#nfs_size: 200
#
#nfs_shares:
#  - user-vols

ocp_pvs:
#   - es-storage
#   - nexus
#   - nexus2
#   - nexus3

#user_vols: 200
#user_vols_size: 10Gi

cache_images:
  - "docker.io/caffe2ai/caffe2:latest"
  - "docker.io/mirrorgooglecontainers/cuda-vector-add:v0.1"

### CLOUDFORMATIONS vars


zone_internal_dns: "{{guid}}.internal."
chomped_zone_internal_dns: "{{guid}}.internal"

cloudapps_record: '*.apps'
cloudapps_dns: '{{cloudapps_record}}.{{subdomain_base}}.'

master_public_dns: "master.{{subdomain_base}}."
bastion_public_dns: "bastion.{{subdomain_base}}."
certtest_public_dns: "certtest.{{subdomain_base}}."
bastion_public_dns_chomped: "bastion.{{subdomain_base}}"
vpcid_cidr_block: "192.168.0.0/16"
vpcid_name_tag: "{{subdomain_base}}"

az_1_name: "{{ aws_region }}a"
az_2_name: "{{ aws_region }}b"

subnet_private_1_cidr_block: "192.168.2.0/24"
subnet_private_1_az: "{{ az_2_name }}"
subnet_private_1_name_tag: "{{subdomain_base}}-private"

subnet_private_2_cidr_block: "192.168.1.0/24"
subnet_private_2_az: "{{ az_1_name }}"
subnet_private_2_name_tag: "{{subdomain_base}}-private"

subnet_public_1_cidr_block: "192.168.10.0/24"
subnet_public_1_az: "{{ az_1_name }}"
subnet_public_1_name_tag: "{{subdomain_base}}-public"

subnet_public_2_cidr_block: "192.168.20.0/24"
subnet_public_2_az: "{{ az_2_name }}"
subnet_public_2_name_tag: "{{subdomain_base}}-public"

dopt_domain_name: "{{ aws_region }}.compute.internal"

rtb_public_name_tag: "{{subdomain_base}}-public"
rtb_private_name_tag: "{{subdomain_base}}-private"

cf_template_description: "{{ env_type }}-{{ guid }} template "

rootfs_size_node: 50
rootfs_size_infranode: 150
rootfs_size_master: 50
rootfs_size_bastion: 20
rootfs_size_support: 20

instances:
  - name: "bastion"
    count: 1
    unique: true
    public_dns: true
    dns_loadbalancer: true
    flavor:
      ec2: "{{master_instance_type}}"
      azure: "{{master_instance_type}}"
    tags:
      - key: "AnsibleGroup"
        value: "bastions"
      - key: "ostype"
        value: "linux"
    rootfs_size: "{{ rootfs_size_bastion }}"
    rootfs_size: "{{ rootfs_size_master }}"
    volumes:
      - device_name: "{{docker_device}}"
        volume_size: "{{master_docker_size|default(docker_size)|default('20')}}"
        volume_type: gp2
        purpose: docker
        lun: 0
