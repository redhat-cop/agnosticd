---
# The output_dir holds all of the files generated during the deployment
# This includes generated Heat templates, SSH config, SSH keys
# This must be an absolute path and no vars (like $HOME or ~)
output_dir: /tmp/output_dir

# The {{ guid }} is used everywhere and it is what differentiates otherwise
# identical environments. Make this unique. Usually they are 4 characters, but
# it can be any reasonable length.
guid: notset

# The name of the OpenShift cluster that will be deployed.
# This is primarily used if you want to automate the OpenShift deployment.
cluster_name: "cluster-{{ guid }}"

# Used to add metadata (tags) to OpenStack objects created
project_tag: "{{ env_type }}-{{ guid }}"

# Why is this config being deployed? Override for specific environments
# Some valid: development, ilt, production, event
purpose: development

# Enable this if you want to use IPA for user authentication.
# Mutually exclusive with {{ install_student_user }}
install_ipa_client: false

# Enable this if you want to create a user on the bastion
# Mutually exclusive with {{ install_ipa_client }}
install_student_user: true

# This should be overwritten based on the user ordering the catalog item
# It will be used by the bastion-student-user role and created on the bastion
student_name: lab-user

# TODO: What does this really do besides run the role?
set_env_authorized_key: true
env_authorized_key: "{{guid}}key"

# Run the bastion-lite role
install_bastion: true

# This config was written with the expectation of using python3
# Several of the roles that it depends on only work with python2,
# so they had to be modified to handle python3 as well. Use this
# var so that it is passed along and influences how those roles run.
all_use_python3: true

# FTL is used for grading and solving. It will pull in the external ftl-injector role.
# This might be enabled when we have solvers to run or graders for ILT
# When enabled a requirements.yml must exist in the config to specify the ftl-injector role and tag.
install_ftl: false

# This will tell Agnosticd to use either:
# satellite, rhn, or file for repos
# Only satellite is supported for RHEL 8
repo_method: satellite

# If using satellite, these are needed and should
# come from secrets:
# satellite_url: satellite.opentlc.com
# satellite_org: # This should be stored in secrets
# satellite_activationkey: # This should be stored in secrets

# If using file, these are needed in addition to the repos_template.j2 file:
# osrelease: '4.4.0'
# repo_version: '4.4'

# own_repo_path: points to a repo mirror. Must defined in secrets
# own_repo_path: <FROM_SECRETS>

# -------------------------------------------------
# Role: common
# -------------------------------------------------
# Packages to install on all of the hosts deployed as part of the agnosticd config
# This invokes the "common" role
install_common: true

# To install extra packages (beyond what's in the common list of packages)
# e.g. RHEL 8
# common_extra_packages:
# - java-17-openjdk
# - maven

# As part of the "common" role, this cause it to do a yum update on the host
update_packages: true

# Types of Nodes (workers / masters) are set in the
# cloud specific vars file
# Number of Nodes
master_instance_count: 3
worker_instance_count: 2

# Types and Sizes of Disks for nodes
# Only set if you know what you're doing...
# master_storage_type: "__DEFAULT__"
# master_storage_size: "30Gi"
# worker_storage_type: "__DEFAULT__"
# worker_storage_size: "100Gi"

# Install OpenShift 4 - and which version
install_ocp4: true

# Use 4.12 for latest available release in the `stable-4.12` directory.
# Use 4.12.2 for exactly the specified release
ocp4_installer_version: "4.12"

# Run logic to enable cluster shutdown before 24h initial certificate rotation
# Only works for OCP 4.1 and 4.2. OCP 4.4.8 and later no longer require this.
ocp4_enable_cluster_shutdown: false

# See role host-ocp4-installer for additional OpenShift 4 Installer options
# E.g. OpenShift Cluster processor architectore or OpenShift installer download location

# Pull secret needs to be defined in secrets
# Get from https://try.openshift.com
# ocp4_pull_secret: ''

ocp4_base_domain: "example.opentlc.com"

# Red Hat Network Plugins for OpenShift:
# - OVNKubernetes (requires OCP 4.6 and newer)
# - OpenshiftSDN (no longer supported as of 4.15)
#
# Third Party Network Plugins for OpenShift
# - Calico (tested on OCP 4.7)
#
ocp4_network_type: OVNKubernetes

# Install the workaround for OVN deployments. Only for 4.6+
# This is *only* necessary when the cluster will contain
# Windows nodes. Should be false otherwise.
ocp4_network_ovn_install_workaround: false

# Run fio performance tests at the end
test_deploy_enable: false
test_deploy_results: false
#test_deploy_runs: 50
#test_deploy_image: quay.io/nstephan/fio-etcd-osp:v3

# User info settings
ocp4_cluster_show_default_user_info: true
ocp4_cluster_show_flight_check_user_info: "{{ ocp4_cluster_show_default_user_info }}"
ocp4_cluster_show_access_user_info: "{{ ocp4_cluster_show_default_user_info }}"

# Set to true to enable creating a cluster-admin service account during installation
openshift_cluster_admin_service_account_enable: false

# YAML List of Infrastructure Workloads.
# REQUIRES Ansible 2.7+ on the deployer host
# Empty by default - to be set by specific configurations
infra_workloads: []

# Suggested infra workloads for a base workshop cluster:
#  - ocp4_workload_authentication
#  - ocp4_workload_project_request_template
#  - ocp4_workload_opentlc_production
#  - ocp4_workload_machinesets
#  - ocp4_workload_logging
#  - ocp4_workload_le_certificates

# YAML List of Student Workloads.
# REQUIRES Ansible 2.7+ on the deployer host
# Empty by default - to be set by specific configurations
# Can only be used with htpasswd authentication
student_workloads: []

# Some workloads create infrastructure that needs to be removed
# when deleting the software or infrastructure. These workloads run on the controller
remove_workloads: []

# Some workloads create infrastructure that needs to be removed
# when deleting the software or infrastructure. These workloads run on the bastion
remove_workloads_bastion: []
