groups:
- name: etcd-rules
  interval: 10s # defaults to global interval
  rules:
  - alert: "Node Down"
    expr: up{job="kubernetes-nodes"} == 0
    annotations:
      component: "ContainerNode"
      severity: "HIGH"
      message: "Node {{$labels.instance}} is down"
  - alert: "Lost ETCD"
    expr: up{job="etcd"} == 0
    annotations:
      component: "ETCD"
      severity: "HIGH"
      message: "ETCD {{$labels.instance}} is down"
  - alert: "Time drift"
    expr: sqrt((scalar(avg(node_time{job="kubernetes-nodes-exporter"})) - node_time{job="kubernetes-nodes-exporter"} )^2) > 60
    for: 30s
    annotations:
      component: "NTP"
      severity: "HIGH"
      message: "Node {{$labels.instance}} has time drift bigger than 60 from average time"
- name: scheduler-rules
  interval: 10s # defaults to global interval
  rules:
  - alert: "Scheduler node1"
    expr: ( (sum(kubelet_running_pod_count{instance=~"^node.*"}) / ((count(node_time) - 6))) * 2 ) < (sum(kubelet_running_pod_count{instance=~"^node1.*"}))
    annotations:
      component: "Scheduler"
      severity: "HIGH"
      message: "Node node1.example.com has more pods than average"
  - alert: "Scheduler node2"
    expr: ( (sum(kubelet_running_pod_count{instance=~"^node.*"}) / ((count(node_time) - 6))) *2 ) < (sum(kubelet_running_pod_count{instance=~"^node2.*"}))
    annotations:
      component: "Scheduler"
      severity: "HIGH"
      message: "Node node2.example.com has more pods than average"
  - alert: "Scheduler node3"
    expr: ( (sum(kubelet_running_pod_count{instance=~"^node.*"}) / ((count(node_time) - 6))) *2 ) < (sum(kubelet_running_pod_count{instance=~"^node3.*"}))
    annotations:
      component: "Scheduler"
      severity: "HIGH"
      message: "Node node3.example.com has more pods than average"
  - alert: "Builds Failing"
    expr: sum(openshift_build_total{phase=~"Failed|Error"}) > 10
    annotations:
      component: "OpenShift Builds"
      severity: "HIGH"
      message: "There is a high volume of builds failing"
  - alert: "Registry storage"
    expr: (avg(kubelet_volume_stats_used_bytes{persistentvolumeclaim="registry-claim"}) * 100) / avg(kubelet_volume_stats_capacity_bytes{persistentvolumeclaim="registry-claim"}) > 80
    annotations:
      component: "Registry Storage"
      severity: "MEDIUM"
      message: "Storage limit reached more than 80% "
  - alert: "Registry storage"
    expr: (avg(kubelet_volume_stats_used_bytes{persistentvolumeclaim="registry-claim"}) * 100) / avg(kubelet_volume_stats_capacity_bytes{persistentvolumeclaim="registry-claim"}) > 95
    annotations:
      component: "Registry Storage"
      severity: "HIGH"
      message: "Storage limit reached more than 95% "
  - alert: "DNS Errors"
    expr: changes(node_dnsmasq_sync_error_count_total[2m]) >=1 
    annotations:
      component: "dnsmasq"
      severity: "HIGH"
message: "DNS errors detected. Check grafana for more details"