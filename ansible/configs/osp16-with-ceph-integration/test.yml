- hosts: bastions
  become: true
  gather_facts: False
  vars:
    create_group_vars_rgws: |
      cat >group_vars/mgrs.yml <<EOF
      ---
      ceph_rgw_docker_memory_limit: 1g
      ceph_rgw_docker_cpu_limit: 1
      EOF

    create_group_vars_mgrs: |
      cat >group_vars/mgrs.yml <<EOF
      ---
      ceph_mgr_docker_memory_limit: 1g
      ceph_mgr_docker_cpu_limit: 1
      EOF
    create_group_vars_mons: |
      cat >group_vars/mons.yml <<EOF
      ---
      ceph_mon_docker_memory_limit: 1g
      ceph_mon_docker_cpu_limit: 1
      EOF
    create_group_vars_osds: |
      cat >group_vars/osds.yml <<EOF
      ---
      copy_admin_key: true

      devices:
        - /dev/sdb
        - /dev/sdc

      ceph_osd_docker_memory_limit: 1g
      ceph_osd_docker_cpu_limit: 1
      EOF
    create_group_vars_all: |
      cat >group_vars/all.yml <<EOF
      ---
      monitor_interface: eth0
      radosgw_interface: eth0
      journal_size: 5120
      public_network: 172.18.0.240/24
      ceph_docker_image: rhceph/rhceph-4-rhel8
      ceph_docker_image_tag: latest
      containerized_deployment: true
      ceph_docker_registry: classroom.example.com
      ceph_origin: repository
      ceph_repository: rhcs
      ceph_repository_type: local
      ceph_rhcs_version: 4
      dashboard_admin_user: admin
      dashboard_admin_password: r3dh4t1!
      grafana_admin_user: admin
      grafana_admin_password: r3dh4t1!
      ceph_conf_overrides:
        global:
          mon_pg_warn_min_per_osd: 0
      EOF
    create_ansible_cfg: |
      cat >ansible.cfg <<EOF
      [defaults]
      inventory     = /usr/share/ceph-ansible/hosts
      action_plugins = /usr/share/ceph-ansible/plugins/actions
      filter_plugins = /usr/share/ceph-ansible/plugins/filter
      roles_path = /usr/share/ceph-ansible/roles
      log_path = /var/log/ansible.log
      timeout = 60
      host_key_checking = False
      retry_files_enabled = False
      retry_files_save_path = /usr/share/ceph-ansible/ansible-retry
      [privilege_escalation]
      become=True
      become_method=sudo
      become_user=root
      become_ask_pass=False
      EOF
    create_hosts: |
      cat > hosts <<EOF
      [mons]
      ceph-mon01
      ceph-mon02
      ceph-mon03

      [mgrs]
      ceph-mon01
      ceph-mon02
      ceph-mon03

      [rgws]
      ceph-mon01
      ceph-mon02
      ceph-mon03

      [osds]
      ceph-osd01
      ceph-osd02
      ceph-osd03

      [grafana-server]
      localhost ansible_connection=local
      EOF

    configure_ssh_config: |
      cat >> ~/.ssh/config <<EOF
      Host ceph*
        User admin
      EOF
    create_ceph_preqs: |
      cat >>/root/ceph-preqs.yaml <<\EOF
      ---
      - name: Ceph Installation Pre-requisites
        hosts: all
        gather_facts: no
        vars:
        remote_user: root
        ignore_errors: yes
        tasks:

        - name: Create the admin user
          user:
            name: admin
            generate_ssh_key: yes
            ssh_key_bits: 2048
            ssh_key_file: .ssh/id_rsa
            password: $6$mZKDrweZ5e04Hcus$97I..Zb0Ywh1lQefdCRxGh2PJ/abNU/LIN7zp8d2E.uYUSmx1RLokyzYS3mUTpipvToZbYKyfMqdP6My7yYJW1

        - name: Create sudo file for admin user
          lineinfile:
            path: /etc/sudoers.d/admin
            state: present
            create: yes
            line: "admin ALL=(root) NOPASSWD:ALL"
            owner: root
            group: root
            mode: 0440

        - name: Push ssh key to hosts
          copy:
            src: /root/.ssh/id_rsa.pub
            dest: /home/admin/.ssh/authorized_keys
            owner: admin
            group: admin
            mode: 0640


        - name: Copy repos
          copy:
            src: /etc/yum.repos.d/local.repo
            dest: /etc/yum.repos.d/local.repo

        - name: Install containers-common
          package:
           name: containers-common

        - name: Copy /etc/containers/registries.conf
          copy:
            src: /etc/containers/registries.conf
            dest: /etc/containers/registries.conf

        - name: Add classroom.example.com record
          lineinfile:
            path: /etc/hosts
            line: "192.0.2.253 classroom.example.com"
      EOF

    create_ceph_nodes: |
      cat >>/root/ceph-nodes <<EOF
      [all]
      ceph-mon01
      ceph-mon02
      ceph-mon03
      ceph-osd01
      ceph-osd02
      ceph-osd03
      EOF

    populate_hosts: |
      cat >> /etc/hosts <<EOF
      172.18.0.240 ceph-mon01 ceph-mon01.example.com
      172.18.0.241 ceph-mon02 ceph-mon02.example.com
      172.18.0.242 ceph-mon03 ceph-mon03.example.com
      172.18.0.243 ceph-osd01 ceph-osd01.example.com
      172.18.0.244 ceph-osd02 ceph-osd02.example.com
      172.18.0.245 ceph-osd03 ceph-osd03.example.com
      EOF
  tasks:
    - name: 02_installing_ceph_Lab
      shell: "{{ item }}"
      register: output_02_1
      args:
        chdir: /root/
      loop:
        - yum makecache
        - dnf -y install ceph-ansible podman
        - ssh-keygen -b 2048 -t rsa -f ~/.ssh/id_rsa -q -N ""
        - sed -i -e '0,/registries = \[\]/ s/registries = \[\]/registries = \["classroom.example.com"\]/' /etc/containers/registries.conf
        - "{{ populate_hosts }}"
        - "{{ create_ceph_nodes }}"
        - "{{ create_ceph_preqs }}"
        - ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook -i ceph-nodes ceph-preqs.yaml -e ansible_ssh_pass=r3dh4t1!
        - "{{ configure_ssh_config }}"

    - name: Output 02_installing_ceph_Lab
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_02_1.results }}"

    - name: 02_installing_ceph_Lab
      shell: "{{ item }}"
      register: output_02_2
      args:
        chdir: /usr/share/ceph-ansible/
      loop:
        - "{{ create_hosts }}"
        - mv ansible.cfg ansible.cfg.orig
        - "{{ create_ansible_cfg }}"
        - "{{ create_group_vars_all }}"
        - "{{ create_group_vars_osds }}"
        - "{{ create_group_vars_mons }}"
        - "{{ create_group_vars_mgrs }}"
        - "{{ create_group_vars_rgws }}"
        - cp site-docker.yml.sample site-docker.yml
        - ansible-playbook  site-docker.yml
        - dnf -y install ceph-common
        - sshpass -pr3dh4t1! scp root@ceph-mon01:/etc/ceph/ceph.conf /etc/ceph/
        - sshpass -pr3dh4t1! scp root@ceph-mon01:/etc/ceph/ceph.client.admin.keyring /etc/ceph/
        - ceph -s
        - ceph health
        - ceph osd tree
        - ceph mon dump
        - ssh ceph-mon01 sudo podman ps
        - ssh ceph-mon01 sudo podman stats --no-stream
        - ssh ceph-mon01 sudo systemctl | grep "ceph-.*.service"
        - ssh ceph-mon01 "sudo systemctl status ceph*@*.service"
        - ssh ceph-osd01 sudo podman ps
        - ssh ceph-osd01 sudo podman stats --no-stream

    - name: Output 02_installing_ceph_Lab
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_02_2.results }}"

    - name: 03_integration_existing
      shell: "{{ item }}"
      register: output_03_1
      args:
        chdir: /usr/share/ceph-ansible/
      loop:
        - ceph osd pool create volumes 32
        - ceph osd pool create images 32
        - ceph osd pool create vms 32
        - ceph osd pool create backups 32
        - ceph osd pool create metrics 32
        - ceph auth add client.openstack mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=volumes, allow rwx pool=vms, allow rwx pool=images, allow rwx pool=backups, allow rwx pool=metrics'
        - ceph auth get client.openstack |grep key
        - grep fsid /etc/ceph/ceph.conf

    - name: Output 03_integration_existing
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_03_1.results }}"

    - name: Get FSID from Ceph
      shell: grep fsid /etc/ceph/ceph.conf | awk '{print $3}'
      register: fsid

    - name: Get client.openstack key
      shell: ceph auth get-key client.openstack
      register: cephkey

- hosts: undercloud
  become: true
  become_user: stack
  gather_facts: False
  vars:
    create_ceph_repo: |
      sudo bash -c 'cat << EOF > /etc/yum.repos.d/ceph.repo
      [rhceph-4-tools-for-rhel-8-x86_64-rpms]
      name=rhceph-4-tools-for-rhel-8-x86_64-rpms
      baseurl=http://192.0.2.253/repos/rhceph-4-tools-for-rhel-8-x86_64-rpms
      enabled=1
      gpgcheck=0
      EOF'
    replace_ceph_config: |
      cat >/home/stack/templates/environments/ceph-config.yaml <<EOF
        parameter_defaults:
          CephClientKey: {{ hostvars['workstation']['cephkey'].stdout }}
          CephClusterFSID: {{ hostvars['workstation']['fsid'].stdout }}
          CephExternalMonHost: 172.18.0.240,172.18.0.241,172.18.0.242
      EOF
  tasks:
    - name: 03_integration_existing
      shell: "{{ item }}"
      register: output_03_2
      args:
        chdir: /home/stack/
      loop:
        - "{{ create_ceph_repo }}"
        - sudo dnf -y install ceph-ansible
        - curl -O  www.opentlc.com/download/novello/ceph4osp16.tar
        - tar xvf ceph4osp16.tar
        - "{{ replace_ceph_config }}"
        - source ~/stackrc && openstack overcloud node import --introspect --provide ~/nodes.json
        - source ~/stackrc && openstack baremetal node set ctrl01 --property capabilities=node:controller-0,boot_option:local
        - source ~/stackrc && openstack baremetal node set ctrl02 --property capabilities=node:controller-1,boot_option:local
        - source ~/stackrc && openstack baremetal node set ctrl03 --property capabilities=node:controller-2,boot_option:local
        - source ~/stackrc && openstack baremetal node set compute01 --property capabilities=node:compute-0,boot_option:local
        - source ~/stackrc && openstack baremetal node set compute02 --property capabilities=node:compute-1,boot_option:local
        - cat ./deploy-external-ceph.sh

    - name: Output 03_integration_existing
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_03_2.results }}"

    - name: Deploy Overcloud with external ceph
      shell: source ~/stackrc && ./deploy-external-ceph.sh
      args:
        chdir: /home/stack/
      async: 100000
      poll: 0
      register: install_overcloud

    - name: "install overcloud - external ceph - check on async task"
      async_status:
        jid: "{{ install_overcloud.ansible_job_id }}"
      register: job_result
      until: job_result.finished
      retries: 600

    - name: 03_integration_existing
      shell: "{{ item }}"
      register: output_03_2b
      args:
        chdir: /home/stack/
      loop:
        - source ~/overcloudrc && cinder get-pools
        - source ~/overcloudrc && openstack volume service list

    - name: Output 03_integration_existing
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_03_2b.results }}"

- hosts: bastions
  become: true
  gather_facts: False
  tasks:
    - name: 03_integration_existing (3)
      shell: "{{ item }}"
      delegate_to: workstation
      register: output_03_3
      args:
        chdir: /root/
      loop:
        - rbd  -p volumes ls

    - name: Output 03_integration_existing
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_03_3.results }}"

- hosts: undercloud
  become: true
  become_user: stack
  gather_facts: False
  tasks:
    - name: 03_integration_existing (4)
      shell: "{{ item }}"
      register: output_03_4
      args:
        chdir: /home/stack/
      loop:
        - source ~/overcloudrc && openstack volume create --size 1 test-vol

    - name: Output 03_integration_existing
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_03_4.results }}"

- hosts: bastions
  become: true
  gather_facts: False
  tasks:
    - name: 03_integration_existing
      shell: "{{ item }}"
      delegate_to: workstation
      register: output_03_5
      args:
        chdir: /root/
      loop:
        - rbd  -p volumes ls
        - rbd  -p images ls

    - name: Output 03_integration_existing
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_03_5.results }}"

- hosts: undercloud
  become: true
  become_user: stack
  gather_facts: False
  tasks:
    - name: 03_integration_existing
      shell: "{{ item }}"
      register: output_03_6
      args:
        chdir: /home/stack/
      loop:
        - curl -L -O https://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img
        - qemu-img convert cirros-0.4.0-x86_64-disk.img cirros-0.4.0-x86_64-disk.raw
        - source ~/overcloudrc && openstack image create --file cirros-0.4.0-x86_64-disk.raw  --container-format bare --disk-format raw --public cirros

    - name: Output 03_integration_existing
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_03_6.results }}"

- hosts: bastions
  become: true
  gather_facts: False
  tasks:
    - name: 03_integration_existing
      shell: "{{ item }}"
      register: output_03_7
      args:
        chdir: /root/
      loop:
        - rbd  -p images ls

    - name: Output 03_integration_existing
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_03_7.results }}"

- hosts: undercloud
  become: true
  become_user: stack
  gather_facts: False
  tasks:
    - name: 03_integration_existing
      shell: "{{ item }}"
      register: output_03_8
      args:
        chdir: /home/stack/
      loop:
        - source ~/overcloudrc && openstack network create example
        - source ~/overcloudrc && openstack subnet create --network example --subnet-range 172.16.0.0/24 subexample
        - source ~/overcloudrc && openstack flavor create --disk 1 m1.tiny
        - source ~/overcloudrc && openstack server create --flavor m1.tiny --image cirros cirros-instance
        - sleep 30
        - source ~/overcloudrc && openstack server list

    - name: Output 03_integration_existing
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_03_8.results }}"

- hosts: bastions
  become: true
  gather_facts: False
  tasks:
    - name: 03_integration_existing
      shell: "{{ item }}"
      register: output_03_9
      args:
        chdir: /root/
      loop:
        - rbd  -p vms ls

    - name: Output 03_integration_existing
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_03_9.results }}"

- hosts: undercloud
  become: true
  become_user: stack
  gather_facts: False
  vars:
    update_node_info: |
      cat >> ~/templates/environments/node-info.yaml <<EOF
        OvercloudCephStorageFlavor: baremetal
        CephStorageCount: 3
      EOF
    create_ceph_config: |
      cat > ~/templates/environments/ceph-config.yaml <<EOF
      parameter_defaults:
        CephConfigOverrides:
          mon_pg_warn_min_per_osd: 0
          mon_max_pg_per_osd: 1000
        CephAnsibleDisksConfig:
          devices:
            - /dev/vdb
            - /dev/vdc
      EOF
  tasks:
    - name: 04_director_deployed_Lab
      shell: "{{ item }}"
      register: output_04_1
      args:
        chdir: /home/stack/
      loop:
        - source ~/stackrc && openstack overcloud delete overcloud --yes
        - source ~/stackrc && openstack baremetal node list
        - source ~/stackrc && openstack baremetal node list --provision-state error -c  Name -f value | xargs -i openstack baremetal node undeploy {}
        - source ~/stackrc && openstack overcloud node import --introspect --provide ~/ceph-nodes.json
        - source ~/stackrc && openstack baremetal node set ceph01 --property capabilities=node:cephstorage-0,boot_option:local
        - source ~/stackrc && openstack baremetal node set ceph02 --property capabilities=node:cephstorage-1,boot_option:local
        - source ~/stackrc && openstack baremetal node set ceph03 --property capabilities=node:cephstorage-2,boot_option:local
        - source ~/stackrc && openstack baremetal introspection data save ceph01 | jq ".inventory.disks"
        - source ~/stackrc && openstack baremetal node set --property root_device='{"name":"/dev/sdb"}' ceph01
        - source ~/stackrc && openstack baremetal node set --property root_device='{"name":"/dev/sdb"}' ceph02
        - source ~/stackrc && openstack baremetal node set --property root_device='{"name":"/dev/sdb"}' ceph03
        - "{{ update_node_info }}"
        - "{{ create_ceph_config }}"
        - cat ~/deploy-with-ceph-nodes.sh

    - name: Output 04_director_deployed_Lab
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_04_1.results }}"

    - name: Deploy Overcloud with ceph nodes
      shell: source ~/stackrc && ~/deploy-with-ceph-nodes.sh
      args:
        chdir: /home/stack/
      async: 100000
      poll: 0
      register: install_overcloud

    - name: "install overcloud - ceph nodes - check on async task"
      async_status:
        jid: "{{ install_overcloud.ansible_job_id }}"
      register: job_result
      until: job_result.finished
      retries: 600

    - name: 04_director_deployed_Lab
      shell: "{{ item }}"
      register: output_04_2
      args:
        chdir: /home/stack/
      loop:
        - source ~/overcloudrc && openstack image create --file cirros-0.4.0-x86_64-disk.raw  --container-format bare --disk-format raw --public cirros
        - source ~/overcloudrc && openstack volume create --size 1 test-vol
        - source ~/stackrc && openstack server list
        - ssh -o StrictHostKeyChecking=no heat-admin@overcloud-controller-0.ctlplane sudo podman ps -f name=ceph
        - ssh -o StrictHostKeyChecking=no heat-admin@overcloud-controller-0.ctlplane sudo podman exec -ti ceph-mon-overcloud-controller-0 ceph -s
        - ssh -o StrictHostKeyChecking=no heat-admin@overcloud-controller-0.ctlplane sudo podman exec -ti ceph-mon-overcloud-controller-0 ceph osd tree
        - ssh -o StrictHostKeyChecking=no heat-admin@overcloud-controller-0.ctlplane sudo podman exec -ti ceph-mon-overcloud-controller-0 ceph osd lspools
        - ssh -o StrictHostKeyChecking=no heat-admin@overcloud-controller-0.ctlplane sudo podman exec -ti ceph-mon-overcloud-controller-0 rbd ls -p volumes
        - ssh -o StrictHostKeyChecking=no heat-admin@overcloud-controller-0.ctlplane sudo podman exec -ti ceph-mon-overcloud-controller-0 rbd ls -p images
        - ssh -o StrictHostKeyChecking=no heat-admin@overcloud-cephstorage-0.ctlplane sudo podman ps
        - ssh -o StrictHostKeyChecking=no heat-admin@overcloud-cephstorage-0.ctlplane sudo ip a

    - name: Output 04_director_deployed_Lab
      include_tasks: test_output.yml
      loop_control:
        loop_var: output
      loop: "{{ output_04_2.results }}"
