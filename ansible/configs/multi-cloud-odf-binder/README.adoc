== Overview

*multi-cloud-odf-binder* _config_ is used to do cross-cluster tasks
after all sub-components have been deployed

== Supported Cloud Providers

No cloud providers have been configured because this env_type is not meant to deploy resources, only interact with already available resources.

== Review the Env_Type variable file

For further information on customizing images consult the link:../../../docs/Creating_a_config.adoc[Creating a Config Guide]

== Review the `sample_vars.yml` variable file

----

---
guid:               test-config-00
env_type:           multi-cloud-odf-binder
cloud_provider:     none
...

----

== Developing with `hybrid-cloud-binder`

You should get a file of "extra-vars" from the AnarchySubject of this base component.

Find the AnarchySubject for this component and copy out the appropriate job data into a local yaml file on your laptop.
You might call it `my_sample_vars.yaml`

While developing, you can deploy this config by running the following command from the `ansible`
directory.

`ansible-playbook main.yml -e @my_sample_vars.yaml -e @configs/multi-cloud-odf-binder/sample_vars.yml`

Here's an abridged example.
This is the AnarchySubect - the source for our `job_vars`.
The following listing is how you'll want them to look in your `my_sample_vars.yaml`

[source,yaml]
----
apiVersion: anarchy.gpte.redhat.com/v1
kind: AnarchySubject
metadata:
    poolboy.gpte.redhat.com/resource-requester-name: Gaurav Midha
    poolboy.gpte.redhat.com/resource-requester-user: gmidha@redhat.com
  name: multi-cloud-odf.dev-xz9vx-3 <1>
  namespace: babylon-anarchy-gpte
  labels:
    anarchy.gpte.redhat.com/governor: multi-cloud.dev
    state: provision-pending
spec:
  governor: multi-cloud.dev
  vars:
    action_schedule:
      default_runtime: 4h
      maximum_runtime: 8h
      start: '2022-07-27T14:42:42Z'
      stop: '2022-07-27T18:42:42Z'
    current_state: provision-pending
    desired_state: started
    healthy: true
    job_vars: <2>
      aws_dev_a_provision_data: <3>
        openshift_console_url: >-
          https://console-openshift-console.apps.cluster-xz9vx-1.xz9vx-1.sandbox1523.opentlc.com
        openshift_api_url: 'https://api.cluster-xz9vx-1.xz9vx-1.sandbox1523.opentlc.com:6443'
        openshift_client_download_url: >-
          http://d3s3zqyaz8cp2d.cloudfront.net/pub/openshift-v4/clients/ocp/stable-4.10/openshift-client-linux.tar.gz
        users:
          user1:
            console_url: >-
              https://console-openshift-console.apps.cluster-xz9vx-1.xz9vx-1.sandbox1523.opentlc.com
            login_command: >-
              oc login -u user1 -p NjQ5NDQ2
              https://api.cluster-xz9vx-1.xz9vx-1.sandbox1523.opentlc.com:6443
            password: NjQ5NDQ2
          [ ... etc ... ]
        bastion_ssh_password: NjQ5NDQ2
        bastion_ssh_user_name: dev-admin
        bastion_public_hostname: bastion.xz9vx-1.sandbox1523.opentlc.com
        openshift_cluster_admin_username: admin
        openshift_cluster_admin_password: NjQ5NDQ2
      aws_hub_provision_data: <4>
        openshift_console_url: >-
          https://console-openshift-console.apps.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com
        openshift_api_url: 'https://api.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com:6443'
        openshift_client_download_url: >-
          http://d3s3zqyaz8cp2d.cloudfront.net/pub/openshift-v4/clients/ocp/stable-4.10/openshift-client-linux.tar.gz
        users:
          user1:
            console_url: >-
              https://console-openshift-console.apps.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com
            login_command: >-
              oc login -u user1 -p NjQ5NDQ2
              https://api.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com:6443
            password: NjQ5NDQ2
          [ ... etc ... ]
        bastion_ssh_password: NjQ5NDQ2
        rhacm_aws_access_key_id: AKIAWI5ERTGI3ZAQCZPJ
        api_url: 'https://api.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com:6443'
        bastion_ssh_user_name: dev-admin
        bastion_public_hostname: bastion.xz9vx-0.sandbox100.opentlc.com
        openshift_cluster_admin_username: admin
        acm_route: >-
          https://multicloud-console.apps.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com
        openshift_cluster_admin_password: NjQ5NDQ2
        rhacm_aws_subdomain: .sandbox100.opentlc.com
        rhacm_aws_secret_key: REDACTED
        web_console_url: >-
          https://console-openshift-console.apps.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com
      aws_region: us-east-2 <5>
      azure_dev_a_provision_data: <6>
        openshift_api_url: 'https://api.ocp4-xz9vx-2-ipi.azure.opentlc.com:6443'
        openshift_client_download_url: >-
          http://d3s3zqyaz8cp2d.cloudfront.net/pub/openshift-v4/clients/ocp/stable-4.9/openshift-client-linux.tar.gz
        openshift_console_url: >-
          https://console-openshift-console.apps.ocp4-xz9vx-2-ipi.azure.opentlc.com
        users:
          user1:
          [ ... etc ... ]
----
<1> The name of the AnarchySubject that called this env_type.  It has the "group"."catalog_item"."environment" format.
<2> The beginning of the `job_vars`
<3> All the `aws_dev_a_provision_data` came from a sub-component AnarchySubject.  Use this in your playbooks.
<4> All the `aws_hub_provision_data` came from a sub-component AnarchySubject.  Use these in your playbooks.
<5> `aws_region` is a `job_var` from this actual run, as defined in the CatalogItem.  Use this in your playbooks, too.
<6> All the `azure_dev_a_provision_data` came from a sub-component AnarchySubject.  Use these in your playbooks.


.`my_sample_vars.yaml`
[source,yaml]
----
aws_dev_a_provision_data:
  bastion_public_hostname: bastion.xz9vx-1.sandbox1523.opentlc.com
  bastion_ssh_password: NjQ5NDQ2
  bastion_ssh_user_name: dev-admin
  openshift_api_url: https://api.cluster-xz9vx-1.xz9vx-1.sandbox1523.opentlc.com:6443
  openshift_client_download_url: http://d3s3zqyaz8cp2d.cloudfront.net/pub/openshift-v4/clients/ocp/stable-4.10/openshift-client-linux.tar.gz
  openshift_cluster_admin_password: NjQ5NDQ2
  openshift_cluster_admin_username: admin
  openshift_console_url: https://console-openshift-console.apps.cluster-xz9vx-1.xz9vx-1.sandbox1523.opentlc.com
  users:
    user1:
      console_url: https://console-openshift-console.apps.cluster-xz9vx-1.xz9vx-1.sandbox1523.opentlc.com
      login_command: 'oc login -u user1 -p NjQ5NDQ2 https://api.cluster-xz9vx-1.xz9vx-1.sandbox1523.opentlc.com:6443'
      password: NjQ5NDQ2
    [ ... etc ... ]
aws_hub_provision_data:
  acm_route: https://multicloud-console.apps.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com
  api_url: https://api.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com:6443
  bastion_public_hostname: bastion.xz9vx-0.sandbox100.opentlc.com
  bastion_ssh_password: NjQ5NDQ2
  bastion_ssh_user_name: dev-admin
  openshift_api_url: https://api.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com:6443
  openshift_client_download_url: http://d3s3zqyaz8cp2d.cloudfront.net/pub/openshift-v4/clients/ocp/stable-4.10/openshift-client-linux.tar.gz
  openshift_cluster_admin_password: NjQ5NDQ2
  openshift_cluster_admin_username: admin
  openshift_console_url: https://console-openshift-console.apps.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com
  rhacm_aws_access_key_id: AKIAWI5ERTGI3ZAQCZPJ
  rhacm_aws_secret_key: REDACTED
  rhacm_aws_subdomain: .sandbox100.opentlc.com
  users:
    user1:
      console_url: https://console-openshift-console.apps.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com
      login_command: 'oc login -u user1 -p NjQ5NDQ2 https://api.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com:6443'
      password: NjQ5NDQ2
    [ ... etc ... ]
  web_console_url: https://console-openshift-console.apps.cluster-xz9vx-0.xz9vx-0.sandbox100.opentlc.com
aws_region: us-east-2
azure_dev_a_provision_data:
  openshift_api_url: https://api.ocp4-xz9vx-2-ipi.azure.opentlc.com:6443
  openshift_client_download_url: http://d3s3zqyaz8cp2d.cloudfront.net/pub/openshift-v4/clients/ocp/stable-4.9/openshift-client-linux.tar.gz
  openshift_console_url: https://console-openshift-console.apps.ocp4-xz9vx-2-ipi.azure.opentlc.com
  users:
    user1:
      login_command: 'oc login -u user1 -p NjQ5NDQ2 https://api.ocp4-xz9vx-2-ipi.azure.opentlc.com:6443'
      password: NjQ5NDQ2
    [ ... etc ... ]
guid: xz9vx-3
----

== Deploying the `multi-cloud-odf-binder`

You can deploy this config by running the following command from the `ansible`
directory.

`ansible-playbook main.yml -e @my_sample_vars.yaml -e @configs/multi-cloud-odf-binder/sample_vars.yml`

=== To Delete an environment

TODO:
. Remove clusters from RHACM

`ansible-playbook destroy.yml -e @configs/multi-cloud-odf-binder/sample_vars.yml`
