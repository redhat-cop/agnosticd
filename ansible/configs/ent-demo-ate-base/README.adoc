== Overview

*ent-demo-ate-base* is a config based upon prior art, aka as `cp -r` the config,*ansible-multi-node* for the purpose of building a highly reliable and repeatable for structure for use with Ansible Automation Platform 2 (AAP2) demos and workshops. Its *primary* purpose is the base for the Automate the Enterprise demo where it will provide the base underlying infrastructure. 

* Bastion host (with bookbag and/or VSCode Server)
* AAP2 Controller (non clustered but easily extensible)
* AAP2 Hub (non clustered but easily extensible)
* Future additions could include
** Per deploy Satellite

It is designed to support Hybrid Cloud use. In other words the primary infrastructure can be deployed to AWS for example Bart the automation controller infrastructure could contain credentials allowing it to deploy subsequent infrastructure to other public or private loud infrastructures such as Azure, vSphere, OpenStack, GCP etc.

To provide Hybrid Cloud use cases it is designed to be used in a *chained config* where this `config` simply deploys a simple foundation of AAP2 infrastructure and the Cloud Credentials come from, other, sandbox configs/deploys which are then injected by the `ent-demo-ate-binder`

See the *Developer Notes* below for more details

*NB* this currently is basically a cp -r of `base-app2-infra`. See that README

=== Basic Architecture and Overview

This config uses a number of new roles, and patterns, that differ from older _Ansible Type_ configs:

* New role `bastion-base` - lighter and less crufty than older roles, basically does less
** Supports new packages list `agd_bastion_packages` simplifying bastion only packaging v `common_packages`
** New role `user-create-ansible-service-account`

* RedHat Enterprise Linux `bastion`

=== Hybrid Cloud Subscription and Credential Handling

This config comes up "credless" and relies on another config to inject AAP2 Automation Credentials. See the simple, but yet to be written (as of 2022-07-26) _binder config_ `ent-demo-ate-binder`

== Developers Notes

Tested and developed with:

* Ansible `2.11`
* Venv `agnosticd-ansible-2.11-python-3.8`
* Deployed with `ansible-playbook` (`2.11` as stated above)
** i.e. at this time no work has been done to validate with `ansible-navigator`
** or execution environments though little difficulty (and some gains) are anticipated
* Makes fairly extensive use of software switches aka booleans etc
** Please continue this trend so everything can be turned on and off simply by vars
** `when: install_vscode_server | default(false) | bool`

NOTE: At this writing, July 2022, the AgnosticD `ec2` cloud_provider uses a number of depreciated or obsolete tasks. See configs `requirements.yaml` to ensure correct collections e.g. `amazon.aws` Laptop developers in particular may need to resolve Collections via `export ANSIBLE_COLLECTIONS_PATH=...` See *LIfecycle Notes* below for implications and why `config` *currently* needs its own `lifecycle.yml`

=== Style etc.

This `config` attempts to offload virtually all its work into roles and as a general guideline the
configs playbooks (pre_, post etc) should primarily or even exclusively avoid embedding other tasks within the plays. IE these plays should try to limit themselves yo:

. `import_role` or `include_role`
. `set_fact`
.  `agnosticd_user_info`

Pretty much everything else should be a role, protected by a software switch `when: ... default(false) | bool`. It goes without saying these should all be FQCN e.g. `ansible.builtin.set_fact`

=== Makefile

An *optional* `Makefile` is provided as this self-documents how the config deploys from a laptop or similar. It is not an essential part of the process but is extremely useful, a simple `make` will list the functionality and modern shells should offer tab completion. Examples:

* `make deploy|destroy`
* `make ssh-bastion`

=== Lifecycle Notes

Config has its own lifecycle.yml for 2 reasons:

. Existing AWS ec2 lifecycle breaks on `ec2_instance_facts` and doesn't like depreciated `ec2` module
.. Updated to modern, FQCNs, modules `amazon.aws.ec_instance_info` and `amazon.aws.ec_instance` 
. More complex lifecycle issues anticipated going forward e.g. Hybrid Cloud sandboxes etc

=== Development *TIPS*

* The `output_dir` inventory is *GOLD* and speeds up development:
** e.g. `ansible-playbook role-wrapping-playbook-to-test.yml -i /tmp/output_dir/inventory_post_software.yaml -e @~/secrets/secret-aws-ate-no-sandbox.yml`
* Use a virtualenv (venv)
* Consider using ANSIBLE_COLLECTIONS_PATH to *hide* more up to date collections you may have installed
** Can be an issue on laptop deployments e.g. you have _latest and greatest_ in`~/.ansible/collections`
** Example, assumes you are in repo root dir: `export ANSIBLE_COLLECTIONS_PATH=$(pwd)/collections` 

NOTE: In some places this config has started to introduce a `agd_` variable prefix e.g. `agd_install_common` instead of `install_common`. This is to avoid collisions and is arguably a superior practice.

== Sample files

* A typical secrets file:

[source,yaml]
----
---
#
# Set cloud provider here as these ties 100% to secrets
#

cloud_provider: ec2

#
# Sandbox creds 2022-07-20
#

aws_access_key_id:                              <YOUR-AWS-SANDBOX-KEY>
aws_secret_access_key:                          <YOUR-AWS-SECRET-ACCESS-SANDBOX-KEY>
subdomain_base_suffix:                          <subdomain from sandbox email, including leading `.`>

#
# Satellite Creds, use labsat-HA and dedicated activation key for isolation
#

repo_method:                                    satellite
set_repositories_satellite_ha:                  True
set_repositories_satellite_url:                 labsat-ha.opentlc.com
set_repositories_satellite_org:                 Red_Hat_GPTE_Labs
set_repositories_satellite_activationkey:       <OBTAIN FROM YOUR ADMIN>


# Remote resources for download

deploy_automationcontroller_installer_url:      "https://www.opentlc.com/satellite/ansible-automation-platform-setup-bundle-2.0.0-1-early-access.tar.gz"
deploy_automationcontroller_manifest_url:       "https://www.opentlc.com/satellite/automationcontroller_manifest.zip"
deploy_automationcontroller_asset_username:     <USERNAME>
deploy_automationcontroller_asset_password:     <PASSWORD>

remote_resources_username:                      
remote_resources_password:                      
...
----

=== Totally Optional File 

Whilst developing I, Tony (tok@redhat.com) basically setup my develop environment like this:

. `workon agnosticd-ansible-2.11-python-3.8` # or however you manage venvs
. `source tok-env.sh` in the root directory of AgnosticD

* An example of my `tok-env.sh`:

[source,bash]
----
export ANSIBLE_COLLECTIONS_PATH=/Users/tok/repos/agnosticd/repo/agnosticd/collections
export ANSIBLE_LOG_PATH=/tmp/output_dir/ate-01
export ANSIBLE_CONFIG=tok-ansible.cfg

export MAKEFILE=$(pwd)/ansible/configs/ent-demo-ate-base/Makefile

# old legacy config
alias mk="make -f $MAKEFILE "
----

NOTE: The above is purely optional but should perhaps help others do laptop based deploys. Also after doing this you can simply `mk dep<TAB>` for example to do a deploy, or `mk ssh-b<TAB>` to ssh to a bastion

=== Common Errors and Mistakes

* Make sure you are using a supported venv and ansible version




