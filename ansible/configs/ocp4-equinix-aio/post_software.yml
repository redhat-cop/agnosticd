---
- name: Step 005 Post Software
  hosts: localhost
  gather_facts: false
  become: false
  tasks:
    - debug:
        msg: "Step 005 Post Software"

- name: Deploy some operators
  hosts: bastion-vm
  tasks:
    - name: Make .kube directory
      ansible.builtin.file:
        path: /root/.kube/
        state: directory
      when: ocp4_aio_deploy_type == 'sno'

    - name: Make rhacm the default cluster for bastion oc commands
      when: ocp4_aio_deploy_type == 'sno'
      ansible.builtin.copy:
        remote_src: yes
        src: /root/sno-rhacm/auth/kubeconfig
        dest: /root/.kube/config

    - name: Setting up OCS Storage
      include_role:
        name: ocp4_aio_role_ocs
      vars:
        deploy_type: "{{ ocp4_aio_deploy_type }}"
        deploy_sno: "{{ ocp4_aio_deploy_sno }}"
        deploy_ipi: "{{ ocp4_aio_deploy_ipi }}"
        deploy_compact: "{{ ocp4_aio_deploy_compact }}"
        deploy_ocs: "{{ ocp4_aio_deploy_ocs }}"
      when: ocp4_aio_deploy_ocs and ocp4_aio_deploy_type == 'ipi'

    - name: Setting up NFS Storage
      include_role:
        name: ocp4_aio_role_nfsmount
      vars:
        deploy_type: "{{ ocp4_aio_deploy_type }}"
        deploy_sno: "{{ ocp4_aio_deploy_sno }}"
        deploy_ipi: "{{ ocp4_aio_deploy_ipi }}"
        deploy_ocs: "{{ ocp4_aio_deploy_ocs }}"
      when: not ocp4_aio_deploy_ocs or ocp4_aio_deploy_type == 'sno'

    - name: Enable internal registry
      include_role:
        name: ocp4_aio_role_imgreg
      vars:
        deploy_type: "{{ ocp4_aio_deploy_type }}"
        deploy_sno: "{{ ocp4_aio_deploy_sno }}"
        deploy_ipi: "{{ ocp4_aio_deploy_ipi }}"
        deploy_ocs: "{{ ocp4_aio_deploy_ocs }}"

    - name: Installing ACM Operator
      include_role:
        name: ocp4_aio_role_acm
      vars:
        deploy_type: "{{ ocp4_aio_deploy_type }}"
        deploy_sno: "{{ ocp4_aio_deploy_sno }}"
        deploy_ipi: "{{ ocp4_aio_deploy_ipi }}"
        deploy_ocs: "{{ ocp4_aio_deploy_ocs }}"
      when: ocp4_aio_deploy_acm or ocp4_aio_deploy_ocp_plus or ocp4_aio_deploy_sno

    - name: Installing ACS operator
      include_role:
        name: ocp4_aio_role_acs
      vars:
        deploy_type: "{{ ocp4_aio_deploy_type }}"
        deploy_sno: "{{ ocp4_aio_deploy_sno }}"
        deploy_ipi: "{{ ocp4_aio_deploy_ipi }}"
        deploy_ocs: "{{ ocp4_aio_deploy_ocs }}"
      when: ocp4_aio_deploy_acs or ocp4_aio_deploy_ocp_plus or ocp4_aio_deploy_sno

## TODO : need to figure out how to make this work to replace our modules
    # - name: Installing ACS Central
    #   include_role: 
    #     name: ocp4_workload_stackrox_central
    #   when: ocp4_aio_deploy_acs or ocp4_aio_deploy_ocp_plus or ocp4_aio_deploy_sno

    # - name: Installing ACS sensors
    #   include_role:
    #     name: ocp4_workload_stackrox_sensor
    #   when: ocp4_aio_deploy_acs or ocp4_aio_deploy_ocp_plus or ocp4_aio_deploy_sno

    # - name: Prepare for sensors install on edge1
    #   when: ocp4_aio_deploy_sno
    #   ansible.builtin.copy:
    #     remote_src: yes
    #     src: /root/sno-edge1/auth/kubeconfig
    #     dest: /root/.kube/config

    # - name: Installing ACS sensors on Edge1
    #   when: ocp4_aio_deploy_sno
    #   include_role:
    #     name: ocp4_workload_stackrox_sensor

    # - name: Prepare for sensors install on edge2
    #   when: ocp4_aio_deploy_sno
    #   ansible.builtin.copy:
    #     remote_src: yes
    #     src: /root/sno-edge2/auth/kubeconfig
    #     dest: /root/.kube/config

    # - name: Installing ACS sensors on Edge2
    #   when: ocp4_aio_deploy_sno
    #   include_role:
    #     name: ocp4_workload_stackrox_sensor

    - name: Installing CNV Operator
      include_role:
        name: ocp4_aio_role_cnv
      vars:
        deploy_type: "{{ ocp4_aio_deploy_type }}"
        deploy_sno: "{{ ocp4_aio_deploy_sno }}"
        deploy_ipi: "{{ ocp4_aio_deploy_ipi }}"
        deploy_ocs: "{{ ocp4_aio_deploy_ocs }}"
      when: ocp4_aio_deploy_cnv

    - name: Print Bastion Connection Information
      agnosticd_user_info:
        msg: "{{ item }}"
      loop:
        - "Lab Instructions : https://github.com/RHFieldProductManagement/baremetal-ipi-lab"
        - "Host you will be using for lab instructions : {{ hostvars['hypervisor']['public_ip_address'] }}"
        - "SSH User : {{ student_name }}"
        - "SSH Password : {{ hostvars['hypervisor']['student_password'] }}"
        - "OpenShift web console : https://console-openshift-console.apps.apps.aio.example.com"
#        - "kubeadmin user Password : {{ hostvars['kube_holder']['kubeadmin_password'] }}"

    - name: Print Guacamole Information
      when: ocp4_aio_deploy_guacamole
      agnosticd_user_info:
        msg: "{{ item }}"
      loop:
        - "As you've enabled Guacamole support, you can access everything you need without a proxy."
        - "To access the environment via your web-browser only (Guacamole)"
        - "Use this URL: http://{{ hostvars['hypervisor']['public_ip_address'] }}:8080/guacamole"
        - "Username: guacadmin"
        - "Password: {{ hostvars['guac_holder']['guac_shared_password'] }}"
        - "The 'Lab Desktop' will give you a GNOME desktop environment, and 'Bastion SSH' just CLI access."

    - name: Print Kube Configuration for IPI
      when: ocp4_aio_deploy_ipi
      agnosticd_user_infos:
        msg: "{{ item }}"
      loop:
        - "As you've requested OpenShift to be installed, you can access the console either via proxy or Guacamole (if enabled)."
        - "To access the environment via a Squid Proxy, open a port-forwarded session:"
        - "$ ssh root@{{ hostvars['hypervisor']['public_ip_address'] }} -L 8080:192.168.123.100:3128"
        - "Then set your local proxy server to localhost:8080 and enable DNS over SOCKS"
        - "The console is available at: https://console-openshift-console.apps.aio.example.com"
        - "The kubeadmin password is: {{ hostvars['kube_holder']['kubeadmin_password'] }}"
        - "If you'd like CLI access, the bastion host will have already been setup - `ssh root@192.168.123.100`"
        - "You should then automatically have oc/kubectl access to the cluster. Check out ~/ocp-install/auth/."


- name: Display kube infos for SNO
  hosts: bastion-vm
  tasks:
      when: ocp4_aio_deploy_sno
      agnosticd_user_infos:
        msg: "{{ item }}"
      loop:
        - "As you've requested OpenShift to be installed, you can access the console either via proxy or Guacamole (if enabled)."
        - "To access the environment via a Squid Proxy, open a port-forwarded session:"
        - "$ ssh root@{{ hostvars['hypervisor']['public_ip_address'] }} -L 8080:192.168.123.100:3128"
        - "Then set your local proxy server to localhost:8080 and enable DNS over SOCKS"
        - "The console for rhacm cluster is available at: https://console-openshift-console.apps.rhacm.example.com"
        - "The kubeadmin password for the rhacm cluster  is: {{ hostvars['rhacm_holder']['kubeadmin_password'] }}"
        - "The console for edge1 cluster is available at: https://console-openshift-console.apps.edge1.example.com"
        - "The kubeadmin password for edge1 cluster is: {{ hostvars['edge1_holder']['kubeadmin_password'] }}"
        - "The console for edge2 cluster is available at: https://console-openshift-console.apps.edge2.example.com"
        - "The kubeadmin password for edge2 cluster is: {{ hostvars['edge2_holder']['kubeadmin_password'] }}"
        - "If you'd like CLI access, the bastion host will have already been setup - `ssh root@192.168.123.100`"
        - "You should then automatically have oc/kubectl access to the cluster. Check out ~/sno-{rhacm,edge1,edge2}/auth/."

- name: PostSoftware flight-check
  hosts: localhost
  connection: local
  gather_facts: false
  become: false
  tags:
    - post_flight_check
  tasks:
    - debug:
        msg: "Post-Software checks completed successfully"
