
# The output_dir holds all of the files generated during the deployment
# This includes generated Heat templates, SSH config, SSH keys
# This must be an absolute path and no vars (like $HOME or ~)
output_dir: /tmp/output_dir

# The {{ guid }} is used everywhere and it is what differentiates otherwise
# identical environments. Make this unique. Usually they are 4 characters, but
# it can be any reasonable length.
guid: notset

# The type of cloud provider this will be deployed to
cloud_provider: osp

# Authenication credentials for OpenStack in order to create the things.
# These should be included with your secrets, but are listed here for reference
# osp_auth_url:
# osp_auth_username:
# osp_auth_password:
# osp_auth_cloud:
# osp_auth_project_domain: #usually set to "default"
# osp_auth_user_domain: #usually set to "default"

# This is an account that must exist in OpenStack.
# It is used to create projects, access, Heat templates
admin_user: opentlc-mgr

# This is the user that Ansible will use to connect to the nodes it is
# configuring from the admin/control host
ansible_user: cloud-user

# This needs to be True for 4.3 and earlier.
# For OpenShift 4.4 and later it can be false
osp_use_swift: false

# The domain that you want to add DNS entries to
#osp_cluster_dns_zone: FROMSECRET

# The dynamic DNS server you will add entries to.
# NOTE: This is only applicable when {{ use_dynamic_dns}} is true
#osp_cluster_dns_server: FROMSECRET

# Whether to wait for an ack from the DNS servers before continuing
wait_for_dns: true

# Authenticaion for DDNS, Must be set in secrets
# ddns_key_name:
# ddns_key_algorithm:                # default value set to: "hmac-md5"
# ddns_secret_name:

# The base domain
# osp_cluster_dns_zone needs to come from secrets
# subdomain_base_suffix: "{{ osp_cluster_dns_zone }}"
ocp4_base_domain: "{{ osp_cluster_dns_zone }}"

# It will pull the subnet CIDR from the defined network below, based on the
# name you define for {{ ocp_network }}
ocp_network: "ocp"
ocp_network_subnet_cidr: "{{ networks | json_query(query_subnet_cidr) | first }}"
query_subnet_cidr: "[?name=='{{ ocp_network }}'].subnet_cidr"

# This will provision an API and Ingress FIP
openshift_fip_provision: True

# This requires DDNS or other DNS solution configured
# If enabled, it will add DNS entries for the API and Ingress FIPs
openshift_fip_dns: True

# The external network in OpenStack where the floating IPs (FIPs) come from
provider_network: external

# Provision Floating IPs for API and Ingress
additional_fips:
  ocp_api_fip:
    description: The floating IP of the OpenShift API
    network: "{{ provider_network }}"
  ocp_ingress_fip:
    description: The floating IP of the OpenShift ingress
    network: "{{ provider_network }}"

# The name of the project that will be created in OpenStack for the user
osp_project_name: "{{ guid }}-project"

# The name of the cloud where ocp-cluster will be created
osp_cloud_name: "{{ osp_project_name }}"

# Set this to true if you need to create a new project in OpenStack
# This should almost always be set to true for OpenShift installations
# If it is set to false, the {{ osp_project_name }} must already exist and
# should be able to run whatever you are deploying
osp_project_create: true


# The name of the OpenShift cluster that will be deployed.
# This is primarily used if you want to automate the OpenShift deployment.
cluster_name: "cluster-{{ guid }}"

# Used to add metadata (tags) to OpenStack objects created
project_tag: "{{ env_type }}-{{ guid }}"

# Why is this config being deployed? Override for specific environments
# Some valid: development, ilt, production, event
purpose: development

# Enable this if you want to use IPA for user authentication.
# Mutually exclusive with {{ install_student_user }}
install_ipa_client: false

# Enable this if you want to create a user on the bastion
# Mutually exclusive with {{ install_ipa_client }}
install_student_user: false

# TODO: What does this really do besides run the role?
set_env_authorized_key: true
env_authorized_key: "{{guid}}key"
key_name: "default_key_name"

# Run the bastion-lite role
install_bastion: true

# This config was written with the expectation of using python3
# Several of the roles that it depends on only work with python2,
# so they had to be modified to handle python3 as well. Use this
# var so that it is passed along and influences how those roles run.
all_use_python3: true

# FTL is used for grading and solving. It will pull in the external ftl-injector role.
# This might be enabled when we have solvers to run or graders for ILT
install_ftl: false

# TODO: Decide on whether to use sat or give access to repos directly with key
# This will tell Agnosticd to use either:
# satellite, rhn, or file for repos
# Only satellite is supported for RHEL 8
repo_method: satellite

# If using satellite, these are needed and should
# come from secrets:
# satellite_url: satellite.opentlc.com
# satellite_org: # This should be stored in secrets
# satellite_activationkey: # This should be stored in secrets

# use_content_view: true
# If using file, these are needed in addition to the repos_template.j2 file:
osrelease: '4.4.0'
repo_version: '4.4'

# own_repo_path: points to a repo mirror. Must defined in secrets
#own_repo_path: <FROM_SECRETS>

# Packages to install on all of the hosts deployed as part of the agnosticd config
# This invokes the "common" role
install_common: true

# As part of the "common" role, this cause it to do a yum update on the host
update_packages: false

# Number of Nodes
master_instance_count: 3
worker_instance_count: 3

# Install OpenShift 4 - and which version
install_ocp4: true
ocp4_installer_version: "4.4.9"

# Run logic to enable cluster shutdown before 24h initial certificate rotation 
# Only works for OCP 4.1 and 4.2. OCP 4.4 should no longer require this.
ocp4_enable_cluster_shutdown: false


# Pull secret needs to be defined in secrets
# Get from https://try.openshift.com
# ocp4_pull_secret: ''

# YAML List of Infrastructure Workloads.
# REQUIRES Ansible 2.7+ on the deployer host
# Empty by default - to be set by specific configurations
infra_workloads:
  - ocp4_workload_authentication
  - ocp4_workload_le_certificates

# YAML List of Student Workloads.
# REQUIRES Ansible 2.7+ on the deployer host
# Empty by default - to be set by specific configurations
# Can only be used with htpasswd authentication
student_workloads: []

# Some workloads create infrastructure that needs to be removed
# when deleting the software or infrastructure
remove_workloads: []

# A list of the private networks and subnets to create in the project
# You can create as many as you want, but at least one is required.
# Use the name of the networks where appropriate in the instance list
networks:
- name: ocp
  shared: "false"
  subnet_cidr: 192.168.47.0/24
  gateway_ip: 192.168.47.1
  allocation_start: 192.168.47.10
  allocation_end: 192.168.47.254
  dns_nameservers: []
  create_router: true

# Security groups and associated rules. This will be provided
#when the Heat template is generated separate groups and rules
security_groups:
  - name: HanaSG
    rules:
      - name: S4HANA
        description: "Access to S4HANA"
        from_port: 3200
        to_port: 3600
        protocol: tcp
        cidr: "0.0.0.0/0"
        rule_type: Ingress
      - name: HanaSSHPrivate
        description: "SSH private"
        from_port: 22
        to_port: 22
        protocol: tcp
        cidr: "0.0.0.0/0"
        rule_type: Ingress
        group: BastionSG
      - name: HanaUDPPortsPrivate
        description: "Only from bastion"
        from_port: 1
        to_port: 65535
        protocol: udp
        group: BastionSG
        rule_type: Ingress
      - name: HanaTCPPPortsPrivate
        description: "Only from bastion"
        from_port: 1
        to_port: 65535
        protocol: tcp
        group: BastionSG
        rule_type: Ingress
  - name: BastionSG
    rules:
      - name: BastionUDPPortsPrivate
        description: "Only from bastion"
        from_port: 1
        to_port: 65535
        protocol: udp
        group: HanaSG
        rule_type: Ingress
      - name: BastionTCPPPortsPrivate
        description: "Only from bastion"
        from_port: 1
        to_port: 65535
        protocol: tcp
        group: HanaSG
        rule_type: Ingress

# -------------------------------------------------------------------
# OpenStack Instances
# -------------------------------------------------------------------

# Bastion Configuration
bastion_instance_type: "2c2g30d"
#bastion_instance_image: rhel-server-7.7-update-2
bastion_instance_image: rhel-8.1
# Root Filesystem Size
bastion_rootfs_size: 30

# Instance Types to be passed to OpenShift Installer
master_instance_type: 4c16g30d
worker_instance_type: 16c30g100d

# Variable used to identify the request being made by a Red Hatter or Partner (external)
rh_internal: false

# SAP HANA and S/4HANA instances variables

hana_instance_image: rhel-8.1
hana_instance_type: "sap-8-128"
rootfs_size_hana: "{{ rootfs_size_hana }}"
pv_size_hana: 500

s4hana_instance_image: rhel-8.1
s4hana_instance_type: "sap-4-64"
rootfs_size_s4hana: "{{ rootfs_size_s4hana }}"
pv_size_s4hana: 100

# SAP Software image and variables
sap_software_image: sap-software-v1.5
sap_software_size: "{{ software_size }}"

# Instances to be provisioned in new project
# Provide these as a list.
# Each instance type can have any number of replicas deployed with the same
# configuration.
# Metadata in OpenStack is equivelent to tags in AWS
# These instances will be created with Cinder persistent volumes
instances:
- name: "bastion-{{ guid }}"
  count: 1
  unique: true
  public_dns: true
  dns_loadbalancer: true
  floating_ip: true
  image_id: "{{ bastion_instance_image }}"
  sofware_image_id: "{{ sap_software_image }}"
  flavor:
    osp: "{{ bastion_instance_type }}"
  tags:
    - key: "AnsibleGroup"
      value: "bastions"
    - key: "ostype"
      value: "linux"
    - key: "instance_filter"
      value: "{{ env_type }}-{{ email }}"
    - key: ansible_python_interpreter
      value: /usr/libexec/platform-python
  rootfs_size: "{{ bastion_rootfs_size }}"
  network: ocp
  softwarefs_size: "{{ software_size }}"
  security_groups:
    - BastionSG

- name: "hana-{{ guid }}"
  count: 1
  public_dns: false
  dns_loadbalancer: false
  floating_ip: false
  image_id: "{{ hana_instance_image }}"
  flavor:
    osp: "{{ hana_instance_type }}"
  tags:
    - key: "AnsibleGroup"
      value: "hanas"
    - key: "ostype"
      value: "rhel"
    - key: "instance_filter"
      value: "{{ env_type }}-{{ email }}"
    - key: ansible_python_interpreter
      value: /usr/libexec/platform-python
  rootfs_size: "50"
  network: ocp
  volumes:
    - volume_name: "hana_pv"
      volume_size: "{{ pv_size_hana }}"
  security_groups:
    - HanaSG

- name: "s4hana-{{ guid }}"
  count: 1
  public_dns: true
  dns_loadbalancer: true
  floating_ip: true
  image_id: "{{ s4hana_instance_image }}"
  flavor:
    osp: "{{ s4hana_instance_type }}"
  tags:
    - key: "AnsibleGroup"
      value: "s4hanas"
    - key: "ostype"
      value: "rhel"
    - key: "instance_filter"
      value: "{{ env_type }}-{{ email }}"
    - key: ansible_python_interpreter
      value: /usr/libexec/platform-python
  rootfs_size: "50"
  network: ocp
  volumes:
    - volume_name: "s4hana_pv"
      volume_size: "{{ pv_size_s4hana }}"
  security_groups:
    - HanaSG