---
- name: Create Namespaces per Team
  kubernetes.core.k8s:
    state: present
    definition: |
      apiVersion: v1
      kind: Namespace
      metadata:
        name: {{ocp4_workload_cloud_native_robot_user}}-{{ item }}
      spec: {}
  with_items:
    - ai
    - dev

# ---------------------------------------------------------
# Create Object Bucket & OpenShift AI Data Connection
# ---------------------------------------------------------

- name: "Create ObjectBucketClaim {{ ocp4_workload_cloud_native_robot_user }}"
  kubernetes.core.k8s:
    state: present
    definition: |
      apiVersion: objectbucket.io/v1alpha1
      kind: ObjectBucketClaim
      metadata:
        name: {{ ocp4_workload_cloud_native_robot_workbench_bucket_name }}
        namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
      spec:
        additionalConfig:
          bucketclass: noobaa-default-bucket-class
        generateBucketName: "{{ ocp4_workload_cloud_native_robot_workbench_bucket_name }}"
        storageClassName: openshift-storage.noobaa.io

- name: "Check if ObjectBucketClaim {{ ocp4_workload_cloud_native_robot_user }} is bound"
  kubernetes.core.k8s_info:
    api_version: objectbucket.io/v1alpha1
    kind: ObjectBucketClaim
    name: "{{ ocp4_workload_cloud_native_robot_workbench_bucket_name }}"
    namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
  register: obc
  retries: 5
  until: obc.resources[0].status.phase == "Bound"

- name: "Fetch Secret {{ ocp4_workload_cloud_native_robot_user }}"
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Secret
    name: "{{ ocp4_workload_cloud_native_robot_workbench_bucket_name }}"
    namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
  register: obc_secret

- name: "Fetch ConfigMap {{ ocp4_workload_cloud_native_robot_user }}"
  kubernetes.core.k8s_info:
    api_version: v1
    kind: ConfigMap
    name: "{{ ocp4_workload_cloud_native_robot_workbench_bucket_name }}"
    namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
  register: obc_cm


- name: "Create OpenShift AI DataConnection - {{ ocp4_workload_cloud_native_robot_user }}"
  kubernetes.core.k8s:
    state: present
    definition: |
      apiVersion: v1
      kind: Secret
      metadata:
        finalizers:
          - github.com/cloud-native-robotz-hackathon_infrastructure_issues_86
        annotations:
          opendatahub.io/connection-type: s3
          openshift.io/display-name: "{{ ocp4_workload_cloud_native_robot_workbench_bucket_name }}"
        labels:
          opendatahub.io/dashboard: "true"
          opendatahub.io/managed: "true"
        name: {{ ocp4_workload_cloud_native_robot_workbench_bucket_name }}-ai-connection
        namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
      type: Opaque
      stringData:
        AWS_ACCESS_KEY_ID: "{{ obc_secret.resources[0].data.AWS_ACCESS_KEY_ID | b64decode }}"
        AWS_DEFAULT_REGION: "us-east-1"
        AWS_S3_BUCKET: "{{ obc_cm.resources[0].data.BUCKET_NAME  }}"
        AWS_S3_ENDPOINT: "https://s3-openshift-storage.{{ openshift_cluster_ingress_domain }}"
        AWS_SECRET_ACCESS_KEY: "{{ obc_secret.resources[0].data.AWS_SECRET_ACCESS_KEY | b64decode }}"


- name: "Create OpenShift AI DataConnection Backup - {{ ocp4_workload_cloud_native_robot_user }}"
  kubernetes.core.k8s:
    state: present
    definition: |
      apiVersion: v1
      kind: Secret
      metadata:
        name: {{ ocp4_workload_cloud_native_robot_workbench_bucket_name }}-ai-connection-backup
        namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
      type: Opaque
      stringData:
        AWS_ACCESS_KEY_ID: "{{ obc_secret.resources[0].data.AWS_ACCESS_KEY_ID | b64decode }}"
        AWS_DEFAULT_REGION: "us-east-1"
        AWS_S3_BUCKET: "{{ obc_cm.resources[0].data.BUCKET_NAME  }}"
        AWS_S3_ENDPOINT: "https://s3-openshift-storage.{{ openshift_cluster_ingress_domain }}"
        AWS_SECRET_ACCESS_KEY: "{{ obc_secret.resources[0].data.AWS_SECRET_ACCESS_KEY | b64decode }}"


# ---------------------------------------------------------
# Create Object Bucket & OpenShift AI Data Science Pipeline Server
# ---------------------------------------------------------

- name: "Create ObjectBucketClaim {{ ocp4_workload_cloud_native_robot_user }}"
  kubernetes.core.k8s:
    state: present
    definition: |
      apiVersion: objectbucket.io/v1alpha1
      kind: ObjectBucketClaim
      metadata:
        name: "data-science-pipeline-bucket"
        namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
      spec:
        additionalConfig:
          bucketclass: noobaa-default-bucket-class
        generateBucketName: "data-science-pipeline-bucket"
        storageClassName: openshift-storage.noobaa.io

- name: "Check if ObjectBucketClaim {{ ocp4_workload_cloud_native_robot_user }} is bound"
  kubernetes.core.k8s_info:
    api_version: objectbucket.io/v1alpha1
    kind: ObjectBucketClaim
    name: "data-science-pipeline-bucket"
    namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
  register: obc
  retries: 5
  until: obc.resources[0].status.phase == "Bound"

- name: "Fetch Secret {{ ocp4_workload_cloud_native_robot_user }}"
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Secret
    name: "data-science-pipeline-bucket"
    namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
  register: obc_secret

- name: "Fetch CnofigMap {{ ocp4_workload_cloud_native_robot_user }}"
  kubernetes.core.k8s_info:
    api_version: v1
    kind: ConfigMap
    name: "data-science-pipeline-bucket"
    namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
  register: obc_cm

- name: "Create data-science-pipeline-bucket-ai-connection - {{ ocp4_workload_cloud_native_robot_user }}"
  kubernetes.core.k8s:
    state: present
    definition: |
      apiVersion: v1
      kind: Secret
      metadata:
        finalizers:
          - github.com/cloud-native-robotz-hackathon_infrastructure_issues_86
        annotations:
          opendatahub.io/connection-type: s3
          openshift.io/display-name: "data-science-pipeline-bucket"
        labels:
          opendatahub.io/dashboard: "true"
          opendatahub.io/managed: "true"
        name: data-science-pipeline-bucket-ai-connection
        namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
      type: Opaque
      stringData:
        AWS_ACCESS_KEY_ID: "{{ obc_secret.resources[0].data.AWS_ACCESS_KEY_ID | b64decode }}"
        AWS_DEFAULT_REGION: "us-east-1"
        AWS_S3_BUCKET: "{{ obc_cm.resources[0].data.BUCKET_NAME  }}"
        AWS_S3_ENDPOINT: "https://s3-openshift-storage.{{ openshift_cluster_ingress_domain }}"
        AWS_SECRET_ACCESS_KEY: "{{ obc_secret.resources[0].data.AWS_SECRET_ACCESS_KEY | b64decode }}"

- name: "Create data-science-pipeline-bucket-ai-connection Backup - {{ ocp4_workload_cloud_native_robot_user }}"
  kubernetes.core.k8s:
    state: present
    definition: |
      apiVersion: v1
      kind: Secret
      metadata:
        finalizers:
          - github.com/cloud-native-robotz-hackathon_infrastructure_issues_86
        name: data-science-pipeline-bucket-ai-connection-backup
        namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
      type: Opaque
      stringData:
        AWS_ACCESS_KEY_ID: "{{ obc_secret.resources[0].data.AWS_ACCESS_KEY_ID | b64decode }}"
        AWS_DEFAULT_REGION: "us-east-1"
        AWS_S3_BUCKET: "{{ obc_cm.resources[0].data.BUCKET_NAME  }}"
        AWS_S3_ENDPOINT: "https://s3-openshift-storage.{{ openshift_cluster_ingress_domain }}"
        AWS_SECRET_ACCESS_KEY: "{{ obc_secret.resources[0].data.AWS_SECRET_ACCESS_KEY | b64decode }}"


- name: Start Data Science Pipeline Server
  kubernetes.core.k8s:
    state: present
    definition: |
      apiVersion: datasciencepipelinesapplications.opendatahub.io/v1alpha1
      kind: DataSciencePipelinesApplication
      metadata:
        name: dspa
        namespace: "{{ ocp4_workload_cloud_native_robot_user }}-ai"
      spec:
        apiServer:
          caBundleFileMountPath: ''
          stripEOF: true
          dbConfigConMaxLifetimeSec: 120
          applyTektonCustomResource: true
          caBundleFileName: ''
          deploy: true
          enableSamplePipeline: false
          autoUpdatePipelineDefaultVersion: true
          archiveLogs: false
          terminateStatus: Cancelled
          enableOauth: true
          trackArtifacts: true
          collectMetrics: true
          injectDefaultScript: true
        dspVersion: v2
        database:
          disableHealthCheck: false
          mariaDB:
            deploy: true
            pipelineDBName: mlpipeline
            pvcSize: 10Gi
            username: mlpipeline
        objectStorage:
          disableHealthCheck: false
          externalStorage:
            bucket: "{{ obc_cm.resources[0].data.BUCKET_NAME  }}"
            host: "s3-openshift-storage.{{ openshift_cluster_ingress_domain }}"
            port: ''
            region: us-east-1
            s3CredentialsSecret:
              accessKey: AWS_ACCESS_KEY_ID
              secretKey: AWS_SECRET_ACCESS_KEY
              secretName: data-science-pipeline-bucket-ai-connection
            scheme: https
        persistenceAgent:
          deploy: true
          numWorkers: 2
        scheduledWorkflow:
          cronScheduleTimezone: UTC
          deploy: true

# ---------------------------------------------------------
# Connect Gitea/starter-app-python and Pipeline As Code via WebHook
# ---------------------------------------------------------

- name: "Delete Gitea Token {{ ocp4_workload_cloud_native_robot_user }}/pipeline-as-code-token"
  ansible.builtin.uri:
    url: "{{ _gitea_api_uri }}/api/v1/users/{{ ocp4_workload_cloud_native_robot_user }}/tokens/pipeline-as-code-token"
    method: DELETE
    force_basic_auth: true
    status_code:
      - 204
      - 404
    url_username: "{{ ocp4_workload_cloud_native_robot_user }}"
    url_password: "{{ ocp4_workload_gitea_operator_user_password }}"
    headers:
      Content-Type: application/json
      accept: application/json


- name: "Create Gitea Token {{ ocp4_workload_cloud_native_robot_user }}/pipeline-as-code-token"
  ansible.builtin.uri:
    url: "{{ _gitea_api_uri }}/api/v1/users/{{ ocp4_workload_cloud_native_robot_user }}/tokens"
    method: POST
    force_basic_auth: true
    status_code:
      - 200
      - 201
    url_username: "{{ ocp4_workload_cloud_native_robot_user }}"
    url_password: "{{ ocp4_workload_gitea_operator_user_password }}"
    headers:
      Content-Type: application/json
      accept: application/json
    body_format: json
    body: '{"name": "pipeline-as-code-token","scopes": ["write:repository"]}'
  register: r_gitea_token

- name: Generate webhook secret
  ansible.builtin.set_fact:
    webhook_secret: "{{ lookup('community.general.random_string',length=32,special=false) }}"

- name: "Create Gitea Webhook {{ ocp4_workload_cloud_native_robot_user }}"
  ansible.builtin.uri:
    url: "{{ _gitea_api_uri }}/api/v1/repos/{{ ocp4_workload_cloud_native_robot_user }}/starter-app-python/hooks"
    method: POST
    force_basic_auth: true
    status_code:
      - 200
      - 201
    url_username: "{{ ocp4_workload_cloud_native_robot_user }}"
    url_password: "{{ ocp4_workload_gitea_operator_user_password }}"
    headers:
      Content-Type: application/json
      accept: application/json
    body_format: json
    body: |
      {
        "active": true,
        "branch_filter": "*",
          "config": {
            "content_type": "json",
            "url": "https://pipelines-as-code-controller-openshift-pipelines.{{ openshift_cluster_ingress_domain }}",
            "secret": "{{ webhook_secret }}"
          },
          "events": [
            "push"
          ],
      "type": "gitea"
      }

- name: "Create Webhook secret - {{ ocp4_workload_cloud_native_robot_user }}"
  kubernetes.core.k8s:
    state: present
    definition: |
      apiVersion: v1
      kind: Secret
      metadata:
        name: git-starter-app-python-token
        namespace: "{{ ocp4_workload_cloud_native_robot_user }}-dev"
      type: Opaque
      stringData:
        provider.token: "{{ r_gitea_token.json.sha1 }}"
        webhook.secret: "{{ webhook_secret }}"


- name: "Create Pipeline as Code Repository - {{ ocp4_workload_cloud_native_robot_user }}"
  kubernetes.core.k8s:
    state: present
    definition: |
      apiVersion: pipelinesascode.tekton.dev/v1alpha1
      kind: Repository
      metadata:
        name: git-starter-app-python
        namespace: {{ ocp4_workload_cloud_native_robot_user }}-dev
      spec:
        git_provider:
          secret:
            key: provider.token
            name: git-starter-app-python-token
          url: '{{ _gitea_api_uri }}/'
          webhook_secret:
            key: webhook.secret
            name: git-starter-app-python-token
        url: '{{ _gitea_api_uri }}/{{ ocp4_workload_cloud_native_robot_user }}/starter-app-python'
