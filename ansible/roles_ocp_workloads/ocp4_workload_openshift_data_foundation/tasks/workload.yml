---
- name: Setting up workload
  debug:
    msg: "Setting up OpenShift Data Foundation"

- name: Discovering worker nodes
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Node
    label_selectors:
    - node-role.kubernetes.io/worker
  register: r_worker_nodes

- name: Fail for less than 3 worker nodes
  when: r_worker_nodes.resources | length < 3
  fail:
    msg: "Less than 3 worker nodes detected. Cannot install Ceph..."

- name: Set variables
  set_fact:
    _ocp4_workload_openshift_data_foundation_worker_nodes: "{{ r_worker_nodes | json_query('resources[*].metadata.name') }}"

- name: Adding Ceph labels to worker nodes
  shell: "oc label nodes --overwrite {{ item }} cluster.ocs.openshift.io/openshift-storage=''"
  loop: "{{ _ocp4_workload_openshift_data_foundation_worker_nodes }}"

- name: Create namespace openshift-storage
  kubernetes.core.k8s:
    state: present
    kind: Namespace
    api_version: v1
    name: openshift-storage

- name: Create CatalogSource
  when: ocp4_workload_openshift_data_foundation_catalogsource_setup | bool
  kubernetes.core.k8s:
    state: present
    definition: "{{ lookup('template', 'catalogsource.yaml.j2' ) | from_yaml }}"

- name: Create OperatorGroup
  kubernetes.core.k8s:
    state: present
    apply: true
    definition: "{{ lookup('template', 'operatorgroup.yaml.j2' ) | from_yaml }}"

- name: Create operator subscription
  kubernetes.core.k8s:
    state: present
    definition: "{{ lookup('template', 'subscription.yaml.j2' ) | from_yaml }}"

- name: Wait for the operator managed CRD to become available
  kubernetes.core.k8s_info:
    api_version: apiextensions.k8s.io/v1
    kind: CustomResourceDefinition
    name: storagesystems.odf.openshift.io
  register: r_crd_check
  retries: 200
  delay: 10
  until: r_crd_check.resources | list | length == 1

- name: Wait for the console plugin to become available
  kubernetes.core.k8s_info:
    api_version: console.openshift.io/v1alpha1
    kind: ConsolePlugin
    name: odf-console
  register: r_crd_check
  retries: 200
  delay: 10
  until: r_crd_check.resources | list | length == 1

- name: Enable ODF console plugin
  kubernetes.core.k8s:
    state: patched
    merge_type:
    - strategic-merge
    - merge
    kind: Console
    api_version: operator.openshift.io/v1
    name: cluster
    definition:
      spec:
        plugins:
        - odf-console

- name: Create the ODF StorageCluster
  kubernetes.core.k8s:
    state: present
    definition: "{{ lookup('template', 'storagecluster.yaml.j2' ) | from_yaml }}"

- name: Create the ODF StorageSystem
  kubernetes.core.k8s:
    state: present
    merge_type:
    - strategic-merge
    - merge
    definition: "{{ lookup('template', 'storagesystem.yaml.j2' ) | from_yaml }}"
  register: r_k8s_run
  until: r_k8s_run is not failed
  delay: 10
  retries: 3

- name: Wait for ODF Storage System to finish deploying
  kubernetes.core.k8s_info:
    api_version: odf.openshift.io/v1alpha1
    kind: StorageSystem
    name: ocs-storagecluster-storagesystem
    namespace: openshift-storage
    wait: true
    wait_condition:
      reason: ReconcileCompleted
      status: 'True'
      type: Available
    wait_sleep: 10
    wait_timeout: 600

- name: Wait for ODF Storage Cluster to finish deploying
  kubernetes.core.k8s_info:
    api_version: ocs.openshift.io/v1
    kind: StorageCluster
    name: ocs-storagecluster
    namespace: openshift-storage
    wait: true
    wait_condition:
      reason: ReconcileCompleted
      status: "True"
      type: ReconcileComplete
    wait_sleep: 10
    wait_timeout: 600

- name: Update Tolerations for CSI DaemonSets
  when: ocp4_workload_openshift_data_foundation_tolerations | length > 0
  block:
  - name: Update Config Map rook-ceph-operator-config
    kubernetes.core.k8s:
      state: present
      definition: "{{ lookup('template', 'configmap-rook-ceph-operator-config.yaml.j2' ) | from_yaml }}"

  - name: Delete DaemonSets to pick up modified ConfigMap
    kubernetes.core.k8s:
      state: absent
      api_version: v1
      kind: DaemonSet
      name: "{{ item }}"
      namespace: openshift-storage
    loop:
    - csi-cephfsplugin
    - csi-rbdplugin

  - name: Restart Rook Ceph operator to redeploy DaemonSets
    kubernetes.core.k8s:
      state: absent
      api_version: v1
      kind: pod
      namespace: openshift-storage
      label_selectors:
      - app = rook-ceph-operator

- name: Update default storage class
  when: ocp4_workload_openshift_data_foundation_update_default_storage_class | bool
  block:
  - name: Wait for the StorageClasses to become available
    kubernetes.core.k8s_info:
      api_version: storage.k8s.io/v1
      kind: StorageClass
      name: "{{ ocp4_workload_openshift_data_foundation_new_default_storage_class_name }}"
    register: sc_crd
    retries: 200
    delay: 10
    until: sc_crd.resources | list | length == 1

  - name: Remove annotation from current default storage class
    command:
      cmd: >-
        oc annotate sc {{ ocp4_workload_openshift_data_foundation_old_default_storage_class_name }}
        storageclass.kubernetes.io/is-default-class-
    ignore_errors: true

  - name: Set new default storage class
    kubernetes.core.k8s:
      api_version: v1
      kind: StorageClass
      name: "{{ ocp4_workload_openshift_data_foundation_new_default_storage_class_name }}"
      merge_type:
      - strategic-merge
      - merge
      definition:
        kind: StorageClass
        apiVersion: v1
        name: "{{ ocp4_workload_openshift_data_foundation_new_default_storage_class_name }}"
        metadata:
          annotations:
            storageclass.kubernetes.io/is-default-class: "true"

- name: Deploy Ceph toolbox
  when: ocp4_workload_openshift_data_foundation_install_toolbox | bool
  kubernetes.core.k8s:
    state: present
    definition: "{{ lookup('template', 'toolbox.yaml.j2') }}"

# Leave this as the last task in the playbook.
# --------------------------------------------
- name: workload tasks complete
  debug:
    msg: "Workload Tasks completed successfully."
  when: not silent|bool
