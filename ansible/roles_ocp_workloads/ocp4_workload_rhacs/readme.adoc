= ocp4_workload_rhacs - Deploys RHACS

== Role overview

* This role installs the following onto the cluster:
** Red Hat Advanced Cluster Security RHACS
** OpenShift Pipelines - to run the plugins
** Sample applications

* It consists of the following tasks files:
** Tasks: link:./tasks/pre_workload.yml[pre_workload.yml] - Sets up an environment for the workload deployment.
*** Debug task will print out: `pre_workload Tasks completed successfully.`

** Tasks: link:./tasks/workload.yml[workload.yml] - Used to deploy ACS
*** This role deploys ACS
*** Debug task will print out: `workload Tasks completed successfully.`

** Tasks: link:./tasks/post_workload.yml[post_workload.yml] - Used to
 configure the workload after deployment
*** This role doesn't do anything here
*** Debug task will print out: `post_workload Tasks completed successfully.`

** Tasks: link:./tasks/remove_workload.yml[remove_workload.yml] - Used to
 delete the workload
*** This role uninstalls ACM and related resources
*** Debug task will print out: `remove_workload Tasks completed successfully.`

== Review the defaults variable file

* This file link:./defaults/main.yml[./defaults/main.yml] contains all the variables you need to define to control the deployment of your workload.
* The variable *ocp_username* is mandatory to assign the workload to the correct OpenShift user.
* A variable *silent=True* can be passed to suppress debug messages.
* Other variables:
** *ocp4_workload_rhacm_acs_namespace*: The name of the project where ACM is deployed. Default: `open-cluster-management`
** *ocp4_workload_rhacm_acs_release*: ACM release to be deployed. Default: `release-3.68.0`

* You can modify any of these default values by adding `-e "variable_name=variable_value"` to the command line

=== Deploy a Workload with the `ocp-workload` playbook [Mostly for testing]

cat <<EOF > ~/configs/secrets.yml
---
aws_access_key_id: '$AWS_ACCESS_KEY_ID'
aws_secret_access_key: '$AWS_SECRET_ACCESS_KEY'
aws_region: '$AWS_REGION'
HostedZoneId: '$AWS_HOSTED_ZONE_ID'
key_name: '$SSH_KEY_NAME'
subdomain_base_suffix: $SUBDOMAIN
ocp4_pull_secret: '$PULL_SECRET'

repo_method: rhn
rhel_subscription_user: $RHN_USER
rhel_subscription_pass: '$RHN_PASSWORD'
rhsm_pool_ids: '$RHN_POOL_ID'
EOF
----

From the Agnosticd/ansible directory run the playbook:

----
TARGET_HOST="<BASTION_IP>"                   # BASTION HOST IP
OCP_USERNAME="opentlc-mgr"                  # OCP CLUSTER ADMIN
WORKLOAD="ocp4_workload_rhacs"              # ROLE NAME
GUID=changeme                                     # GUID
SSH_PRIVATE_KEY='~/.ssh/id_rsa'              # SSH PRIVATE KEY TO CONNECT TO BASTION HOST

ansible-playbook -i ${TARGET_HOST}, ./configs/ocp-workloads/ocp-workload.yml \
    -e"ansible_ssh_private_key_file=${SSH_PRIVATE_KEY}" \
    -e"ansible_user=ec2-user" \
    -e"ocp_username=${OCP_USERNAME}" \
    -e"ocp_workload=${WORKLOAD}" \
    -e"silent=False" \
    -e"guid=${GUID}" \
    -e"ACTION=create" \
    -e @~/configs/secrets.yml
----

=== To Delete an environment

From the Agnosticd/ansible directory run the playbook:

----
ansible-playbook -i ${TARGET_HOST}, ./configs/ocp-workloads/ocp-workload.yml \
    -e"ansible_ssh_private_key_file=${SSH_PRIVATE_KEY}" \
    -e"ansible_user=ec2-user" \
    -e"ocp_username=${OCP_USERNAME}" \
    -e"ocp_workload=${WORKLOAD}" \
    -e"silent=False" \
    -e"guid=${GUID}" \
    -e"ACTION=remove" \
    -e @~/configs/ocp_rhacs_vars.yml \
    -e @~/configs/secrets.yml
----

== Planning

Cores: RHACS with all components on one host takes 6 cores.
Memory:  Need at least 36GB instance type: all in one: limits 8G + 8G + 4G + 4G + 500MGB
Storage: On AWS, use gp2
Subscription needed? for definitions.stackrox.io collector-modules.stackrox.io
