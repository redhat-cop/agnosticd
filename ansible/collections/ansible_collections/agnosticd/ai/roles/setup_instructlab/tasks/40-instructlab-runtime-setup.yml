---
- name: Venv and iLab Python setup
  block:

    - name: "Setup a Python {{ setup_instructlab_python_version }} virtual environment"
      ansible.builtin.command:
        cmd: >-
          python{{ setup_instructlab_python_version }} -m venv 
          --upgrade-deps {{ setup_instructlab_home }}/venv
      args:
        creates: "{{ setup_instructlab_home }}/venv"

    - name: Install InstructLab package from local git repo
      ansible.builtin.pip:
        name: "{{ setup_instructlab_home }}"
        state: present
        executable: "{{ setup_instructlab_home }}/venv/bin/pip"
      register: r_pip_install_result
      retries: 3
      delay: 5
      until: r_pip_install_result is success
      environment:
        PYTHONUNBUFFERED: 1
        PIP_NO_CACHE_DIR: "off"  # Allow caching to prevent redownloads
        PIP_TIMEOUT: 100  # Longer timeout

    - name: Remove llama_cpp_python from pip cache
      ansible.builtin.command:
        cmd: >-
          {{ setup_instructlab_home }}/venv/bin/pip
          cache remove llama_cpp_python

    - name: Setup llama-cpp-python with CUDA support
      ansible.builtin.command:
        cmd: >-
            {{ setup_instructlab_home }}/venv/bin/pip install -v
            --force-reinstall "llama_cpp_python[server]==0.2.79"
            --config-settings cmake.args="-DLLAMA_CUDA=on"
      environment:
        CUDA_HOME: "{{ setup_instructlab_cuda_home }}"
        LD_LIBRARY_PATH: "{{ setup_instructlab_cuda_lib_path }}:/usr/lib64"
        PATH: "{{ ansible_env.PATH }}:/usr/local/cuda/bin"
      ignore_errors: true

  become: true
  become_user: "{{ setup_instructlab_user }}"